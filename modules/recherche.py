# modules/recherche.py
"""Module de recherche unifi√© - Interface principale avec toutes les fonctionnalit√©s"""

import streamlit as st
import asyncio
import re
from datetime import datetime
from typing import Dict, Any, Optional, List
from collections import defaultdict
import pandas as pd

# ========================= CONFIGURATION =========================

# Styles de r√©daction
REDACTION_STYLES = {
    'formel': {
        'name': 'Formel',
        'description': 'Style juridique classique et solennel',
        'tone': 'respectueux et distant',
        'vocabulary': 'technique et pr√©cis'
    },
    'persuasif': {
        'name': 'Persuasif',
        'description': 'Style argumentatif et convaincant',
        'tone': 'assertif et engag√©',
        'vocabulary': 'percutant et imag√©'
    },
    'technique': {
        'name': 'Technique',
        'description': 'Style factuel et d√©taill√©',
        'tone': 'neutre et objectif',
        'vocabulary': 'sp√©cialis√© et exhaustif'
    },
    'synth√©tique': {
        'name': 'Synth√©tique',
        'description': 'Style concis et efficace',
        'tone': 'direct et clair',
        'vocabulary': 'simple et pr√©cis'
    },
    'p√©dagogique': {
        'name': 'P√©dagogique',
        'description': 'Style explicatif et accessible',
        'tone': 'bienveillant et didactique',
        'vocabulary': 'vulgaris√© et illustr√©'
    }
}

# Templates de documents pr√©d√©finis
DOCUMENT_TEMPLATES = {
    'conclusions_defense': {
        'name': 'Conclusions en d√©fense',
        'structure': [
            'I. FAITS ET PROC√âDURE',
            'II. DISCUSSION',
            ' A. Sur la recevabilit√©',
            ' B. Sur le fond',
            ' 1. Sur l\'√©l√©ment mat√©riel',
            ' 2. Sur l\'√©l√©ment intentionnel',
            ' 3. Sur le pr√©judice',
            'III. PAR CES MOTIFS'
        ],
        'style': 'formel'
    },
    'plainte_simple': {
        'name': 'Plainte simple',
        'structure': [
            'Objet : Plainte',
            'EXPOS√â DES FAITS',
            'QUALIFICATION JURIDIQUE',
            'PR√âJUDICES SUBIS',
            'DEMANDES',
            'PI√àCES JOINTES'
        ],
        'style': 'formel'
    },
    'plainte_avec_cpc': {
        'name': 'Plainte avec constitution de partie civile',
        'structure': [
            'Objet : Plainte avec constitution de partie civile',
            'EXPOS√â DES FAITS',
            'QUALIFICATION JURIDIQUE',
            'PR√âJUDICES SUBIS',
            'CONSTITUTION DE PARTIE CIVILE',
            '√âVALUATION DU PR√âJUDICE',
            'DEMANDES',
            'PI√àCES JOINTES'
        ],
        'style': 'formel'
    },
    'mise_en_demeure': {
        'name': 'Mise en demeure',
        'structure': [
            'MISE EN DEMEURE',
            'Rappel des faits',
            'Obligations non respect√©es',
            'D√©lai accord√©',
            'Cons√©quences du d√©faut',
            'R√©serves'
        ],
        'style': 'persuasif'
    },
    'note_synthese': {
        'name': 'Note de synth√®se',
        'structure': [
            'SYNTH√àSE EX√âCUTIVE',
            'I. CONTEXTE',
            'II. ANALYSE',
            'III. RECOMMANDATIONS',
            'IV. PLAN D\'ACTION'
        ],
        'style': 'synth√©tique'
    }
}

# ========================= IMPORTS =========================

# modules/recherche.py
"""Module de recherche unifi√© - Interface principale avec toutes les fonctionnalit√©s"""

import streamlit as st
import asyncio
import re
from datetime import datetime
from typing import Dict, Any, Optional, List
from collections import defaultdict
import pandas as pd

# ========================= CONFIGURATION =========================

# Styles de r√©daction
REDACTION_STYLES = {
    'formel': {
        'name': 'Formel',
        'description': 'Style juridique classique et solennel',
        'tone': 'respectueux et distant',
        'vocabulary': 'technique et pr√©cis'
    },
    'persuasif': {
        'name': 'Persuasif',
        'description': 'Style argumentatif et convaincant',
        'tone': 'assertif et engag√©',
        'vocabulary': 'percutant et imag√©'
    },
    'technique': {
        'name': 'Technique',
        'description': 'Style factuel et d√©taill√©',
        'tone': 'neutre et objectif',
        'vocabulary': 'sp√©cialis√© et exhaustif'
    },
    'synth√©tique': {
        'name': 'Synth√©tique',
        'description': 'Style concis et efficace',
        'tone': 'direct et clair',
        'vocabulary': 'simple et pr√©cis'
    },
    'p√©dagogique': {
        'name': 'P√©dagogique',
        'description': 'Style explicatif et accessible',
        'tone': 'bienveillant et didactique',
        'vocabulary': 'vulgaris√© et illustr√©'
    }
}

# Templates de documents pr√©d√©finis
DOCUMENT_TEMPLATES = {
    'conclusions_defense': {
        'name': 'Conclusions en d√©fense',
        'structure': [
            'I. FAITS ET PROC√âDURE',
            'II. DISCUSSION',
            ' A. Sur la recevabilit√©',
            ' B. Sur le fond',
            ' 1. Sur l\'√©l√©ment mat√©riel',
            ' 2. Sur l\'√©l√©ment intentionnel',
            ' 3. Sur le pr√©judice',
            'III. PAR CES MOTIFS'
        ],
        'style': 'formel'
    },
    'plainte_simple': {
        'name': 'Plainte simple',
        'structure': [
            'Objet : Plainte',
            'EXPOS√â DES FAITS',
            'QUALIFICATION JURIDIQUE',
            'PR√âJUDICES SUBIS',
            'DEMANDES',
            'PI√àCES JOINTES'
        ],
        'style': 'formel'
    },
    'plainte_avec_cpc': {
        'name': 'Plainte avec constitution de partie civile',
        'structure': [
            'Objet : Plainte avec constitution de partie civile',
            'EXPOS√â DES FAITS',
            'QUALIFICATION JURIDIQUE',
            'PR√âJUDICES SUBIS',
            'CONSTITUTION DE PARTIE CIVILE',
            '√âVALUATION DU PR√âJUDICE',
            'DEMANDES',
            'PI√àCES JOINTES'
        ],
        'style': 'formel'
    },
    'mise_en_demeure': {
        'name': 'Mise en demeure',
        'structure': [
            'MISE EN DEMEURE',
            'Rappel des faits',
            'Obligations non respect√©es',
            'D√©lai accord√©',
            'Cons√©quences du d√©faut',
            'R√©serves'
        ],
        'style': 'persuasif'
    },
    'note_synthese': {
        'name': 'Note de synth√®se',
        'structure': [
            'SYNTH√àSE EX√âCUTIVE',
            'I. CONTEXTE',
            'II. ANALYSE',
            'III. RECOMMANDATIONS',
            'IV. PLAN D\'ACTION'
        ],
        'style': 'synth√©tique'
    }
}

# ========================= IMPORTS =========================

try:
    # Import des managers
    from managers.azure_blob_manager import AzureBlobManager
    from managers.azure_search_manager import AzureSearchManager
    from managers.multi_llm_manager import MultiLLMManager
    from managers.jurisprudence_verifier import JurisprudenceVerifier, display_jurisprudence_verification
    
    # Import des mod√®les
    from models.dataclasses import (
        Document, 
        PieceSelectionnee, 
        AnalyseJuridique,
        InfractionIdentifiee
    )
    
    # Import de la configuration
    from config.app_config import (
        InfractionAffaires,
        ANALYSIS_PROMPTS_AFFAIRES,
        ANALYSIS_PROMPTS_INFRACTIONS,
        LLMProvider,
        SearchMode,
        app_config,
        api_config
    )
    
except ImportError as e:
    st.error(f"‚ö†Ô∏è Import manquant : {e}")
    
# ========================= PAGE PRINCIPALE =========================

def show_page():
    """Fonction principale de la page recherche universelle"""
    
    st.markdown("## üîç Recherche Universelle")
    
    # Barre de recherche principale
    col1, col2 = st.columns([5, 1])
    
    with col1:
        query = st.text_input(
            "Entrez votre commande ou recherche",
            placeholder="Ex: r√©diger conclusions @affaire_martin, analyser risques, importer documents...",
            key="universal_query",
            help="Utilisez @ pour r√©f√©rencer une affaire sp√©cifique"
        )
    
    with col2:
        search_button = st.button("üîç Rechercher", key="search_button", use_container_width=True)
    
    # Suggestions de commandes
    with st.expander("üí° Exemples de commandes", expanded=False):
        st.markdown("""
        **Recherche :**
        - `contrats soci√©t√© XYZ`
        - `@affaire_martin documents comptables`
        
        **Analyse :**
        - `analyser les risques @dossier_p√©nal`
        - `identifier les infractions @affaire_corruption`
        
        **R√©daction :**
        - `r√©diger conclusions d√©fense @affaire_martin abus biens sociaux`
        - `cr√©er plainte avec constitution partie civile escroquerie`
        - `r√©diger plainte contre Vinci, SOGEPROM @projet_26_05_2025`
        
        **Plaidoirie & Pr√©paration :**
        - `pr√©parer plaidoirie @affaire_martin audience correctionnelle`
        - `pr√©parer client interrogatoire @dossier_fraude`
        
        **Visualisations :**
        - `chronologie des faits @affaire_martin`
        - `cartographie des soci√©t√©s @groupe_abc`
        - `comparer les auditions @t√©moins`
        
        **Gestion :**
        - `s√©lectionner pi√®ces @dossier cat√©gorie proc√©dure`
        - `cr√©er bordereau @pi√®ces_s√©lectionn√©es`
        - `importer documents PDF`
        - `exporter analyse format word`
        - `envoyer par email @destinataire`
        """)
    
    # Menu d'actions rapides
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        if st.button("üìÑ Nouvelle r√©daction", key="quick_redaction"):
            st.session_state.universal_query = "r√©diger "
            st.session_state.process_query = True
    
    with col2:
        if st.button("ü§ñ Analyser dossier", key="quick_analysis"):
            st.session_state.universal_query = "analyser "
            st.session_state.process_query = True
    
    with col3:
        if st.button("üì• Importer", key="quick_import"):
            st.session_state.universal_query = "importer documents"
            st.session_state.process_query = True
    
    with col4:
        if st.button("üîÑ R√©initialiser", key="quick_reset"):
            clear_universal_state()
    
    # Traiter la requ√™te
    if query and (search_button or st.session_state.get('process_query', False)):
        with st.spinner("üîÑ Traitement en cours..."):
            process_universal_query(query)
    
    # Afficher les r√©sultats
    show_unified_results_tab()
    
    # R√©initialiser le flag de traitement
    if 'process_query' in st.session_state:
        st.session_state.process_query = False
    
    # Footer avec actions
    st.markdown("---")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("üíæ Sauvegarder le travail", key="save_work"):
            save_current_work()
    
    with col2:
        if st.button("üìä Afficher les statistiques", key="show_stats"):
            show_work_statistics()
    
    with col3:
        if st.button("üîó Partager", key="share_work"):
            share_current_work()

# ========================= ROUTING ET TRAITEMENT =========================

def process_universal_query(query: str):
    """Traite une requ√™te universelle et route vers la bonne fonction"""
    
    # Sauvegarder la requ√™te
    st.session_state.last_universal_query = query
    
    # Analyser la requ√™te pour d√©tecter le type
    query_lower = query.lower()
    
    # D√âTECTION POUR R√âDACTION (incluant votre cas de plainte)
    if any(word in query_lower for word in ['r√©dige', 'r√©diger', '√©crire', 'cr√©er', 'plainte', 'conclusions', 'courrier', 'assignation']):
        st.info("üìù D√©tection d'une demande de r√©daction...")
        
        # Cas sp√©cifique : plainte avec parties multiples
        if 'plainte' in query_lower:
            # Extraire les parties de la requ√™te
            parties = []
            parties_keywords = [
                'interconstruction', 'vinci', 'sogeprom', 'demathieu bard',
                'bouygues', 'eiffage', 'spie', 'leon grosse'
            ]
            
            for partie in parties_keywords:
                if partie in query_lower:
                    # Formatage correct du nom
                    if partie == 'sogeprom':
                        parties.append('SOGEPROM R√©alisations')
                    elif partie == 'demathieu bard':
                        parties.append('Demathieu Bard')
                    else:
                        parties.append(partie.title())
            
            # Extraire la r√©f√©rence
            reference = None
            if '@' in query:
                ref_match = re.search(r'@(\w+)', query)
                if ref_match:
                    reference = ref_match.group(1)
            
            # Cr√©er la demande de r√©daction
            st.session_state.redaction_request = {
                'type': 'plainte',
                'parties': parties,
                'reference': reference,
                'query': query
            }
            
            # G√©n√©rer la plainte
            generate_plainte(query, parties)
        else:
            # Autres types de r√©daction
            process_redaction_request(query, analyze_query(query))
    
    # PLAIDOIRIE
    elif any(word in query_lower for word in ['plaidoirie', 'plaider', 'audience']):
        st.info("üé§ D√©tection d'une demande de plaidoirie...")
        process_plaidoirie_request(query, analyze_query(query))
    
    # PR√âPARATION CLIENT
    elif any(word in query_lower for word in ['pr√©parer client', 'pr√©paration', 'coaching']):
        st.info("üë• D√©tection d'une demande de pr√©paration client...")
        process_preparation_client_request(query, analyze_query(query))
    
    # IMPORT
    elif any(word in query_lower for word in ['import', 'importer', 'charger', 'upload']):
        st.info("üì• D√©tection d'une demande d'import...")
        process_import_request(query, analyze_query(query))
    
    # EXPORT
    elif any(word in query_lower for word in ['export', 'exporter', 't√©l√©charger', 'download']):
        st.info("üíæ D√©tection d'une demande d'export...")
        process_export_request(query, analyze_query(query))
    
    # EMAIL
    elif any(word in query_lower for word in ['email', 'envoyer', 'mail', 'courrier √©lectronique']):
        st.info("üìß D√©tection d'une demande d'email...")
        process_email_request(query, analyze_query(query))
    
    # ANALYSE
    elif any(word in query_lower for word in ['analyser', 'analyse', '√©tudier', 'examiner']):
        st.info("ü§ñ D√©tection d'une demande d'analyse...")
        process_analysis_request(query, analyze_query(query))
    
    # PI√àCES
    elif any(word in query_lower for word in ['s√©lectionner pi√®ces', 'pi√®ces', 's√©lection']):
        st.info("üìã D√©tection d'une demande de s√©lection de pi√®ces...")
        process_piece_selection_request(query, analyze_query(query))
    
    # BORDEREAU
    elif 'bordereau' in query_lower:
        st.info("üìä D√©tection d'une demande de bordereau...")
        process_bordereau_request(query, analyze_query(query))
    
    # SYNTH√àSE
    elif any(word in query_lower for word in ['synth√®se', 'synth√©tiser', 'r√©sumer']):
        st.info("üìù D√©tection d'une demande de synth√®se...")
        process_synthesis_request(query, analyze_query(query))
    
    # TEMPLATES
    elif any(word in query_lower for word in ['template', 'mod√®le', 'gabarit']):
        st.info("üìÑ D√©tection d'une demande de template...")
        process_template_request(query, analyze_query(query))
    
    # JURISPRUDENCE
    elif any(word in query_lower for word in ['jurisprudence', 'juris', 'd√©cision', 'arr√™t']):
        st.info("‚öñÔ∏è D√©tection d'une demande de jurisprudence...")
        process_jurisprudence_request(query, analyze_query(query))
    
    # CHRONOLOGIE
    elif any(word in query_lower for word in ['chronologie', 'timeline', 'frise']):
        st.info("‚è±Ô∏è D√©tection d'une demande de chronologie...")
        process_timeline_request(query, analyze_query(query))
    
    # CARTOGRAPHIE
    elif any(word in query_lower for word in ['cartographie', 'mapping', 'carte', 'r√©seau']):
        st.info("üó∫Ô∏è D√©tection d'une demande de cartographie...")
        process_mapping_request(query, analyze_query(query))
    
    # COMPARAISON
    elif any(word in query_lower for word in ['comparer', 'comparaison', 'diff√©rences']):
        st.info("üîÑ D√©tection d'une demande de comparaison...")
        process_comparison_request(query, analyze_query(query))
    
    else:
        # Recherche simple par d√©faut
        st.info("üîç Recherche simple...")
        process_search_request(query, analyze_query(query))

# ========================= AFFICHAGE DES R√âSULTATS =========================

def show_unified_results_tab():
    """Affiche tous les types de r√©sultats dans un onglet unifi√©"""
    
    has_results = False
    
    # R√âSULTATS DE R√âDACTION (Priorit√© 1)
    if st.session_state.get('redaction_result'):
        show_redaction_results()
        has_results = True
    
    # R√âSULTATS D'ANALYSE IA (Priorit√© 2)
    elif st.session_state.get('ai_analysis_results'):
        show_ai_analysis_results()
        has_results = True
    
    # R√âSULTATS DE RECHERCHE (Priorit√© 3)
    elif st.session_state.get('search_results'):
        show_search_results()
        has_results = True
    
    # R√âSULTATS DE SYNTH√àSE (Priorit√© 4)
    elif st.session_state.get('synthesis_result'):
        show_synthesis_results()
        has_results = True
    
    # R√âSULTATS DE TIMELINE (Priorit√© 5)
    elif st.session_state.get('timeline_result'):
        show_timeline_results()
        has_results = True
    
    # Message si aucun r√©sultat
    if not has_results:
        st.info("üí° Utilisez la barre de recherche universelle pour commencer")
        
        # Suggestions d'utilisation
        st.markdown("""
        ### üöÄ Exemples de commandes
        
        **Recherche :**
        - `contrats soci√©t√© XYZ`
        - `@affaire_martin documents comptables`
        
        **Analyse :**
        - `analyser les risques @dossier_p√©nal`
        - `identifier les infractions @affaire_corruption`
        
        **R√©daction :**
        - `r√©diger conclusions d√©fense @affaire_martin`
        - `cr√©er plainte contre Vinci, SOGEPROM`
        
        **Gestion :**
        - `importer documents PDF`
        - `exporter analyse format word`
        """)

def show_redaction_results():
    """Affiche les r√©sultats de r√©daction"""
    result = st.session_state.redaction_result
    
    st.markdown("### üìù Document juridique g√©n√©r√©")
    
    # M√©tadonn√©es
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        doc_icons = {
            'conclusions': '‚öñÔ∏è Conclusions',
            'plainte': 'üìã Plainte',
            'courrier': '‚úâÔ∏è Courrier',
            'assignation': 'üìú Assignation'
        }
        st.metric("Type", doc_icons.get(result['type'], 'üìÑ Document'))
    
    with col2:
        st.metric("G√©n√©r√© par", result.get('provider', 'IA'))
    
    with col3:
        word_count = len(result['document'].split())
        st.metric("Mots", f"{word_count:,}")
    
    with col4:
        char_count = len(result['document'])
        st.metric("Caract√®res", f"{char_count:,}")
    
    # Zone d'√©dition principale
    st.markdown("#### üìÑ Contenu du document")
    
    edited_content = st.text_area(
        "Vous pouvez √©diter le document",
        value=result['document'],
        height=600,
        key="edit_redaction_main"
    )
    
    # Barre d'outils
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        if st.button("üîÑ R√©g√©n√©rer", key="regenerate_main"):
            st.session_state.process_query = True
            st.rerun()
    
    with col2:
        if st.button("üìä Statistiques", key="document_stats"):
            show_document_statistics(edited_content)
    
    with col3:
        # Export Word
        st.download_button(
            "üìÑ Word",
            edited_content.encode('utf-8'),
            f"{result['type']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.docx",
            "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
        )
    
    with col4:
        # Export texte
        st.download_button(
            "üìù Texte",
            edited_content.encode('utf-8'),
            f"{result['type']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
            "text/plain"
        )
    
    with col5:
        if st.button("üìß Envoyer", key="prepare_email_main"):
            st.session_state.pending_email = {
                'content': edited_content,
                'type': result['type']
            }

def show_ai_analysis_results():
    """Affiche les r√©sultats d'analyse IA avec v√©rification des jurisprudences"""
    results = st.session_state.ai_analysis_results
    
    if 'error' in results:
        st.error(f"‚ùå {results['error']}")
        return
    
    analysis_titles = {
        'risk_analysis': '‚ö†Ô∏è Analyse des risques',
        'compliance': '‚úÖ Analyse de conformit√©',
        'strategy': 'üéØ Analyse strat√©gique',
        'general_analysis': 'ü§ñ Analyse g√©n√©rale',
        'infractions': 'üéØ Analyse infractions √©conomiques'
    }
    
    st.markdown(f"### {analysis_titles.get(results.get('type'), 'ü§ñ Analyse IA')}")
    
    # M√©tadonn√©es
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Documents analys√©s", results.get('document_count', 0))
    with col2:
        st.metric("Type", results.get('type', 'general').replace('_', ' ').title())
    with col3:
        st.metric("G√©n√©r√© le", results.get('timestamp', datetime.now()).strftime('%H:%M'))
    
    # Contenu de l'analyse
    st.markdown("#### üìä R√©sultats de l'analyse")
    
    analysis_content = st.text_area(
        "Analyse d√©taill√©e",
        value=results.get('content', ''),
        height=600,
        key="ai_analysis_content"
    )
    
    # V√©rification des jurisprudences
    if st.checkbox("üîç V√©rifier les jurisprudences cit√©es", key="verify_juris_check"):
        verify_jurisprudences_in_analysis(analysis_content)
    
    # Actions
    col1, col2 = st.columns(2)
    
    with col1:
        st.download_button(
            "üíæ T√©l√©charger",
            analysis_content.encode('utf-8'),
            f"analyse_{results.get('type', 'general')}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
            "text/plain"
        )
    
    with col2:
        if st.button("üîÑ Approfondir", key="deepen_analysis"):
            st.session_state.pending_deepen_analysis = True

def show_search_results():
    """Affiche les r√©sultats de recherche"""
    results = st.session_state.search_results
    
    st.markdown(f"### üîç R√©sultats de recherche ({len(results)} documents)")
    
    if not results:
        st.info("Aucun r√©sultat trouv√©")
        return
    
    # Options d'affichage
    col1, col2 = st.columns(2)
    
    with col1:
        sort_by = st.selectbox(
            "Trier par",
            ["Pertinence", "Titre", "Date", "Source"],
            key="sort_search_results"
        )
    
    with col2:
        view_mode = st.radio(
            "Affichage",
            ["Compact", "D√©taill√©"],
            key="view_mode_search",
            horizontal=True
        )
    
    # Afficher les r√©sultats
    for i, result in enumerate(results[:20], 1):  # Limiter √† 20
        with st.container():
            if view_mode == "Compact":
                st.markdown(f"**{i}. {result.get('title', 'Sans titre')}**")
                st.caption(f"Source: {result.get('source', 'N/A')} | Score: {result.get('score', 0):.0%}")
            else:
                st.markdown(f"**{i}. {result.get('title', 'Sans titre')}**")
                st.caption(f"Source: {result.get('source', 'N/A')} | Score: {result.get('score', 0):.0%}")
                
                # Extrait
                content = result.get('content', '')
                if content:
                    st.text_area(
                        "Extrait",
                        value=content[:500] + '...' if len(content) > 500 else content,
                        height=150,
                        key=f"extract_{i}",
                        disabled=True
                    )
            
            st.divider()

def show_synthesis_results():
    """Affiche les r√©sultats de synth√®se"""
    result = st.session_state.synthesis_result
    
    if 'error' in result:
        st.error(f"‚ùå {result['error']}")
        return
    
    st.markdown("### üìù Synth√®se des documents")
    
    # M√©tadonn√©es
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Pi√®ces analys√©es", result.get('piece_count', 0))
    with col2:
        st.metric("Cat√©gories", len(result.get('categories', [])))
    with col3:
        st.metric("G√©n√©r√© le", result.get('timestamp', datetime.now()).strftime('%H:%M'))
    
    # Contenu
    synthesis_content = st.text_area(
        "Contenu de la synth√®se",
        value=result.get('content', ''),
        height=600,
        key="synthesis_content_display"
    )
    
    # Actions
    if st.download_button(
        "üíæ T√©l√©charger",
        synthesis_content.encode('utf-8'),
        f"synthese_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
        "text/plain"
    ):
        st.success("‚úÖ Synth√®se t√©l√©charg√©e")

def show_timeline_results():
    """Affiche les r√©sultats de chronologie"""
    result = st.session_state.timeline_result
    
    st.markdown(f"### ‚è±Ô∏è Chronologie")
    
    # Affichage simple
    for event in result.get('events', []):
        col1, col2 = st.columns([1, 4])
        with col1:
            st.write(f"**{event.get('date', 'N/A')}**")
        with col2:
            st.write(event.get('description', ''))
            if event.get('actors'):
                st.caption(f"üë• {', '.join(event['actors'])}")

# ========================= GESTION DES PI√àCES =========================

def process_piece_selection_request(query: str, analysis: dict):
    """Traite une demande de s√©lection de pi√®ces"""
    
    st.markdown("### üìã S√©lection de pi√®ces")
    
    # Collecter les documents disponibles
    available_docs = collect_available_documents(analysis)
    
    if not available_docs:
        st.warning("‚ö†Ô∏è Aucun document disponible")
        return
    
    # Grouper par cat√©gorie
    categories = group_documents_by_category(available_docs)
    
    # Interface de s√©lection
    selected_pieces = []
    
    for category, docs in categories.items():
        with st.expander(f"üìÅ {category} ({len(docs)} documents)", expanded=True):
            select_all = st.checkbox(f"Tout s√©lectionner - {category}", key=f"select_all_{category}")
            
            for doc in docs:
                is_selected = st.checkbox(
                    f"üìÑ {doc['title']}",
                    value=select_all,
                    key=f"select_doc_{doc['id']}",
                    help=f"Source: {doc.get('source', 'N/A')}"
                )
                
                if is_selected:
                    selected_pieces.append(PieceSelectionnee(
                        numero=len(selected_pieces) + 1,
                        titre=doc['title'],
                        description=doc.get('description', ''),
                        categorie=category,
                        date=doc.get('date'),
                        source=doc.get('source', ''),
                        pertinence=calculate_piece_relevance(doc, analysis)
                    ))
    
    # Sauvegarder la s√©lection
    st.session_state.selected_pieces = selected_pieces
    
    # Actions
    if selected_pieces:
        st.success(f"‚úÖ {len(selected_pieces)} pi√®ces s√©lectionn√©es")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("üìä Cr√©er bordereau", key="create_bordereau_from_selection"):
                process_bordereau_request(query, analysis)
        
        with col2:
            if st.button("üìÑ Synth√©tiser", key="synthesize_selection"):
                synthesize_selected_pieces(selected_pieces)
        
        with col3:
            if st.button("üì§ Exporter liste", key="export_piece_list"):
                export_piece_list(selected_pieces)

def process_bordereau_request(query: str, analysis: dict):
    """Traite une demande de cr√©ation de bordereau"""
    
    pieces = st.session_state.get('selected_pieces', [])
    
    if not pieces:
        st.warning("‚ö†Ô∏è Aucune pi√®ce s√©lectionn√©e pour le bordereau")
        return
    
    # Cr√©er le bordereau
    bordereau = create_bordereau(pieces, analysis)
    
    # Afficher
    st.markdown("### üìä Bordereau de communication de pi√®ces")
    
    # En-t√™te
    st.text_area(
        "En-t√™te du bordereau",
        value=bordereau['header'],
        height=150,
        key="bordereau_header"
    )
    
    # Table des pi√®ces
    try:
        df = pd.DataFrame([
            {
                'N¬∞': p.numero,
                'Titre': p.titre,
                'Description': p.description,
                'Cat√©gorie': p.categorie,
                'Date': p.date.strftime('%d/%m/%Y') if p.date else 'N/A'
            }
            for p in pieces
        ])
        
        st.dataframe(df, use_container_width=True)
    except:
        # Affichage sans pandas
        for piece in pieces:
            st.write(f"**{piece.numero}.** {piece.titre}")
            if piece.description:
                st.caption(piece.description)
    
    # Actions
    col1, col2 = st.columns(2)
    
    with col1:
        st.download_button(
            "üíæ T√©l√©charger bordereau",
            create_bordereau_document(bordereau),
            f"bordereau_{datetime.now().strftime('%Y%m%d_%H%M%S')}.docx",
            "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
        )
    
    with col2:
        if st.button("üìß Envoyer bordereau", key="send_bordereau"):
            st.session_state.pending_email = {
                'content': create_bordereau_document(bordereau),
                'type': 'bordereau'
            }

def synthesize_selected_pieces(pieces: list):
    """Synth√©tise les pi√®ces s√©lectionn√©es"""
    
    try:
        llm_manager = MultiLLMManager()
        
        if not llm_manager.clients:
            return {'error': 'Aucune IA disponible'}
        
        # Construire le contexte
        context = "PI√àCES √Ä SYNTH√âTISER:\n\n"
        
        for piece in pieces[:20]:  # Limiter
            context += f"Pi√®ce {piece.numero}: {piece.titre}\n"
            context += f"Cat√©gorie: {piece.categorie}\n"
            if piece.description:
                context += f"Description: {piece.description}\n"
            context += "\n"
        
        # Prompt
        synthesis_prompt = f"""{context}
Cr√©e une synth√®se structur√©e de ces pi√®ces.
La synth√®se doit inclure:
1. Vue d'ensemble des pi√®ces
2. Points cl√©s par cat√©gorie
3. Chronologie si applicable
4. Points d'attention juridiques
5. Recommandations"""
        
        provider = list(llm_manager.clients.keys())[0]
        response = llm_manager.query_single_llm(
            provider,
            synthesis_prompt,
            "Tu es un expert en analyse de documents juridiques."
        )
        
        if response['success']:
            synthesis_result = {
                'content': response['response'],
                'piece_count': len(pieces),
                'categories': list(set(p.categorie for p in pieces)),
                'timestamp': datetime.now()
            }
            st.session_state.synthesis_result = synthesis_result
            return synthesis_result
        else:
            return {'error': '√âchec de la synth√®se'}
            
    except Exception as e:
        return {'error': f'Erreur synth√®se: {str(e)}'}

# ========================= ANALYSE IA =========================

def process_analysis_request(query: str, analysis: dict):
    """Traite une demande d'analyse IA avec support des infractions"""
    
    # Collecter les documents pertinents
    documents = collect_relevant_documents(analysis)
    
    if not documents:
        st.warning("‚ö†Ô∏è Aucun document trouv√© pour l'analyse")
        return
    
    # Configuration de l'analyse
    st.markdown("### ‚öôÔ∏è Configuration de l'analyse")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Type d'infraction si pertinent
        if any(word in query.lower() for word in ['infraction', 'd√©lit', 'crime']):
            infractions_list = [inf.value for inf in InfractionAffaires]
            
            st.session_state.infraction = st.text_input(
                "Type d'infraction",
                placeholder="Ex: Abus de biens sociaux, corruption, fraude fiscale...",
                key="infraction_input",
                help="Saisissez librement l'infraction"
            )
            
            if not st.session_state.infraction:
                st.info("üí° Suggestions : " + ", ".join(infractions_list[:5]) + "...")
        
        # Client
        st.session_state.client_nom = st.text_input(
            "Nom du client",
            placeholder="Personne physique ou morale",
            key="client_nom_analyse"
        )
    
    with col2:
        # Type d'analyse
        analysis_type = st.selectbox(
            "Type d'analyse",
            ["Analyse g√©n√©rale", "Risques juridiques", "Conformit√©", "Strat√©gie", "Infractions"],
            key="analysis_type_select"
        )
    
    # Lancer l'analyse
    if st.button("üöÄ Lancer l'analyse", type="primary", key="launch_analysis"):
        with st.spinner("ü§ñ Analyse en cours..."):
            if analysis_type == "Risques juridiques":
                results = analyze_legal_risks(documents, query)
            elif analysis_type == "Conformit√©":
                results = analyze_compliance(documents, query)
            elif analysis_type == "Strat√©gie":
                results = analyze_strategy(documents, query)
            elif analysis_type == "Infractions":
                results = analyze_infractions(documents, query)
            else:
                results = perform_general_analysis(documents, query)
        
        # Stocker les r√©sultats
        st.session_state.ai_analysis_results = results
        st.rerun()

def analyze_infractions(documents: List[Dict[str, Any]], query: str) -> dict:
    """Analyse sp√©cifique des infractions √©conomiques"""
    
    llm_manager = MultiLLMManager()
    if not llm_manager.clients:
        return {'error': 'Aucune IA disponible'}
    
    # Construire le prompt sp√©cialis√©
    infraction_prompt = f"""Analyse ces documents pour identifier des infractions √©conomiques.
Client: {st.session_state.get('client_nom', 'Non sp√©cifi√©')}
Infraction suspect√©e: {st.session_state.get('infraction', '√Ä d√©terminer')}
DOCUMENTS:
{chr(10).join([f"- {doc.get('title', 'Sans titre')}: {doc.get('content', '')[:500]}..." for doc in documents[:10]])}
Identifie:
1. INFRACTIONS CARACT√âRIS√âES
   - Qualification juridique pr√©cise
   - Articles du Code p√©nal applicables
   - √âl√©ments constitutifs pr√©sents/absents
   
2. RESPONSABILIT√âS
   - Personnes physiques impliqu√©es
   - Responsabilit√© des personnes morales
   
3. SANCTIONS ENCOURUES
   - Peines principales
   - Peines compl√©mentaires
   - Prescription
4. √âL√âMENTS DE PREUVE
   - Preuves mat√©rielles identifi√©es
   - T√©moignages pertinents
   - Documents cl√©s
5. STRAT√âGIE DE D√âFENSE
   - Points faibles de l'accusation
   - Arguments de d√©fense possibles
   - Jurisprudences favorables"""
    
    try:
        provider = list(llm_manager.clients.keys())[0]
        response = llm_manager.query_single_llm(
            provider,
            infraction_prompt,
            "Tu es un avocat expert en droit p√©nal des affaires."
        )
        
        if response['success']:
            return {
                'type': 'infractions',
                'content': response['response'],
                'document_count': len(documents),
                'timestamp': datetime.now(),
                'query': query,
                'infraction': st.session_state.get('infraction', 'Non sp√©cifi√©e')
            }
    except Exception as e:
        return {'error': f'Erreur analyse infractions: {str(e)}'}

def analyze_legal_risks(documents: List[Dict[str, Any]], query: str) -> dict:
    """Analyse les risques juridiques"""
    
    llm_manager = MultiLLMManager()
    if not llm_manager.clients:
        return {'error': 'Aucune IA disponible'}
    
    # Construire le prompt
    risk_prompt = f"""Analyse les risques juridiques dans ces documents.
DOCUMENTS:
{chr(10).join([f"- {doc.get('title', 'Sans titre')}: {doc.get('content', '')[:500]}..." for doc in documents[:10]])}
QUESTION: {query}
Identifie et √©value:
1. RISQUES P√âNAUX
2. RISQUES CIVILS
3. RISQUES R√âPUTATIONNELS
4. RECOMMANDATIONS
Format structur√© avec √©valuation pr√©cise."""
    
    try:
        provider = list(llm_manager.clients.keys())[0]
        response = llm_manager.query_single_llm(
            provider,
            risk_prompt,
            "Tu es un expert en analyse de risques juridiques."
        )
        
        if response['success']:
            return {
                'type': 'risk_analysis',
                'content': response['response'],
                'document_count': len(documents),
                'timestamp': datetime.now(),
                'query': query
            }
    except Exception as e:
        return {'error': f'Erreur analyse: {str(e)}'}

def analyze_compliance(documents: List[Dict[str, Any]], query: str) -> dict:
    """Analyse de conformit√©"""
    
    llm_manager = MultiLLMManager()
    if not llm_manager.clients:
        return {'error': 'Aucune IA disponible'}
    
    compliance_prompt = f"""Analyse la conformit√© l√©gale et r√©glementaire.
DOCUMENTS:
{chr(10).join([f"- {doc.get('title', 'Sans titre')}: {doc.get('content', '')[:500]}..." for doc in documents[:10]])}
QUESTION: {query}
V√©rifie:
1. CONFORMIT√â L√âGALE
2. CONFORMIT√â R√âGLEMENTAIRE
3. MANQUEMENTS IDENTIFI√âS
4. ACTIONS CORRECTIVES
5. RECOMMANDATIONS"""
    
    try:
        provider = list(llm_manager.clients.keys())[0]
        response = llm_manager.query_single_llm(
            provider,
            compliance_prompt,
            "Tu es un expert en conformit√© juridique."
        )
        
        if response['success']:
            return {
                'type': 'compliance',
                'content': response['response'],
                'document_count': len(documents),
                'timestamp': datetime.now(),
                'query': query
            }
    except Exception as e:
        return {'error': f'Erreur analyse conformit√©: {str(e)}'}

def analyze_strategy(documents: List[Dict[str, Any]], query: str) -> dict:
    """Analyse strat√©gique"""
    
    llm_manager = MultiLLMManager()
    if not llm_manager.clients:
        return {'error': 'Aucune IA disponible'}
    
    strategy_prompt = f"""D√©veloppe une strat√©gie juridique bas√©e sur ces documents.
DOCUMENTS:
{chr(10).join([f"- {doc.get('title', 'Sans titre')}: {doc.get('content', '')[:500]}..." for doc in documents[:10]])}
QUESTION: {query}
√âlabore:
1. ANALYSE DE LA SITUATION
2. OPTIONS STRAT√âGIQUES
3. AVANTAGES/INCONV√âNIENTS
4. STRAT√âGIE RECOMMAND√âE
5. PLAN D'ACTION"""
    
    try:
        provider = list(llm_manager.clients.keys())[0]
        response = llm_manager.query_single_llm(
            provider,
            strategy_prompt,
            "Tu es un strat√®ge juridique exp√©riment√©."
        )
        
        if response['success']:
            return {
                'type': 'strategy',
                'content': response['response'],
                'document_count': len(documents),
                'timestamp': datetime.now(),
                'query': query
            }
    except Exception as e:
        return {'error': f'Erreur analyse strat√©gique: {str(e)}'}

def perform_general_analysis(documents: List[Dict[str, Any]], query: str) -> dict:
    """Analyse g√©n√©rale des documents"""
    
    llm_manager = MultiLLMManager()
    if not llm_manager.clients:
        return {'error': 'Aucune IA disponible'}
    
    general_prompt = f"""Analyse ces documents pour r√©pondre √† la question.
DOCUMENTS:
{chr(10).join([f"- {doc.get('title', 'Sans titre')}: {doc.get('content', '')[:500]}..." for doc in documents[:10]])}
QUESTION: {query}
Fournis une analyse compl√®te et structur√©e."""
    
    try:
        provider = list(llm_manager.clients.keys())[0]
        response = llm_manager.query_single_llm(
            provider,
            general_prompt,
            "Tu es un expert en analyse juridique."
        )
        
        if response['success']:
            return {
                'type': 'general_analysis',
                'content': response['response'],
                'document_count': len(documents),
                'timestamp': datetime.now(),
                'query': query
            }
    except Exception as e:
        return {'error': f'Erreur analyse: {str(e)}'}

def verify_jurisprudences_in_analysis(content: str):
    """V√©rifie les jurisprudences cit√©es dans l'analyse"""
    st.markdown("### üîç V√©rification des jurisprudences cit√©es")
    
    try:
        # Cr√©er le v√©rificateur
        verifier = JurisprudenceVerifier()
        
        # Afficher l'interface de v√©rification
        verification_results = display_jurisprudence_verification(content, verifier)
        
        # Stocker les r√©sultats de v√©rification
        if verification_results:
            st.session_state.jurisprudence_verification = verification_results
            
            # R√©sum√©
            verified_count = sum(1 for r in verification_results if r.status == 'verified')
            total_count = len(verification_results)
            
            col1, col2 = st.columns(2)
            with col1:
                st.metric("Jurisprudences v√©rifi√©es", f"{verified_count}/{total_count}")
            
            with col2:
                confidence = (verified_count / total_count * 100) if total_count > 0 else 0
                st.metric("Fiabilit√© des sources", f"{confidence:.0f}%")
        
        return verification_results
    except:
        st.warning("‚ö†Ô∏è V√©rificateur de jurisprudences non disponible")
        return []

# ========================= FONCTIONS DE TRAITEMENT =========================

def process_redaction_request(query: str, analysis: dict):
    """Traite une demande de r√©daction"""
    # Import depuis le module de r√©daction
    st.info("üìù Traitement de la demande de r√©daction...")
    # TODO: Impl√©menter ou importer depuis recherche_redaction

def generate_plainte(query: str, parties: list):
    """G√©n√®re une plainte avec les parties sp√©cifi√©es"""
    
    llm_manager = MultiLLMManager()
    if not llm_manager.clients:
        st.error("‚ùå Aucune IA disponible")
        return
    
    # Construire le prompt
    plainte_prompt = f"""R√©dige une plainte p√©nale professionnelle.
DEMANDEUR: {st.session_state.get('client_nom', 'Le plaignant')}
PARTIES MISES EN CAUSE: {', '.join(parties)}
CONTEXTE: {query}
Structure la plainte avec:
1. En-t√™te (Tribunal comp√©tent, identit√© du plaignant)
2. EXPOS√â DES FAITS (chronologique et d√©taill√©)
3. QUALIFICATION JURIDIQUE (infractions caract√©ris√©es)
4. PR√âJUDICES SUBIS (moral, mat√©riel, financier)
5. DEMANDES (poursuites p√©nales, dommages-int√©r√™ts)
6. PI√àCES JOINTES
Style: Formel, juridique, factuel."""
    
    try:
        provider = list(llm_manager.clients.keys())[0]
        response = llm_manager.query_single_llm(
            provider,
            plainte_prompt,
            "Tu es un avocat expert en r√©daction de plaintes p√©nales."
        )
        
        if response['success']:
            st.session_state.redaction_result = {
                'type': 'plainte',
                'document': response['response'],
                'provider': provider.value,
                'timestamp': datetime.now(),
                'parties': parties
            }
            st.rerun()
    except Exception as e:
        st.error(f"‚ùå Erreur g√©n√©ration: {str(e)}")

def process_plaidoirie_request(query: str, analysis: dict):
    """Traite une demande de plaidoirie"""
    st.info("üé§ Pr√©paration de plaidoirie...")
    # TODO: Impl√©menter

def process_preparation_client_request(query: str, analysis: dict):
    """Traite une demande de pr√©paration client"""
    st.info("üë• Pr√©paration du client...")
    # TODO: Impl√©menter

def process_import_request(query: str, analysis: dict):
    """Traite une demande d'import"""
    st.info("üì• Import de documents...")
    # TODO: Impl√©menter

def process_export_request(query: str, analysis: dict):
    """Traite une demande d'export"""
    st.info("üíæ Export en cours...")
    # TODO: Impl√©menter

def process_email_request(query: str, analysis: dict):
    """Traite une demande d'email"""
    st.info("üìß Pr√©paration de l'email...")
    # TODO: Impl√©menter

def process_synthesis_request(query: str, analysis: dict):
    """Traite une demande de synth√®se"""
    
    # D√©terminer la source
    if st.session_state.get('selected_pieces'):
        content_to_synthesize = synthesize_selected_pieces(st.session_state.selected_pieces)
    elif analysis.get('reference'):
        docs = search_by_reference(f"@{analysis['reference']}")
        pieces = []
        for i, doc in enumerate(docs):
            pieces.append(PieceSelectionnee(
                numero=i + 1,
                titre=doc.get('title', 'Sans titre'),
                description=doc.get('content', '')[:200] + '...' if doc.get('content') else '',
                categorie=determine_document_category(doc),
                source=doc.get('source', '')
            ))
        content_to_synthesize = synthesize_selected_pieces(pieces)
    else:
        st.warning("‚ö†Ô∏è Aucun contenu √† synth√©tiser")
        return

def process_template_request(query: str, analysis: dict):
    """Traite une demande de template"""
    st.info("üìÑ Gestion des templates...")
    
    # Afficher les templates disponibles
    st.markdown("### üìÑ Templates disponibles")
    
    for template_id, template in DOCUMENT_TEMPLATES.items():
        with st.expander(f"üìÑ {template['name']}", expanded=False):
            st.markdown("**Structure:**")
            for element in template['structure']:
                st.write(f"- {element}")
            st.markdown(f"**Style:** {REDACTION_STYLES[template['style']]['description']}")
            
            if st.button(f"Utiliser ce template", key=f"use_template_{template_id}"):
                st.session_state.selected_template = template_id
                st.info(f"‚úÖ Template '{template['name']}' s√©lectionn√©")

def process_jurisprudence_request(query: str, analysis: dict):
    """Traite une demande de jurisprudence"""
    st.info("‚öñÔ∏è Recherche de jurisprudence...")
    # TODO: Impl√©menter

def process_timeline_request(query: str, analysis: dict):
    """Traite une demande de chronologie"""
    st.info("‚è±Ô∏è Cr√©ation de la chronologie...")
    # TODO: Impl√©menter

def process_mapping_request(query: str, analysis: dict):
    """Traite une demande de cartographie"""
    st.info("üó∫Ô∏è Cr√©ation de la cartographie...")
    # TODO: Impl√©menter

def process_comparison_request(query: str, analysis: dict):
    """Traite une demande de comparaison"""
    st.info("üîÑ Comparaison en cours...")
    # TODO: Impl√©menter

def process_search_request(query: str, analysis: dict):
    """Traite une demande de recherche simple"""
    
    results = []
    
    # Recherche selon le contexte
    if analysis.get('reference'):
        results = search_by_reference(f"@{analysis['reference']}")
    else:
        results = perform_search(query)
    
    # Stocker les r√©sultats
    st.session_state.search_results = results
    
    if not results:
        st.warning("‚ö†Ô∏è Aucun r√©sultat trouv√©")
    else:
        st.success(f"‚úÖ {len(results)} r√©sultats trouv√©s")

# ========================= FONCTIONS HELPER =========================

def analyze_query(query: str) -> dict:
    """Analyse une requ√™te pour extraire les informations cl√©s"""
    
    analysis = {
        'original_query': query,
        'reference': None,
        'subject_matter': None,
        'document_type': None,
        'action': None
    }
    
    # Extraire la r√©f√©rence @
    ref_match = re.search(r'@(\w+)', query)
    if ref_match:
        analysis['reference'] = ref_match.group(1)
    
    # D√©tecter le type de document
    query_lower = query.lower()
    for doc_type in ['conclusions', 'plainte', 'courrier', 'assignation', 'mise en demeure']:
        if doc_type in query_lower:
            analysis['document_type'] = doc_type
            break
    
    # D√©tecter l'action principale
    actions = {
        'r√©diger': 'redaction',
        'analyser': 'analysis',
        'rechercher': 'search',
        'comparer': 'comparison',
        'cr√©er': 'creation'
    }
    
    for keyword, action in actions.items():
        if keyword in query_lower:
            analysis['action'] = action
            break
    
    # Extraire le sujet
    # Simplification - en production, utiliser NLP
    if 'abus' in query_lower and 'biens' in query_lower:
        analysis['subject_matter'] = 'abus de biens sociaux'
    elif 'corruption' in query_lower:
        analysis['subject_matter'] = 'corruption'
    elif 'fraude' in query_lower:
        analysis['subject_matter'] = 'fraude'
    
    return analysis

def collect_relevant_documents(analysis: dict) -> List[Dict[str, Any]]:
    """Collecte les documents pertinents selon l'analyse"""
    
    documents = []
    
    # Documents locaux
    for doc_id, doc in st.session_state.get('azure_documents', {}).items():
        documents.append({
            'id': doc_id,
            'title': doc.title,
            'content': doc.content,
            'source': doc.source,
            'metadata': doc.metadata
        })
    
    # Filtrer par r√©f√©rence si pr√©sente
    if analysis.get('reference'):
        ref_lower = analysis['reference'].lower()
        documents = [d for d in documents if ref_lower in d['title'].lower() or ref_lower in d.get('source', '').lower()]
    
    return documents

def collect_available_documents(analysis: dict) -> list:
    """Collecte tous les documents disponibles"""
    documents = []
    
    # Documents locaux
    for doc_id, doc in st.session_state.get('azure_documents', {}).items():
        documents.append({
            'id': doc_id,
            'title': doc.title,
            'content': doc.content,
            'source': doc.source,
            'metadata': doc.metadata
        })
    
    return documents

def group_documents_by_category(documents: list) -> dict:
    """Groupe les documents par cat√©gorie"""
    categories = defaultdict(list)
    
    for doc in documents:
        category = determine_document_category(doc)
        categories[category].append(doc)
    
    return dict(categories)

def determine_document_category(doc: dict) -> str:
    """D√©termine la cat√©gorie d'un document"""
    title_lower = doc.get('title', '').lower()
    content_lower = doc.get('content', '')[:500].lower()
    
    category_patterns = {
        'Proc√©dure': ['plainte', 'proc√®s-verbal', 'audition'],
        'Expertise': ['expertise', 'expert', 'rapport technique'],
        'Comptabilit√©': ['bilan', 'compte', 'facture'],
        'Contrats': ['contrat', 'convention', 'accord'],
        'Correspondance': ['courrier', 'email', 'lettre']
    }
    
    for category, keywords in category_patterns.items():
        if any(kw in title_lower or kw in content_lower for kw in keywords):
            return category
    
    return 'Autres'

def calculate_piece_relevance(doc: dict, analysis: dict) -> float:
    """Calcule la pertinence d'une pi√®ce"""
    score = 0.5
    
    if analysis.get('subject_matter'):
        if analysis['subject_matter'] in doc.get('content', '').lower():
            score += 0.3
    
    if analysis.get('reference'):
        if analysis['reference'] in doc.get('title', '').lower():
            score += 0.2
    
    return min(score, 1.0)

def create_bordereau(pieces: list, analysis: dict) -> dict:
    """Cr√©e un bordereau structur√©"""
    
    bordereau = {
        'header': f"""BORDEREAU DE COMMUNICATION DE PI√àCES
AFFAIRE : {analysis.get('reference', 'N/A').upper()}
DATE : {datetime.now().strftime('%d/%m/%Y')}
NOMBRE DE PI√àCES : {len(pieces)}""",
        'pieces': pieces,
        'footer': f"""Je certifie que les pi√®ces communiqu√©es sont conformes aux originaux.
Fait le {datetime.now().strftime('%d/%m/%Y')}""",
        'metadata': {
            'created_at': datetime.now(),
            'piece_count': len(pieces),
            'reference': analysis.get('reference')
        }
    }
    
    return bordereau

def create_bordereau_document(bordereau: dict) -> bytes:
    """Cr√©e le document du bordereau"""
    content = bordereau['header'] + '\n\n'
    
    for piece in bordereau['pieces']:
        content += f"{piece.numero}. {piece.titre}\n"
        if piece.description:
            content += f"   {piece.description}\n"
        content += f"   Cat√©gorie: {piece.categorie}\n"
        if piece.date:
            content += f"   Date: {piece.date.strftime('%d/%m/%Y')}\n"
        content += "\n"
    
    content += bordereau['footer']
    
    return content.encode('utf-8')

def export_piece_list(pieces: list):
    """Exporte la liste des pi√®ces"""
    content = "LISTE DES PI√àCES S√âLECTIONN√âES\n"
    content += f"Date : {datetime.now().strftime('%d/%m/%Y %H:%M')}\n"
    content += f"Nombre de pi√®ces : {len(pieces)}\n\n"
    
    # Grouper par cat√©gorie
    by_category = defaultdict(list)
    for piece in pieces:
        by_category[piece.categorie].append(piece)
    
    for category, cat_pieces in by_category.items():
        content += f"\n{category.upper()} ({len(cat_pieces)} pi√®ces)\n"
        content += "-" * 50 + "\n"
        
        for piece in cat_pieces:
            content += f"{piece.numero}. {piece.titre}\n"
            if piece.description:
                content += f"   {piece.description}\n"
            content += "\n"
    
    # T√©l√©charger
    st.download_button(
        "üíæ T√©l√©charger la liste",
        content.encode('utf-8'),
        f"liste_pieces_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
        "text/plain"
    )

def search_by_reference(reference: str) -> list:
    """Recherche par r√©f√©rence @"""
    results = []
    ref_clean = reference.replace('@', '').strip().lower()
    
    for doc_id, doc in st.session_state.get('azure_documents', {}).items():
        if ref_clean in doc.title.lower() or ref_clean in doc.source.lower():
            results.append({
                'id': doc_id,
                'title': doc.title,
                'content': doc.content,
                'source': doc.source
            })
    
    return results

def perform_search(query: str) -> List[Dict[str, Any]]:
    """Effectue une recherche g√©n√©rale"""
    
    results = []
    query_lower = query.lower()
    query_words = query_lower.split()
    
    # Recherche locale
    for doc_id, doc in st.session_state.get('azure_documents', {}).items():
        score = 0
        content_lower = doc.content.lower()
        title_lower = doc.title.lower()
        
        for word in query_words:
            if word in title_lower:
                score += 2
            if word in content_lower:
                score += 1
        
        if score > 0:
            results.append({
                'id': doc_id,
                'title': doc.title,
                'content': doc.content,
                'source': doc.source,
                'score': score / len(query_words)
            })
    
    # Recherche Azure si disponible
    try:
        search_manager = st.session_state.get('azure_search_manager')
        if search_manager and hasattr(search_manager, 'search'):
            azure_results = search_manager.search(query)
            results.extend(azure_results)
    except:
        pass
    
    return sorted(results, key=lambda x: x.get('score', 0), reverse=True)[:50]

def clear_universal_state():
    """Efface l'√©tat de l'interface universelle"""
    keys_to_clear = [
        'universal_query', 'last_universal_query', 'current_analysis',
        'redaction_result', 'timeline_result', 'mapping_result',
        'comparison_result', 'synthesis_result', 'ai_analysis_results',
        'search_results', 'selected_pieces', 'import_files',
        'plaidoirie_result', 'preparation_client_result'
    ]
    
    for key in keys_to_clear:
        if key in st.session_state:
            del st.session_state[key]
    
    st.success("‚úÖ Interface r√©initialis√©e")
    st.rerun()

def save_current_work():
    """Sauvegarde le travail actuel"""
    work_data = {
        'timestamp': datetime.now().isoformat(),
        'query': st.session_state.get('universal_query', ''),
        'analysis': st.session_state.get('current_analysis', {}),
        'results': {}
    }
    
    # Collecter tous les r√©sultats
    result_keys = [
        'redaction_result', 'timeline_result', 'mapping_result',
        'comparison_result', 'synthesis_result', 'ai_analysis_results',
        'search_results', 'plaidoirie_result', 'preparation_client_result'
    ]
    
    for key in result_keys:
        if key in st.session_state:
            work_data['results'][key] = st.session_state[key]
    
    # Sauvegarder
    import json
    
    json_str = json.dumps(work_data, indent=2, ensure_ascii=False, default=str)
    
    st.download_button(
        "üíæ T√©l√©charger la sauvegarde",
        json_str,
        f"sauvegarde_travail_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
        "application/json",
        key="download_work_save"
    )

def show_work_statistics():
    """Affiche les statistiques du travail en cours"""
    st.info("üìä Statistiques du travail en cours")
    
    # Compter les r√©sultats
    stats = {
        'Documents': len(st.session_state.get('azure_documents', {})),
        'Pi√®ces s√©lectionn√©es': len(st.session_state.get('selected_pieces', [])),
        'Analyses': 1 if st.session_state.get('ai_analysis_results') else 0,
        'R√©dactions': 1 if st.session_state.get('redaction_result') else 0
    }
    
    cols = st.columns(len(stats))
    for i, (label, value) in enumerate(stats.items()):
        with cols[i]:
            st.metric(label, value)

def share_current_work():
    """Partage le travail actuel"""
    st.info("üîó Fonctionnalit√© de partage")
    
    # Pour l'instant, proposer l'export
    save_current_work()

def show_document_statistics(content: str):
    """Affiche les statistiques d'un document"""
    
    # Calculs
    words = content.split()
    sentences = content.split('.')
    paragraphs = content.split('\n\n')
    
    # R√©f√©rences
    law_refs = len(re.findall(r'article\s+[LR]?\s*\d+', content, re.IGNORECASE))
    
    # Affichage
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Mots", f"{len(words):,}")
        st.metric("Phrases", f"{len(sentences):,}")
    
    with col2:
        st.metric("Paragraphes", len(paragraphs))
        st.metric("Mots/phrase", f"{len(words) / max(len(sentences), 1):.1f}")
    
    with col3:
        st.metric("Articles cit√©s", law_refs)
        avg_word_length = sum(len(w) for w in words) / max(len(words), 1)
        st.metric("Longueur moy.", f"{avg_word_length:.1f} car/mot")

# ========================= FIN DU MODULE =========================

# ========================= PAGE PRINCIPALE =========================

def show_page():
    """Fonction principale de la page recherche universelle"""
    
    st.markdown("## üîç Recherche Universelle")
    
    # Barre de recherche principale
    col1, col2 = st.columns([5, 1])
    
    with col1:
        query = st.text_input(
            "Entrez votre commande ou recherche",
            placeholder="Ex: r√©diger conclusions @affaire_martin, analyser risques, importer documents...",
            key="universal_query",
            help="Utilisez @ pour r√©f√©rencer une affaire sp√©cifique"
        )
    
    with col2:
        search_button = st.button("üîç Rechercher", key="search_button", use_container_width=True)
    
    # Suggestions de commandes
    with st.expander("üí° Exemples de commandes", expanded=False):
        st.markdown("""
        **Recherche :**
        - `contrats soci√©t√© XYZ`
        - `@affaire_martin documents comptables`
        
        **Analyse :**
        - `analyser les risques @dossier_p√©nal`
        - `identifier les infractions @affaire_corruption`
        
        **R√©daction :**
        - `r√©diger conclusions d√©fense @affaire_martin abus biens sociaux`
        - `cr√©er plainte avec constitution partie civile escroquerie`
        - `r√©diger plainte contre Vinci, SOGEPROM @projet_26_05_2025`
        
        **Plaidoirie & Pr√©paration :**
        - `pr√©parer plaidoirie @affaire_martin audience correctionnelle`
        - `pr√©parer client interrogatoire @dossier_fraude`
        
        **Visualisations :**
        - `chronologie des faits @affaire_martin`
        - `cartographie des soci√©t√©s @groupe_abc`
        - `comparer les auditions @t√©moins`
        
        **Gestion :**
        - `s√©lectionner pi√®ces @dossier cat√©gorie proc√©dure`
        - `cr√©er bordereau @pi√®ces_s√©lectionn√©es`
        - `importer documents PDF`
        - `exporter analyse format word`
        - `envoyer par email @destinataire`
        """)
    
    # Menu d'actions rapides
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        if st.button("üìÑ Nouvelle r√©daction", key="quick_redaction"):
            st.session_state.universal_query = "r√©diger "
            st.session_state.process_query = True
    
    with col2:
        if st.button("ü§ñ Analyser dossier", key="quick_analysis"):
            st.session_state.universal_query = "analyser "
            st.session_state.process_query = True
    
    with col3:
        if st.button("üì• Importer", key="quick_import"):
            st.session_state.universal_query = "importer documents"
            st.session_state.process_query = True
    
    with col4:
        if st.button("üîÑ R√©initialiser", key="quick_reset"):
            clear_universal_state()
    
    # Traiter la requ√™te
    if query and (search_button or st.session_state.get('process_query', False)):
        with st.spinner("üîÑ Traitement en cours..."):
            process_universal_query(query)
    
    # Afficher les r√©sultats
    show_unified_results_tab()
    
    # R√©initialiser le flag de traitement
    if 'process_query' in st.session_state:
        st.session_state.process_query = False
    
    # Footer avec actions
    st.markdown("---")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("üíæ Sauvegarder le travail", key="save_work"):
            save_current_work()
    
    with col2:
        if st.button("üìä Afficher les statistiques", key="show_stats"):
            show_work_statistics()
    
    with col3:
        if st.button("üîó Partager", key="share_work"):
            share_current_work()

# ========================= ROUTING ET TRAITEMENT =========================

def process_universal_query(query: str):
    """Traite une requ√™te universelle et route vers la bonne fonction"""
    
    # Sauvegarder la requ√™te
    st.session_state.last_universal_query = query
    
    # Analyser la requ√™te pour d√©tecter le type
    query_lower = query.lower()
    
    # D√âTECTION POUR R√âDACTION (incluant votre cas de plainte)
    if any(word in query_lower for word in ['r√©dige', 'r√©diger', '√©crire', 'cr√©er', 'plainte', 'conclusions', 'courrier', 'assignation']):
        st.info("üìù D√©tection d'une demande de r√©daction...")
        
        # Cas sp√©cifique : plainte avec parties multiples
        if 'plainte' in query_lower:
            # Extraire les parties de la requ√™te
            parties = []
            parties_keywords = [
                'interconstruction', 'vinci', 'sogeprom', 'demathieu bard',
                'bouygues', 'eiffage', 'spie', 'leon grosse'
            ]
            
            for partie in parties_keywords:
                if partie in query_lower:
                    # Formatage correct du nom
                    if partie == 'sogeprom':
                        parties.append('SOGEPROM R√©alisations')
                    elif partie == 'demathieu bard':
                        parties.append('Demathieu Bard')
                    else:
                        parties.append(partie.title())
            
            # Extraire la r√©f√©rence
            reference = None
            if '@' in query:
                ref_match = re.search(r'@(\w+)', query)
                if ref_match:
                    reference = ref_match.group(1)
            
            # Cr√©er la demande de r√©daction
            st.session_state.redaction_request = {
                'type': 'plainte',
                'parties': parties,
                'reference': reference,
                'query': query
            }
            
            # G√©n√©rer la plainte
            generate_plainte(query, parties)
        else:
            # Autres types de r√©daction
            process_redaction_request(query, analyze_query(query))
    
    # PLAIDOIRIE
    elif any(word in query_lower for word in ['plaidoirie', 'plaider', 'audience']):
        st.info("üé§ D√©tection d'une demande de plaidoirie...")
        process_plaidoirie_request(query, analyze_query(query))
    
    # PR√âPARATION CLIENT
    elif any(word in query_lower for word in ['pr√©parer client', 'pr√©paration', 'coaching']):
        st.info("üë• D√©tection d'une demande de pr√©paration client...")
        process_preparation_client_request(query, analyze_query(query))
    
    # IMPORT
    elif any(word in query_lower for word in ['import', 'importer', 'charger', 'upload']):
        st.info("üì• D√©tection d'une demande d'import...")
        process_import_request(query, analyze_query(query))
    
    # EXPORT
    elif any(word in query_lower for word in ['export', 'exporter', 't√©l√©charger', 'download']):
        st.info("üíæ D√©tection d'une demande d'export...")
        process_export_request(query, analyze_query(query))
    
    # EMAIL
    elif any(word in query_lower for word in ['email', 'envoyer', 'mail', 'courrier √©lectronique']):
        st.info("üìß D√©tection d'une demande d'email...")
        process_email_request(query, analyze_query(query))
    
    # ANALYSE
    elif any(word in query_lower for word in ['analyser', 'analyse', '√©tudier', 'examiner']):
        st.info("ü§ñ D√©tection d'une demande d'analyse...")
        process_analysis_request(query, analyze_query(query))
    
    # PI√àCES
    elif any(word in query_lower for word in ['s√©lectionner pi√®ces', 'pi√®ces', 's√©lection']):
        st.info("üìã D√©tection d'une demande de s√©lection de pi√®ces...")
        process_piece_selection_request(query, analyze_query(query))
    
    # BORDEREAU
    elif 'bordereau' in query_lower:
        st.info("üìä D√©tection d'une demande de bordereau...")
        process_bordereau_request(query, analyze_query(query))
    
    # SYNTH√àSE
    elif any(word in query_lower for word in ['synth√®se', 'synth√©tiser', 'r√©sumer']):
        st.info("üìù D√©tection d'une demande de synth√®se...")
        process_synthesis_request(query, analyze_query(query))
    
    # TEMPLATES
    elif any(word in query_lower for word in ['template', 'mod√®le', 'gabarit']):
        st.info("üìÑ D√©tection d'une demande de template...")
        process_template_request(query, analyze_query(query))
    
    # JURISPRUDENCE
    elif any(word in query_lower for word in ['jurisprudence', 'juris', 'd√©cision', 'arr√™t']):
        st.info("‚öñÔ∏è D√©tection d'une demande de jurisprudence...")
        process_jurisprudence_request(query, analyze_query(query))
    
    # CHRONOLOGIE
    elif any(word in query_lower for word in ['chronologie', 'timeline', 'frise']):
        st.info("‚è±Ô∏è D√©tection d'une demande de chronologie...")
        process_timeline_request(query, analyze_query(query))
    
    # CARTOGRAPHIE
    elif any(word in query_lower for word in ['cartographie', 'mapping', 'carte', 'r√©seau']):
        st.info("üó∫Ô∏è D√©tection d'une demande de cartographie...")
        process_mapping_request(query, analyze_query(query))
    
    # COMPARAISON
    elif any(word in query_lower for word in ['comparer', 'comparaison', 'diff√©rences']):
        st.info("üîÑ D√©tection d'une demande de comparaison...")
        process_comparison_request(query, analyze_query(query))
    
    else:
        # Recherche simple par d√©faut
        st.info("üîç Recherche simple...")
        process_search_request(query, analyze_query(query))

# ========================= AFFICHAGE DES R√âSULTATS =========================

def show_unified_results_tab():
    """Affiche tous les types de r√©sultats dans un onglet unifi√©"""
    
    has_results = False
    
    # R√âSULTATS DE R√âDACTION (Priorit√© 1)
    if st.session_state.get('redaction_result'):
        show_redaction_results()
        has_results = True
    
    # R√âSULTATS D'ANALYSE IA (Priorit√© 2)
    elif st.session_state.get('ai_analysis_results'):
        show_ai_analysis_results()
        has_results = True
    
    # R√âSULTATS DE RECHERCHE (Priorit√© 3)
    elif st.session_state.get('search_results'):
        show_search_results()
        has_results = True
    
    # R√âSULTATS DE SYNTH√àSE (Priorit√© 4)
    elif st.session_state.get('synthesis_result'):
        show_synthesis_results()
        has_results = True
    
    # R√âSULTATS DE TIMELINE (Priorit√© 5)
    elif st.session_state.get('timeline_result'):
        show_timeline_results()
        has_results = True
    
    # Message si aucun r√©sultat
    if not has_results:
        st.info("üí° Utilisez la barre de recherche universelle pour commencer")
        
        # Suggestions d'utilisation
        st.markdown("""
        ### üöÄ Exemples de commandes
        
        **Recherche :**
        - `contrats soci√©t√© XYZ`
        - `@affaire_martin documents comptables`
        
        **Analyse :**
        - `analyser les risques @dossier_p√©nal`
        - `identifier les infractions @affaire_corruption`
        
        **R√©daction :**
        - `r√©diger conclusions d√©fense @affaire_martin`
        - `cr√©er plainte contre Vinci, SOGEPROM`
        
        **Gestion :**
        - `importer documents PDF`
        - `exporter analyse format word`
        """)

def show_redaction_results():
    """Affiche les r√©sultats de r√©daction"""
    result = st.session_state.redaction_result
    
    st.markdown("### üìù Document juridique g√©n√©r√©")
    
    # M√©tadonn√©es
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        doc_icons = {
            'conclusions': '‚öñÔ∏è Conclusions',
            'plainte': 'üìã Plainte',
            'courrier': '‚úâÔ∏è Courrier',
            'assignation': 'üìú Assignation'
        }
        st.metric("Type", doc_icons.get(result['type'], 'üìÑ Document'))
    
    with col2:
        st.metric("G√©n√©r√© par", result.get('provider', 'IA'))
    
    with col3:
        word_count = len(result['document'].split())
        st.metric("Mots", f"{word_count:,}")
    
    with col4:
        char_count = len(result['document'])
        st.metric("Caract√®res", f"{char_count:,}")
    
    # Zone d'√©dition principale
    st.markdown("#### üìÑ Contenu du document")
    
    edited_content = st.text_area(
        "Vous pouvez √©diter le document",
        value=result['document'],
        height=600,
        key="edit_redaction_main"
    )
    
    # Barre d'outils
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        if st.button("üîÑ R√©g√©n√©rer", key="regenerate_main"):
            st.session_state.process_query = True
            st.rerun()
    
    with col2:
        if st.button("üìä Statistiques", key="document_stats"):
            show_document_statistics(edited_content)
    
    with col3:
        # Export Word
        st.download_button(
            "üìÑ Word",
            edited_content.encode('utf-8'),
            f"{result['type']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.docx",
            "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
        )
    
    with col4:
        # Export texte
        st.download_button(
            "üìù Texte",
            edited_content.encode('utf-8'),
            f"{result['type']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
            "text/plain"
        )
    
    with col5:
        if st.button("üìß Envoyer", key="prepare_email_main"):
            st.session_state.pending_email = {
                'content': edited_content,
                'type': result['type']
            }

def show_ai_analysis_results():
    """Affiche les r√©sultats d'analyse IA avec v√©rification des jurisprudences"""
    results = st.session_state.ai_analysis_results
    
    if 'error' in results:
        st.error(f"‚ùå {results['error']}")
        return
    
    analysis_titles = {
        'risk_analysis': '‚ö†Ô∏è Analyse des risques',
        'compliance': '‚úÖ Analyse de conformit√©',
        'strategy': 'üéØ Analyse strat√©gique',
        'general_analysis': 'ü§ñ Analyse g√©n√©rale',
        'infractions': 'üéØ Analyse infractions √©conomiques'
    }
    
    st.markdown(f"### {analysis_titles.get(results.get('type'), 'ü§ñ Analyse IA')}")
    
    # M√©tadonn√©es
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Documents analys√©s", results.get('document_count', 0))
    with col2:
        st.metric("Type", results.get('type', 'general').replace('_', ' ').title())
    with col3:
        st.metric("G√©n√©r√© le", results.get('timestamp', datetime.now()).strftime('%H:%M'))
    
    # Contenu de l'analyse
    st.markdown("#### üìä R√©sultats de l'analyse")
    
    analysis_content = st.text_area(
        "Analyse d√©taill√©e",
        value=results.get('content', ''),
        height=600,
        key="ai_analysis_content"
    )
    
    # V√©rification des jurisprudences
    if st.checkbox("üîç V√©rifier les jurisprudences cit√©es", key="verify_juris_check"):
        verify_jurisprudences_in_analysis(analysis_content)
    
    # Actions
    col1, col2 = st.columns(2)
    
    with col1:
        st.download_button(
            "üíæ T√©l√©charger",
            analysis_content.encode('utf-8'),
            f"analyse_{results.get('type', 'general')}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
            "text/plain"
        )
    
    with col2:
        if st.button("üîÑ Approfondir", key="deepen_analysis"):
            st.session_state.pending_deepen_analysis = True

def show_search_results():
    """Affiche les r√©sultats de recherche"""
    results = st.session_state.search_results
    
    st.markdown(f"### üîç R√©sultats de recherche ({len(results)} documents)")
    
    if not results:
        st.info("Aucun r√©sultat trouv√©")
        return
    
    # Options d'affichage
    col1, col2 = st.columns(2)
    
    with col1:
        sort_by = st.selectbox(
            "Trier par",
            ["Pertinence", "Titre", "Date", "Source"],
            key="sort_search_results"
        )
    
    with col2:
        view_mode = st.radio(
            "Affichage",
            ["Compact", "D√©taill√©"],
            key="view_mode_search",
            horizontal=True
        )
    
    # Afficher les r√©sultats
    for i, result in enumerate(results[:20], 1):  # Limiter √† 20
        with st.container():
            if view_mode == "Compact":
                st.markdown(f"**{i}. {result.get('title', 'Sans titre')}**")
                st.caption(f"Source: {result.get('source', 'N/A')} | Score: {result.get('score', 0):.0%}")
            else:
                st.markdown(f"**{i}. {result.get('title', 'Sans titre')}**")
                st.caption(f"Source: {result.get('source', 'N/A')} | Score: {result.get('score', 0):.0%}")
                
                # Extrait
                content = result.get('content', '')
                if content:
                    st.text_area(
                        "Extrait",
                        value=content[:500] + '...' if len(content) > 500 else content,
                        height=150,
                        key=f"extract_{i}",
                        disabled=True
                    )
            
            st.divider()

def show_synthesis_results():
    """Affiche les r√©sultats de synth√®se"""
    result = st.session_state.synthesis_result
    
    if 'error' in result:
        st.error(f"‚ùå {result['error']}")
        return
    
    st.markdown("### üìù Synth√®se des documents")
    
    # M√©tadonn√©es
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Pi√®ces analys√©es", result.get('piece_count', 0))
    with col2:
        st.metric("Cat√©gories", len(result.get('categories', [])))
    with col3:
        st.metric("G√©n√©r√© le", result.get('timestamp', datetime.now()).strftime('%H:%M'))
    
    # Contenu
    synthesis_content = st.text_area(
        "Contenu de la synth√®se",
        value=result.get('content', ''),
        height=600,
        key="synthesis_content_display"
    )
    
    # Actions
    if st.download_button(
        "üíæ T√©l√©charger",
        synthesis_content.encode('utf-8'),
        f"synthese_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
        "text/plain"
    ):
        st.success("‚úÖ Synth√®se t√©l√©charg√©e")

def show_timeline_results():
    """Affiche les r√©sultats de chronologie"""
    result = st.session_state.timeline_result
    
    st.markdown(f"### ‚è±Ô∏è Chronologie")
    
    # Affichage simple
    for event in result.get('events', []):
        col1, col2 = st.columns([1, 4])
        with col1:
            st.write(f"**{event.get('date', 'N/A')}**")
        with col2:
            st.write(event.get('description', ''))
            if event.get('actors'):
                st.caption(f"üë• {', '.join(event['actors'])}")

# ========================= GESTION DES PI√àCES =========================

def process_piece_selection_request(query: str, analysis: dict):
    """Traite une demande de s√©lection de pi√®ces"""
    
    st.markdown("### üìã S√©lection de pi√®ces")
    
    # Collecter les documents disponibles
    available_docs = collect_available_documents(analysis)
    
    if not available_docs:
        st.warning("‚ö†Ô∏è Aucun document disponible")
        return
    
    # Grouper par cat√©gorie
    categories = group_documents_by_category(available_docs)
    
    # Interface de s√©lection
    selected_pieces = []
    
    for category, docs in categories.items():
        with st.expander(f"üìÅ {category} ({len(docs)} documents)", expanded=True):
            select_all = st.checkbox(f"Tout s√©lectionner - {category}", key=f"select_all_{category}")
            
            for doc in docs:
                is_selected = st.checkbox(
                    f"üìÑ {doc['title']}",
                    value=select_all,
                    key=f"select_doc_{doc['id']}",
                    help=f"Source: {doc.get('source', 'N/A')}"
                )
                
                if is_selected:
                    selected_pieces.append(PieceSelectionnee(
                        numero=len(selected_pieces) + 1,
                        titre=doc['title'],
                        description=doc.get('description', ''),
                        categorie=category,
                        date=doc.get('date'),
                        source=doc.get('source', ''),
                        pertinence=calculate_piece_relevance(doc, analysis)
                    ))
    
    # Sauvegarder la s√©lection
    st.session_state.selected_pieces = selected_pieces
    
    # Actions
    if selected_pieces:
        st.success(f"‚úÖ {len(selected_pieces)} pi√®ces s√©lectionn√©es")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("üìä Cr√©er bordereau", key="create_bordereau_from_selection"):
                process_bordereau_request(query, analysis)
        
        with col2:
            if st.button("üìÑ Synth√©tiser", key="synthesize_selection"):
                synthesize_selected_pieces(selected_pieces)
        
        with col3:
            if st.button("üì§ Exporter liste", key="export_piece_list"):
                export_piece_list(selected_pieces)

def process_bordereau_request(query: str, analysis: dict):
    """Traite une demande de cr√©ation de bordereau"""
    
    pieces = st.session_state.get('selected_pieces', [])
    
    if not pieces:
        st.warning("‚ö†Ô∏è Aucune pi√®ce s√©lectionn√©e pour le bordereau")
        return
    
    # Cr√©er le bordereau
    bordereau = create_bordereau(pieces, analysis)
    
    # Afficher
    st.markdown("### üìä Bordereau de communication de pi√®ces")
    
    # En-t√™te
    st.text_area(
        "En-t√™te du bordereau",
        value=bordereau['header'],
        height=150,
        key="bordereau_header"
    )
    
    # Table des pi√®ces
    try:
        df = pd.DataFrame([
            {
                'N¬∞': p.numero,
                'Titre': p.titre,
                'Description': p.description,
                'Cat√©gorie': p.categorie,
                'Date': p.date.strftime('%d/%m/%Y') if p.date else 'N/A'
            }
            for p in pieces
        ])
        
        st.dataframe(df, use_container_width=True)
    except:
        # Affichage sans pandas
        for piece in pieces:
            st.write(f"**{piece.numero}.** {piece.titre}")
            if piece.description:
                st.caption(piece.description)
    
    # Actions
    col1, col2 = st.columns(2)
    
    with col1:
        st.download_button(
            "üíæ T√©l√©charger bordereau",
            create_bordereau_document(bordereau),
            f"bordereau_{datetime.now().strftime('%Y%m%d_%H%M%S')}.docx",
            "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
        )
    
    with col2:
        if st.button("üìß Envoyer bordereau", key="send_bordereau"):
            st.session_state.pending_email = {
                'content': create_bordereau_document(bordereau),
                'type': 'bordereau'
            }

def synthesize_selected_pieces(pieces: list):
    """Synth√©tise les pi√®ces s√©lectionn√©es"""
    
    try:
        llm_manager = MultiLLMManager()
        
        if not llm_manager.clients:
            return {'error': 'Aucune IA disponible'}
        
        # Construire le contexte
        context = "PI√àCES √Ä SYNTH√âTISER:\n\n"
        
        for piece in pieces[:20]:  # Limiter
            context += f"Pi√®ce {piece.numero}: {piece.titre}\n"
            context += f"Cat√©gorie: {piece.categorie}\n"
            if piece.description:
                context += f"Description: {piece.description}\n"
            context += "\n"
        
        # Prompt
        synthesis_prompt = f"""{context}
Cr√©e une synth√®se structur√©e de ces pi√®ces.
La synth√®se doit inclure:
1. Vue d'ensemble des pi√®ces
2. Points cl√©s par cat√©gorie
3. Chronologie si applicable
4. Points d'attention juridiques
5. Recommandations"""
        
        provider = list(llm_manager.clients.keys())[0]
        response = llm_manager.query_single_llm(
            provider,
            synthesis_prompt,
            "Tu es un expert en analyse de documents juridiques."
        )
        
        if response['success']:
            synthesis_result = {
                'content': response['response'],
                'piece_count': len(pieces),
                'categories': list(set(p.categorie for p in pieces)),
                'timestamp': datetime.now()
            }
            st.session_state.synthesis_result = synthesis_result
            return synthesis_result
        else:
            return {'error': '√âchec de la synth√®se'}
            
    except Exception as e:
        return {'error': f'Erreur synth√®se: {str(e)}'}

# ========================= ANALYSE IA =========================

def process_analysis_request(query: str, analysis: dict):
    """Traite une demande d'analyse IA avec support des infractions"""
    
    # Collecter les documents pertinents
    documents = collect_relevant_documents(analysis)
    
    if not documents:
        st.warning("‚ö†Ô∏è Aucun document trouv√© pour l'analyse")
        return
    
    # Configuration de l'analyse
    st.markdown("### ‚öôÔ∏è Configuration de l'analyse")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Type d'infraction si pertinent
        if any(word in query.lower() for word in ['infraction', 'd√©lit', 'crime']):
            infractions_list = [inf.value for inf in InfractionAffaires]
            
            st.session_state.infraction = st.text_input(
                "Type d'infraction",
                placeholder="Ex: Abus de biens sociaux, corruption, fraude fiscale...",
                key="infraction_input",
                help="Saisissez librement l'infraction"
            )
            
            if not st.session_state.infraction:
                st.info("üí° Suggestions : " + ", ".join(infractions_list[:5]) + "...")
        
        # Client
        st.session_state.client_nom = st.text_input(
            "Nom du client",
            placeholder="Personne physique ou morale",
            key="client_nom_analyse"
        )
    
    with col2:
        # Type d'analyse
        analysis_type = st.selectbox(
            "Type d'analyse",
            ["Analyse g√©n√©rale", "Risques juridiques", "Conformit√©", "Strat√©gie", "Infractions"],
            key="analysis_type_select"
        )
    
    # Lancer l'analyse
    if st.button("üöÄ Lancer l'analyse", type="primary", key="launch_analysis"):
        with st.spinner("ü§ñ Analyse en cours..."):
            if analysis_type == "Risques juridiques":
                results = analyze_legal_risks(documents, query)
            elif analysis_type == "Conformit√©":
                results = analyze_compliance(documents, query)
            elif analysis_type == "Strat√©gie":
                results = analyze_strategy(documents, query)
            elif analysis_type == "Infractions":
                results = analyze_infractions(documents, query)
            else:
                results = perform_general_analysis(documents, query)
        
        # Stocker les r√©sultats
        st.session_state.ai_analysis_results = results
        st.rerun()

def analyze_infractions(documents: List[Dict[str, Any]], query: str) -> dict:
    """Analyse sp√©cifique des infractions √©conomiques"""
    
    llm_manager = MultiLLMManager()
    if not llm_manager.clients:
        return {'error': 'Aucune IA disponible'}
    
    # Construire le prompt sp√©cialis√©
    infraction_prompt = f"""Analyse ces documents pour identifier des infractions √©conomiques.
Client: {st.session_state.get('client_nom', 'Non sp√©cifi√©')}
Infraction suspect√©e: {st.session_state.get('infraction', '√Ä d√©terminer')}

DOCUMENTS:
{chr(10).join([f"- {doc.get('title', 'Sans titre')}: {doc.get('content', '')[:500]}..." for doc in documents[:10]])}

Identifie:
1. INFRACTIONS CARACT√âRIS√âES
   - Qualification juridique pr√©cise
   - Articles du Code p√©nal applicables
   - √âl√©ments constitutifs pr√©sents/absents
   
2. RESPONSABILIT√âS
   - Personnes physiques impliqu√©es
   - Responsabilit√© des personnes morales
   
3. SANCTIONS ENCOURUES
   - Peines principales
   - Peines compl√©mentaires
   - Prescription

4. √âL√âMENTS DE PREUVE
   - Preuves mat√©rielles identifi√©es
   - T√©moignages pertinents
   - Documents cl√©s

5. STRAT√âGIE DE D√âFENSE
   - Points faibles de l'accusation
   - Arguments de d√©fense possibles
   - Jurisprudences favorables"""
    
    try:
        provider = list(llm_manager.clients.keys())[0]
        response = llm_manager.query_single_llm(
            provider,
            infraction_prompt,
            "Tu es un avocat expert en droit p√©nal des affaires."
        )
        
        if response['success']:
            return {
                'type': 'infractions',
                'content': response['response'],
                'document_count': len(documents),
                'timestamp': datetime.now(),
                'query': query,
                'infraction': st.session_state.get('infraction', 'Non sp√©cifi√©e')
            }
    except Exception as e:
        return {'error': f'Erreur analyse infractions: {str(e)}'}

def analyze_legal_risks(documents: List[Dict[str, Any]], query: str) -> dict:
    """Analyse les risques juridiques"""
    
    llm_manager = MultiLLMManager()
    if not llm_manager.clients:
        return {'error': 'Aucune IA disponible'}
    
    # Construire le prompt
    risk_prompt = f"""Analyse les risques juridiques dans ces documents.
DOCUMENTS:
{chr(10).join([f"- {doc.get('title', 'Sans titre')}: {doc.get('content', '')[:500]}..." for doc in documents[:10]])}
QUESTION: {query}
Identifie et √©value:
1. RISQUES P√âNAUX
2. RISQUES CIVILS
3. RISQUES R√âPUTATIONNELS
4. RECOMMANDATIONS
Format structur√© avec √©valuation pr√©cise."""
    
    try:
        provider = list(llm_manager.clients.keys())[0]
        response = llm_manager.query_single_llm(
            provider,
            risk_prompt,
            "Tu es un expert en analyse de risques juridiques."
        )
        
        if response['success']:
            return {
                'type': 'risk_analysis',
                'content': response['response'],
                'document_count': len(documents),
                'timestamp': datetime.now(),
                'query': query
            }
    except Exception as e:
        return {'error': f'Erreur analyse: {str(e)}'}

def analyze_compliance(documents: List[Dict[str, Any]], query: str) -> dict:
    """Analyse de conformit√©"""
    
    llm_manager = MultiLLMManager()
    if not llm_manager.clients:
        return {'error': 'Aucune IA disponible'}
    
    compliance_prompt = f"""Analyse la conformit√© l√©gale et r√©glementaire.
DOCUMENTS:
{chr(10).join([f"- {doc.get('title', 'Sans titre')}: {doc.get('content', '')[:500]}..." for doc in documents[:10]])}
QUESTION: {query}
V√©rifie:
1. CONFORMIT√â L√âGALE
2. CONFORMIT√â R√âGLEMENTAIRE
3. MANQUEMENTS IDENTIFI√âS
4. ACTIONS CORRECTIVES
5. RECOMMANDATIONS"""
    
    try:
        provider = list(llm_manager.clients.keys())[0]
        response = llm_manager.query_single_llm(
            provider,
            compliance_prompt,
            "Tu es un expert en conformit√© juridique."
        )
        
        if response['success']:
            return {
                'type': 'compliance',
                'content': response['response'],
                'document_count': len(documents),
                'timestamp': datetime.now(),
                'query': query
            }
    except Exception as e:
        return {'error': f'Erreur analyse conformit√©: {str(e)}'}

def analyze_strategy(documents: List[Dict[str, Any]], query: str) -> dict:
    """Analyse strat√©gique"""
    
    llm_manager = MultiLLMManager()
    if not llm_manager.clients:
        return {'error': 'Aucune IA disponible'}
    
    strategy_prompt = f"""D√©veloppe une strat√©gie juridique bas√©e sur ces documents.
DOCUMENTS:
{chr(10).join([f"- {doc.get('title', 'Sans titre')}: {doc.get('content', '')[:500]}..." for doc in documents[:10]])}
QUESTION: {query}
√âlabore:
1. ANALYSE DE LA SITUATION
2. OPTIONS STRAT√âGIQUES
3. AVANTAGES/INCONV√âNIENTS
4. STRAT√âGIE RECOMMAND√âE
5. PLAN D'ACTION"""
    
    try:
        provider = list(llm_manager.clients.keys())[0]
        response = llm_manager.query_single_llm(
            provider,
            strategy_prompt,
            "Tu es un strat√®ge juridique exp√©riment√©."
        )
        
        if response['success']:
            return {
                'type': 'strategy',
                'content': response['response'],
                'document_count': len(documents),
                'timestamp': datetime.now(),
                'query': query
            }
    except Exception as e:
        return {'error': f'Erreur analyse strat√©gique: {str(e)}'}

def perform_general_analysis(documents: List[Dict[str, Any]], query: str) -> dict:
    """Analyse g√©n√©rale des documents"""
    
    llm_manager = MultiLLMManager()
    if not llm_manager.clients:
        return {'error': 'Aucune IA disponible'}
    
    general_prompt = f"""Analyse ces documents pour r√©pondre √† la question.
DOCUMENTS:
{chr(10).join([f"- {doc.get('title', 'Sans titre')}: {doc.get('content', '')[:500]}..." for doc in documents[:10]])}
QUESTION: {query}
Fournis une analyse compl√®te et structur√©e."""
    
    try:
        provider = list(llm_manager.clients.keys())[0]
        response = llm_manager.query_single_llm(
            provider,
            general_prompt,
            "Tu es un expert en analyse juridique."
        )
        
        if response['success']:
            return {
                'type': 'general_analysis',
                'content': response['response'],
                'document_count': len(documents),
                'timestamp': datetime.now(),
                'query': query
            }
    except Exception as e:
        return {'error': f'Erreur analyse: {str(e)}'}

def verify_jurisprudences_in_analysis(content: str):
    """V√©rifie les jurisprudences cit√©es dans l'analyse"""
    st.markdown("### üîç V√©rification des jurisprudences cit√©es")
    
    try:
        # Cr√©er le v√©rificateur
        verifier = JurisprudenceVerifier()
        
        # Afficher l'interface de v√©rification
        verification_results = display_jurisprudence_verification(content, verifier)
        
        # Stocker les r√©sultats de v√©rification
        if verification_results:
            st.session_state.jurisprudence_verification = verification_results
            
            # R√©sum√©
            verified_count = sum(1 for r in verification_results if r.status == 'verified')
            total_count = len(verification_results)
            
            col1, col2 = st.columns(2)
            with col1:
                st.metric("Jurisprudences v√©rifi√©es", f"{verified_count}/{total_count}")
            
            with col2:
                confidence = (verified_count / total_count * 100) if total_count > 0 else 0
                st.metric("Fiabilit√© des sources", f"{confidence:.0f}%")
        
        return verification_results
    except:
        st.warning("‚ö†Ô∏è V√©rificateur de jurisprudences non disponible")
        return []

# ========================= FONCTIONS DE TRAITEMENT =========================

def process_redaction_request(query: str, analysis: dict):
    """Traite une demande de r√©daction"""
    # Import depuis le module de r√©daction
    st.info("üìù Traitement de la demande de r√©daction...")
    # TODO: Impl√©menter ou importer depuis recherche_redaction

def generate_plainte(query: str, parties: list):
    """G√©n√®re une plainte avec les parties sp√©cifi√©es"""
    
    llm_manager = MultiLLMManager()
    if not llm_manager.clients:
        st.error("‚ùå Aucune IA disponible")
        return
    
    # Construire le prompt
    plainte_prompt = f"""R√©dige une plainte p√©nale professionnelle.

DEMANDEUR: {st.session_state.get('client_nom', 'Le plaignant')}
PARTIES MISES EN CAUSE: {', '.join(parties)}
CONTEXTE: {query}

Structure la plainte avec:
1. En-t√™te (Tribunal comp√©tent, identit√© du plaignant)
2. EXPOS√â DES FAITS (chronologique et d√©taill√©)
3. QUALIFICATION JURIDIQUE (infractions caract√©ris√©es)
4. PR√âJUDICES SUBIS (moral, mat√©riel, financier)
5. DEMANDES (poursuites p√©nales, dommages-int√©r√™ts)
6. PI√àCES JOINTES

Style: Formel, juridique, factuel."""
    
    try:
        provider = list(llm_manager.clients.keys())[0]
        response = llm_manager.query_single_llm(
            provider,
            plainte_prompt,
            "Tu es un avocat expert en r√©daction de plaintes p√©nales."
        )
        
        if response['success']:
            st.session_state.redaction_result = {
                'type': 'plainte',
                'document': response['response'],
                'provider': provider.value,
                'timestamp': datetime.now(),
                'parties': parties
            }
            st.rerun()
    except Exception as e:
        st.error(f"‚ùå Erreur g√©n√©ration: {str(e)}")

def process_plaidoirie_request(query: str, analysis: dict):
    """Traite une demande de plaidoirie"""
    st.info("üé§ Pr√©paration de plaidoirie...")
    # TODO: Impl√©menter

def process_preparation_client_request(query: str, analysis: dict):
    """Traite une demande de pr√©paration client"""
    st.info("üë• Pr√©paration du client...")
    # TODO: Impl√©menter

def process_import_request(query: str, analysis: dict):
    """Traite une demande d'import"""
    st.info("üì• Import de documents...")
    # TODO: Impl√©menter

def process_export_request(query: str, analysis: dict):
    """Traite une demande d'export"""
    st.info("üíæ Export en cours...")
    # TODO: Impl√©menter

def process_email_request(query: str, analysis: dict):
    """Traite une demande d'email"""
    st.info("üìß Pr√©paration de l'email...")
    # TODO: Impl√©menter

def process_synthesis_request(query: str, analysis: dict):
    """Traite une demande de synth√®se"""
    
    # D√©terminer la source
    if st.session_state.get('selected_pieces'):
        content_to_synthesize = synthesize_selected_pieces(st.session_state.selected_pieces)
    elif analysis.get('reference'):
        docs = search_by_reference(f"@{analysis['reference']}")
        pieces = []
        for i, doc in enumerate(docs):
            pieces.append(PieceSelectionnee(
                numero=i + 1,
                titre=doc.get('title', 'Sans titre'),
                description=doc.get('content', '')[:200] + '...' if doc.get('content') else '',
                categorie=determine_document_category(doc),
                source=doc.get('source', '')
            ))
        content_to_synthesize = synthesize_selected_pieces(pieces)
    else:
        st.warning("‚ö†Ô∏è Aucun contenu √† synth√©tiser")
        return

def process_template_request(query: str, analysis: dict):
    """Traite une demande de template"""
    st.info("üìÑ Gestion des templates...")
    
    # Afficher les templates disponibles
    st.markdown("### üìÑ Templates disponibles")
    
    for template_id, template in DOCUMENT_TEMPLATES.items():
        with st.expander(f"üìÑ {template['name']}", expanded=False):
            st.markdown("**Structure:**")
            for element in template['structure']:
                st.write(f"- {element}")
            st.markdown(f"**Style:** {REDACTION_STYLES[template['style']]['description']}")
            
            if st.button(f"Utiliser ce template", key=f"use_template_{template_id}"):
                st.session_state.selected_template = template_id
                st.info(f"‚úÖ Template '{template['name']}' s√©lectionn√©")

def process_jurisprudence_request(query: str, analysis: dict):
    """Traite une demande de jurisprudence"""
    st.info("‚öñÔ∏è Recherche de jurisprudence...")
    # TODO: Impl√©menter

def process_timeline_request(query: str, analysis: dict):
    """Traite une demande de chronologie"""
    st.info("‚è±Ô∏è Cr√©ation de la chronologie...")
    # TODO: Impl√©menter

def process_mapping_request(query: str, analysis: dict):
    """Traite une demande de cartographie"""
    st.info("üó∫Ô∏è Cr√©ation de la cartographie...")
    # TODO: Impl√©menter

def process_comparison_request(query: str, analysis: dict):
    """Traite une demande de comparaison"""
    st.info("üîÑ Comparaison en cours...")
    # TODO: Impl√©menter

def process_search_request(query: str, analysis: dict):
    """Traite une demande de recherche simple"""
    
    results = []
    
    # Recherche selon le contexte
    if analysis.get('reference'):
        results = search_by_reference(f"@{analysis['reference']}")
    else:
        results = perform_search(query)
    
    # Stocker les r√©sultats
    st.session_state.search_results = results
    
    if not results:
        st.warning("‚ö†Ô∏è Aucun r√©sultat trouv√©")
    else:
        st.success(f"‚úÖ {len(results)} r√©sultats trouv√©s")

# ========================= FONCTIONS HELPER =========================

def analyze_query(query: str) -> dict:
    """Analyse une requ√™te pour extraire les informations cl√©s"""
    
    analysis = {
        'original_query': query,
        'reference': None,
        'subject_matter': None,
        'document_type': None,
        'action': None
    }
    
    # Extraire la r√©f√©rence @
    ref_match = re.search(r'@(\w+)', query)
    if ref_match:
        analysis['reference'] = ref_match.group(1)
    
    # D√©tecter le type de document
    query_lower = query.lower()
    for doc_type in ['conclusions', 'plainte', 'courrier', 'assignation', 'mise en demeure']:
        if doc_type in query_lower:
            analysis['document_type'] = doc_type
            break
    
    # D√©tecter l'action principale
    actions = {
        'r√©diger': 'redaction',
        'analyser': 'analysis',
        'rechercher': 'search',
        'comparer': 'comparison',
        'cr√©er': 'creation'
    }
    
    for keyword, action in actions.items():
        if keyword in query_lower:
            analysis['action'] = action
            break
    
    # Extraire le sujet
    # Simplification - en production, utiliser NLP
    if 'abus' in query_lower and 'biens' in query_lower:
        analysis['subject_matter'] = 'abus de biens sociaux'
    elif 'corruption' in query_lower:
        analysis['subject_matter'] = 'corruption'
    elif 'fraude' in query_lower:
        analysis['subject_matter'] = 'fraude'
    
    return analysis

def collect_relevant_documents(analysis: dict) -> List[Dict[str, Any]]:
    """Collecte les documents pertinents selon l'analyse"""
    
    documents = []
    
    # Documents locaux
    for doc_id, doc in st.session_state.get('azure_documents', {}).items():
        documents.append({
            'id': doc_id,
            'title': doc.title,
            'content': doc.content,
            'source': doc.source,
            'metadata': doc.metadata
        })
    
    # Filtrer par r√©f√©rence si pr√©sente
    if analysis.get('reference'):
        ref_lower = analysis['reference'].lower()
        documents = [d for d in documents if ref_lower in d['title'].lower() or ref_lower in d.get('source', '').lower()]
    
    return documents

def collect_available_documents(analysis: dict) -> list:
    """Collecte tous les documents disponibles"""
    documents = []
    
    # Documents locaux
    for doc_id, doc in st.session_state.get('azure_documents', {}).items():
        documents.append({
            'id': doc_id,
            'title': doc.title,
            'content': doc.content,
            'source': doc.source,
            'metadata': doc.metadata
        })
    
    return documents

def group_documents_by_category(documents: list) -> dict:
    """Groupe les documents par cat√©gorie"""
    categories = defaultdict(list)
    
    for doc in documents:
        category = determine_document_category(doc)
        categories[category].append(doc)
    
    return dict(categories)

def determine_document_category(doc: dict) -> str:
    """D√©termine la cat√©gorie d'un document"""
    title_lower = doc.get('title', '').lower()
    content_lower = doc.get('content', '')[:500].lower()
    
    category_patterns = {
        'Proc√©dure': ['plainte', 'proc√®s-verbal', 'audition'],
        'Expertise': ['expertise', 'expert', 'rapport technique'],
        'Comptabilit√©': ['bilan', 'compte', 'facture'],
        'Contrats': ['contrat', 'convention', 'accord'],
        'Correspondance': ['courrier', 'email', 'lettre']
    }
    
    for category, keywords in category_patterns.items():
        if any(kw in title_lower or kw in content_lower for kw in keywords):
            return category
    
    return 'Autres'

def calculate_piece_relevance(doc: dict, analysis: dict) -> float:
    """Calcule la pertinence d'une pi√®ce"""
    score = 0.5
    
    if analysis.get('subject_matter'):
        if analysis['subject_matter'] in doc.get('content', '').lower():
            score += 0.3
    
    if analysis.get('reference'):
        if analysis['reference'] in doc.get('title', '').lower():
            score += 0.2
    
    return min(score, 1.0)

def create_bordereau(pieces: list, analysis: dict) -> dict:
    """Cr√©e un bordereau structur√©"""
    
    bordereau = {
        'header': f"""BORDEREAU DE COMMUNICATION DE PI√àCES
AFFAIRE : {analysis.get('reference', 'N/A').upper()}
DATE : {datetime.now().strftime('%d/%m/%Y')}
NOMBRE DE PI√àCES : {len(pieces)}""",
        'pieces': pieces,
        'footer': f"""Je certifie que les pi√®ces communiqu√©es sont conformes aux originaux.
Fait le {datetime.now().strftime('%d/%m/%Y')}""",
        'metadata': {
            'created_at': datetime.now(),
            'piece_count': len(pieces),
            'reference': analysis.get('reference')
        }
    }
    
    return bordereau

def create_bordereau_document(bordereau: dict) -> bytes:
    """Cr√©e le document du bordereau"""
    content = bordereau['header'] + '\n\n'
    
    for piece in bordereau['pieces']:
        content += f"{piece.numero}. {piece.titre}\n"
        if piece.description:
            content += f"   {piece.description}\n"
        content += f"   Cat√©gorie: {piece.categorie}\n"
        if piece.date:
            content += f"   Date: {piece.date.strftime('%d/%m/%Y')}\n"
        content += "\n"
    
    content += bordereau['footer']
    
    return content.encode('utf-8')

def export_piece_list(pieces: list):
    """Exporte la liste des pi√®ces"""
    content = "LISTE DES PI√àCES S√âLECTIONN√âES\n"
    content += f"Date : {datetime.now().strftime('%d/%m/%Y %H:%M')}\n"
    content += f"Nombre de pi√®ces : {len(pieces)}\n\n"
    
    # Grouper par cat√©gorie
    by_category = defaultdict(list)
    for piece in pieces:
        by_category[piece.categorie].append(piece)
    
    for category, cat_pieces in by_category.items():
        content += f"\n{category.upper()} ({len(cat_pieces)} pi√®ces)\n"
        content += "-" * 50 + "\n"
        
        for piece in cat_pieces:
            content += f"{piece.numero}. {piece.titre}\n"
            if piece.description:
                content += f"   {piece.description}\n"
            content += "\n"
    
    # T√©l√©charger
    st.download_button(
        "üíæ T√©l√©charger la liste",
        content.encode('utf-8'),
        f"liste_pieces_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
        "text/plain"
    )

def search_by_reference(reference: str) -> list:
    """Recherche par r√©f√©rence @"""
    results = []
    ref_clean = reference.replace('@', '').strip().lower()
    
    for doc_id, doc in st.session_state.get('azure_documents', {}).items():
        if ref_clean in doc.title.lower() or ref_clean in doc.source.lower():
            results.append({
                'id': doc_id,
                'title': doc.title,
                'content': doc.content,
                'source': doc.source
            })
    
    return results

def perform_search(query: str) -> List[Dict[str, Any]]:
    """Effectue une recherche g√©n√©rale"""
    
    results = []
    query_lower = query.lower()
    query_words = query_lower.split()
    
    # Recherche locale
    for doc_id, doc in st.session_state.get('azure_documents', {}).items():
        score = 0
        content_lower = doc.content.lower()
        title_lower = doc.title.lower()
        
        for word in query_words:
            if word in title_lower:
                score += 2
            if word in content_lower:
                score += 1
        
        if score > 0:
            results.append({
                'id': doc_id,
                'title': doc.title,
                'content': doc.content,
                'source': doc.source,
                'score': score / len(query_words)
            })
    
    # Recherche Azure si disponible
    try:
        search_manager = st.session_state.get('azure_search_manager')
        if search_manager and search_manager.is_connected():
            azure_results = search_manager.search(query)
            results.extend(azure_results)
    except:
        pass
    
    return sorted(results, key=lambda x: x.get('score', 0), reverse=True)[:50]

def clear_universal_state():
    """Efface l'√©tat de l'interface universelle"""
    keys_to_clear = [
        'universal_query', 'last_universal_query', 'current_analysis',
        'redaction_result', 'timeline_result', 'mapping_result',
        'comparison_result', 'synthesis_result', 'ai_analysis_results',
        'search_results', 'selected_pieces', 'import_files',
        'plaidoirie_result', 'preparation_client_result'
    ]
    
    for key in keys_to_clear:
        if key in st.session_state:
            del st.session_state[key]
    
    st.success("‚úÖ Interface r√©initialis√©e")
    st.rerun()

def save_current_work():
    """Sauvegarde le travail actuel"""
    work_data = {
        'timestamp': datetime.now().isoformat(),
        'query': st.session_state.get('universal_query', ''),
        'analysis': st.session_state.get('current_analysis', {}),
        'results': {}
    }
    
    # Collecter tous les r√©sultats
    result_keys = [
        'redaction_result', 'timeline_result', 'mapping_result',
        'comparison_result', 'synthesis_result', 'ai_analysis_results',
        'search_results', 'plaidoirie_result', 'preparation_client_result'
    ]
    
    for key in result_keys:
        if key in st.session_state:
            work_data['results'][key] = st.session_state[key]
    
    # Sauvegarder
    import json
    
    json_str = json.dumps(work_data, indent=2, ensure_ascii=False, default=str)
    
    st.download_button(
        "üíæ T√©l√©charger la sauvegarde",
        json_str,
        f"sauvegarde_travail_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
        "application/json",
        key="download_work_save"
    )

def show_work_statistics():
    """Affiche les statistiques du travail en cours"""
    st.info("üìä Statistiques du travail en cours")
    
    # Compter les r√©sultats
    stats = {
        'Documents': len(st.session_state.get('azure_documents', {})),
        'Pi√®ces s√©lectionn√©es': len(st.session_state.get('selected_pieces', [])),
        'Analyses': 1 if st.session_state.get('ai_analysis_results') else 0,
        'R√©dactions': 1 if st.session_state.get('redaction_result') else 0
    }
    
    cols = st.columns(len(stats))
    for i, (label, value) in enumerate(stats.items()):
        with cols[i]:
            st.metric(label, value)

def share_current_work():
    """Partage le travail actuel"""
    st.info("üîó Fonctionnalit√© de partage")
    
    # Pour l'instant, proposer l'export
    save_current_work()

def show_document_statistics(content: str):
    """Affiche les statistiques d'un document"""
    
    # Calculs
    words = content.split()
    sentences = content.split('.')
    paragraphs = content.split('\n\n')
    
    # R√©f√©rences
    law_refs = len(re.findall(r'article\s+[LR]?\s*\d+', content, re.IGNORECASE))
    
    # Affichage
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Mots", f"{len(words):,}")
        st.metric("Phrases", f"{len(sentences):,}")
    
    with col2:
        st.metric("Paragraphes", len(paragraphs))
        st.metric("Mots/phrase", f"{len(words) / max(len(sentences), 1):.1f}")
    
    with col3:
        st.metric("Articles cit√©s", law_refs)
        avg_word_length = sum(len(w) for w in words) / max(len(words), 1)
        st.metric("Longueur moy.", f"{avg_word_length:.1f} car/mot")

# ========================= FIN DU MODULE =========================