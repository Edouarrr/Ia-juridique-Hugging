# modules/recherche.py
"""Module de recherche unifi√© avec toutes les fonctionnalit√©s avanc√©es int√©gr√©es"""

import streamlit as st
import asyncio
import re
import html
from datetime import datetime
from typing import Dict, Any, Optional, List, Tuple
from difflib import SequenceMatcher

# ========================= IMPORTS CENTRALIS√âS =========================

# Import du service de recherche depuis les managers
try:
    from managers import UniversalSearchService, get_universal_search_service
    SEARCH_SERVICE_AVAILABLE = True
except ImportError:
    SEARCH_SERVICE_AVAILABLE = False

# Import des dataclasses et configurations
from modules.dataclasses import (
    Document, DocumentJuridique, Partie, TypePartie, PhaseProcedure,
    TypeDocument, TypeAnalyse, QueryAnalysis, InfractionAffaires,
    PieceSelectionnee, BordereauPieces, collect_available_documents,
    group_documents_by_category, determine_document_category,
    calculate_piece_relevance, create_bordereau, create_bordereau_document,
    InfractionIdentifiee, FactWithSource, SourceReference, ArgumentStructure,
    StyleLearningResult, StyleConfig, learn_document_style
)

from models.configurations import (
    DEFAULT_STYLE_CONFIGS, BUILTIN_DOCUMENT_TEMPLATES,
    DEFAULT_LETTERHEADS, FORMULES_JURIDIQUES,
    ARGUMENTATION_PATTERNS, ANALYSIS_CONFIGS
)

# ========================= MANAGERS AVANC√âS - IMPORT CONDITIONNEL =========================

MANAGERS = {
    'company_info': False,
    'jurisprudence_verifier': False,
    'style_analyzer': False,
    'dynamic_generators': False,
    'document_manager': False,
    'legal_search': False,
    'multi_llm': False
}

# Import des managers avec gestion d'erreur individuelle
try:
    from managers.company_info_manager import CompanyInfoManager
    MANAGERS['company_info'] = True
except ImportError as e:
    print(f"Import CompanyInfoManager failed: {e}")

try:
    from managers.jurisprudence_verifier import JurisprudenceVerifier
    MANAGERS['jurisprudence_verifier'] = True
except ImportError as e:
    print(f"Import JurisprudenceVerifier failed: {e}")

try:
    from managers.style_analyzer import StyleAnalyzer
    MANAGERS['style_analyzer'] = True
except ImportError as e:
    print(f"Import StyleAnalyzer failed: {e}")

try:
    from managers.dynamic_generators import generate_dynamic_search_prompts, generate_dynamic_templates
    MANAGERS['dynamic_generators'] = True
except ImportError as e:
    print(f"Import dynamic_generators functions failed: {e}")

try:
    from managers.document_manager import DocumentManager
    MANAGERS['document_manager'] = True
except ImportError as e:
    print(f"Import DocumentManager failed: {e}")

try:
    from managers.legal_search import LegalSearchManager
    MANAGERS['legal_search'] = True
except ImportError as e:
    print(f"Import LegalSearchManager failed: {e}")

try:
    from managers.multi_llm_manager import MultiLLMManager
    MANAGERS['multi_llm'] = True
except ImportError as e:
    print(f"Import MultiLLMManager failed: {e}")

# APIs - Import conditionnel
try:
    from utils.api_utils import get_available_models, call_llm_api
    HAS_API_UTILS = True
except ImportError:
    HAS_API_UTILS = False

# ========================= IMPORTS DES MODULES SP√âCIFIQUES =========================

MODULES_AVAILABLE = {}
MODULE_FUNCTIONS = {}

# Import conditionnel de tous les modules
modules_to_import = [
    ('analyse_ia', ['show_page']),
    ('bordereau', ['process_bordereau_request', 'create_bordereau']),
    ('comparison', ['process_comparison_request']),
    ('configuration', ['show_page']),
    ('email', ['process_email_request']),
    ('explorer', ['show_explorer_interface']),
    ('import_export', ['process_import_request', 'process_export_request']),
    ('jurisprudence', ['process_jurisprudence_request', 'show_jurisprudence_interface']),
    ('mapping', ['process_mapping_request']),
    ('plaidoirie', ['process_plaidoirie_request']),
    ('preparation_client', ['process_preparation_client_request']),
    ('redaction_unified', ['process_redaction_request']),
    ('selection_piece', ['show_page']),
    ('synthesis', ['process_synthesis_request']),
    ('templates', ['process_template_request']),
    ('timeline', ['process_timeline_request'])
]

for module_name, functions in modules_to_import:
    try:
        module = __import__(f'modules.{module_name}', fromlist=functions)
        MODULES_AVAILABLE[module_name] = True
        
        for func_name in functions:
            if hasattr(module, func_name):
                if func_name == 'show_page':
                    MODULE_FUNCTIONS[f'{module_name}_page'] = getattr(module, func_name)
                else:
                    MODULE_FUNCTIONS[func_name] = getattr(module, func_name)
    except ImportError:
        MODULES_AVAILABLE[module_name] = False

# ========================= G√âN√âRATION AVANC√âE DE PLAINTES =========================

async def generate_advanced_plainte(query: str):
    """G√©n√®re une plainte avanc√©e avec toutes les fonctionnalit√©s"""
    
    st.markdown("### üöÄ G√©n√©ration avanc√©e de plainte")
    
    # Analyser la requ√™te
    analysis = analyze_plainte_request(query)
    
    # V√©rifier si CPC
    is_cpc = check_if_cpc_required(query)
    
    if is_cpc:
        st.info("üìã G√©n√©ration d'une plainte avec constitution de partie civile EXHAUSTIVE")
        await generate_exhaustive_cpc_plainte(analysis)
    else:
        await generate_standard_plainte(analysis)

def analyze_plainte_request(query: str) -> Dict[str, Any]:
    """Analyse la requ√™te pour extraire les informations"""
    
    # Extraction des parties
    parties_pattern = r'contre\s+([A-Z][A-Za-z\s,&]+?)(?:\s+et\s+|,\s*|$)'
    parties = re.findall(parties_pattern, query, re.IGNORECASE)
    
    # Extraction des infractions
    infractions = []
    infractions_keywords = {
        'abus de biens sociaux': 'Abus de biens sociaux',
        'abs': 'Abus de biens sociaux',
        'corruption': 'Corruption',
        'escroquerie': 'Escroquerie',
        'abus de confiance': 'Abus de confiance',
        'blanchiment': 'Blanchiment'
    }
    
    query_lower = query.lower()
    for keyword, infraction in infractions_keywords.items():
        if keyword in query_lower:
            infractions.append(infraction)
    
    return {
        'parties': parties,
        'infractions': infractions or ['Abus de biens sociaux'],  # Par d√©faut
        'query': query
    }

def check_if_cpc_required(query: str) -> bool:
    """V√©rifie si une CPC est requise"""
    cpc_indicators = [
        'constitution de partie civile',
        'cpc',
        'partie civile',
        'exhaustive',
        'compl√®te'
    ]
    
    query_lower = query.lower()
    return any(indicator in query_lower for indicator in cpc_indicators)

async def generate_exhaustive_cpc_plainte(analysis: Dict[str, Any]):
    """G√©n√®re une plainte CPC exhaustive de 8000+ mots"""
    
    with st.spinner("‚è≥ G√©n√©ration d'une plainte exhaustive en cours... (cela peut prendre 2-3 minutes)"):
        
        # Options de g√©n√©ration
        col1, col2, col3 = st.columns(3)
        
        with col1:
            temperature = st.slider(
                "üå°Ô∏è Cr√©ativit√©",
                min_value=0.0,
                max_value=1.0,
                value=0.3,
                step=0.1,
                help="Plus bas = plus factuel, Plus haut = plus cr√©atif"
            )
        
        with col2:
            model = "claude-3-sonnet" 
            if HAS_API_UTILS:
                models = get_available_models()
                if models:
                    model = st.selectbox("ü§ñ Mod√®le", models, index=0)
        
        with col3:
            enrich_parties = st.checkbox(
                "üè¢ Enrichir les parties",
                value=True,
                help="Rechercher des informations sur les soci√©t√©s"
            )
        
        # Enrichissement des parties si demand√©
        enriched_parties = analysis['parties']
        if enrich_parties and MANAGERS['company_info']:
            enriched_parties = await enrich_parties_info(analysis['parties'])
        
        # G√©n√©rer le prompt d√©taill√©
        prompt = create_exhaustive_cpc_prompt(
            parties=enriched_parties,
            infractions=analysis['infractions']
        )
        
        # Appel √† l'API
        try:
            if HAS_API_UTILS:
                response = await call_llm_api(
                    prompt=prompt,
                    model=model,
                    temperature=temperature,
                    max_tokens=8000
                )
                
                # Stocker le r√©sultat
                st.session_state.generated_plainte = response
                st.session_state.search_results = {
                    'type': 'plainte_avancee',
                    'content': response,
                    'metadata': {
                        'parties': enriched_parties,
                        'infractions': analysis['infractions'],
                        'model': model,
                        'length': len(response.split())
                    }
                }
                
                # Afficher les statistiques
                show_plainte_statistics(response)
                
                # V√©rifier les jurisprudences si disponible
                if MANAGERS['jurisprudence_verifier']:
                    verify_jurisprudences_in_plainte(response)
                
                # Suggestions d'am√©lioration
                show_improvement_suggestions(response)
                
            else:
                # Fallback sans API
                st.warning("API non disponible - G√©n√©ration d'un mod√®le de plainte")
                generate_plainte_template(enriched_parties, analysis['infractions'])
                
        except Exception as e:
            st.error(f"Erreur lors de la g√©n√©ration : {str(e)}")

async def generate_standard_plainte(analysis: Dict[str, Any]):
    """G√©n√®re une plainte standard"""
    
    with st.spinner("‚è≥ G√©n√©ration de la plainte..."):
        
        # Options simplifi√©es
        col1, col2 = st.columns(2)
        
        with col1:
            plainte_type = st.selectbox(
                "Type de plainte",
                ["Simple", "Avec constitution de partie civile"],
                index=1
            )
        
        with col2:
            include_jurisprudence = st.checkbox(
                "üìö Inclure jurisprudences",
                value=True
            )
        
        # G√©n√©rer
        if HAS_API_UTILS:
            prompt = create_standard_plainte_prompt(
                parties=analysis['parties'],
                infractions=analysis['infractions'],
                plainte_type=plainte_type,
                include_jurisprudence=include_jurisprudence
            )
            
            try:
                response = await call_llm_api(
                    prompt=prompt,
                    model="claude-3-sonnet",
                    temperature=0.3
                )
                
                st.session_state.generated_plainte = response
                st.session_state.search_results = {
                    'type': 'plainte',
                    'content': response
                }
                
            except Exception as e:
                st.error(f"Erreur : {str(e)}")
        else:
            generate_plainte_template(analysis['parties'], analysis['infractions'])

# ========================= ENRICHISSEMENT DES PARTIES =========================

async def enrich_parties_info(parties: List[str]) -> List[Dict[str, Any]]:
    """Enrichit les informations sur les parties"""
    
    if not MANAGERS['company_info']:
        return [{'name': p} for p in parties]
    
    enriched = []
    company_manager = CompanyInfoManager()
    
    for party in parties:
        with st.spinner(f"üîç Recherche d'informations sur {party}..."):
            info = await company_manager.get_company_info(party)
            
            if info:
                enriched.append({
                    'name': party,
                    'siren': info.get('siren'),
                    'address': info.get('address'),
                    'legal_form': info.get('legal_form'),
                    'capital': info.get('capital'),
                    'executives': info.get('executives', [])
                })
            else:
                enriched.append({'name': party})
    
    return enriched

# ========================= CR√âATION DES PROMPTS =========================

def create_exhaustive_cpc_prompt(parties: List[Any], infractions: List[str]) -> str:
    """Cr√©e un prompt pour une plainte CPC exhaustive"""
    
    parties_text = format_parties_for_prompt(parties)
    infractions_text = ', '.join(infractions)
    
    return f"""
R√©digez une plainte avec constitution de partie civile EXHAUSTIVE et D√âTAILL√âE d'au moins 8000 mots.
PARTIES MISES EN CAUSE :
{parties_text}
INFRACTIONS √Ä D√âVELOPPER :
{infractions_text}
STRUCTURE IMPOS√âE :
1. EN-T√äTE COMPLET
   - Destinataire (Doyen des juges d'instruction)
   - Plaignant (√† compl√©ter)
   - Objet d√©taill√©
2. EXPOS√â EXHAUSTIF DES FAITS (3000+ mots)
   - Contexte d√©taill√© de l'affaire
   - Chronologie pr√©cise et compl√®te
   - Description minutieuse de chaque fait
   - Liens entre les protagonistes
   - Montants et pr√©judices d√©taill√©s
3. DISCUSSION JURIDIQUE APPROFONDIE (3000+ mots)
   Pour chaque infraction :
   - Rappel complet des textes
   - Analyse d√©taill√©e des √©l√©ments constitutifs
   - Application aux faits esp√®ce par esp√®ce
   - Jurisprudences pertinentes cit√©es
   - R√©futation des arguments contraires
4. PR√âJUDICES D√âTAILL√âS (1000+ mots)
   - Pr√©judice financier chiffr√©
   - Pr√©judice moral d√©velopp√©
   - Pr√©judice d'image
   - Autres pr√©judices
5. DEMANDES ET CONCLUSION (1000+ mots)
   - Constitution de partie civile motiv√©e
   - Demandes d'actes pr√©cises
   - Mesures conservatoires
   - Provision sur dommages-int√©r√™ts
CONSIGNES :
- Style juridique soutenu et pr√©cis
- Citations de jurisprudences r√©centes
- Argumentation implacable
- Aucune zone d'ombre
- Anticipation des contre-arguments
"""

def create_standard_plainte_prompt(parties: List[str], infractions: List[str], 
                                  plainte_type: str, include_jurisprudence: bool) -> str:
    """Cr√©e un prompt pour une plainte standard"""
    
    parties_text = ', '.join(parties)
    infractions_text = ', '.join(infractions)
    
    jurisprudence_instruction = ""
    if include_jurisprudence:
        jurisprudence_instruction = "\n- Citez au moins 3 jurisprudences pertinentes"
    
    return f"""
R√©digez une {plainte_type} concernant :
- Parties : {parties_text}
- Infractions : {infractions_text}
Structure :
1. En-t√™te et qualit√©s
2. Expos√© des faits
3. Discussion juridique
4. Pr√©judices
5. Demandes
Consignes :
- Style juridique professionnel
- Argumentation structur√©e{jurisprudence_instruction}
- Environ 2000-3000 mots
"""

def format_parties_for_prompt(parties: List[Any]) -> str:
    """Formate les parties pour le prompt"""
    
    if not parties:
        return "√Ä COMPL√âTER"
    
    formatted = []
    for party in parties:
        if isinstance(party, dict):
            text = f"- {party['name']}"
            if party.get('siren'):
                text += f" (SIREN: {party['siren']})"
            if party.get('address'):
                text += f"\n  Si√®ge: {party['address']}"
            if party.get('executives'):
                text += f"\n  Dirigeants: {', '.join(party['executives'][:3])}"
            formatted.append(text)
        else:
            formatted.append(f"- {party}")
    
    return '\n'.join(formatted)

# ========================= V√âRIFICATION ET ANALYSE =========================

def verify_jurisprudences_in_plainte(content: str):
    """V√©rifie les jurisprudences cit√©es dans la plainte"""
    
    if not MANAGERS['jurisprudence_verifier']:
        return
    
    with st.expander("üîç V√©rification des jurisprudences"):
        verifier = JurisprudenceVerifier()
        
        # Extraire les r√©f√©rences
        jurisprudence_pattern = r'(Cass\.\s+\w+\.?,?\s+\d{1,2}\s+\w+\s+\d{4}|C\.\s*cass\.\s*\w+\.?\s*\d{1,2}\s+\w+\s+\d{4})'
        references = re.findall(jurisprudence_pattern, content)
        
        if references:
            st.write(f"**{len(references)} r√©f√©rences trouv√©es**")
            
            verified = 0
            for ref in references[:5]:  # V√©rifier les 5 premi√®res
                if verifier.verify_reference(ref):
                    st.success(f"‚úÖ {ref}")
                    verified += 1
                else:
                    st.warning(f"‚ö†Ô∏è {ref} - Non v√©rifi√©e")
            
            reliability = (verified / len(references[:5])) * 100
            st.metric("Taux de fiabilit√©", f"{reliability:.0f}%")
        else:
            st.info("Aucune jurisprudence d√©tect√©e")

def show_plainte_statistics(content: str):
    """Affiche les statistiques de la plainte"""
    
    with st.expander("üìä Statistiques du document"):
        words = content.split()
        sentences = content.split('.')
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("Mots", len(words))
        
        with col2:
            st.metric("Phrases", len(sentences))
        
        with col3:
            st.metric("Pages estim√©es", f"~{len(words) // 250}")
        
        # Analyse du style si disponible
        if MANAGERS['style_analyzer']:
            analyzer = StyleAnalyzer()
            style_score = analyzer.analyze_style(content)
            
            st.markdown("**Analyse du style :**")
            st.progress(style_score / 100)
            st.caption(f"Score de qualit√© : {style_score}/100")

def show_improvement_suggestions(content: str):
    """Sugg√®re des am√©liorations pour la plainte"""
    
    with st.expander("üí° Suggestions d'am√©lioration"):
        suggestions = []
        
        # V√©rifier la longueur
        word_count = len(content.split())
        if word_count < 2000:
            suggestions.append("üìù D√©velopper davantage l'expos√© des faits")
        
        # V√©rifier les citations
        if content.count('"') < 4:
            suggestions.append("üìö Ajouter plus de citations de jurisprudence")
        
        # V√©rifier les montants
        if not re.search(r'\d+\s*‚Ç¨|\d+\s*euros', content):
            suggestions.append("üí∞ Chiffrer pr√©cis√©ment les pr√©judices")
        
        # V√©rifier la structure
        required_sections = ['FAITS', 'DISCUSSION', 'PR√âJUDICE', 'DEMANDE']
        missing = [s for s in required_sections if s not in content.upper()]
        if missing:
            suggestions.append(f"üìã Ajouter sections : {', '.join(missing)}")
        
        if suggestions:
            for suggestion in suggestions:
                st.write(suggestion)
        else:
            st.success("‚úÖ La plainte semble compl√®te !")

# ========================= G√âN√âRATION DE PLAINTES =========================

def generate_plainte_simple(parties_defenderesses: List[str], infractions: List[str]) -> str:
    """G√©n√®re une plainte simple"""
    
    parties_text = '\n'.join([f"- {p}" for p in parties_defenderesses]) if parties_defenderesses else "- [√Ä COMPL√âTER]"
    infractions_text = '\n'.join([f"- {i}" for i in infractions]) if infractions else "- [√Ä COMPL√âTER]"
    
    return f"""PLAINTE SIMPLE
√Ä l'attention de Monsieur le Procureur de la R√©publique
Tribunal Judiciaire de [VILLE]
[VILLE], le {datetime.now().strftime('%d/%m/%Y')}
OBJET : Plainte
Monsieur le Procureur,
Je soussign√©(e) [NOM PR√âNOM]
Demeurant [ADRESSE]
Ai l'honneur de porter plainte contre :
{parties_text}
Pour les faits suivants :
[EXPOS√â DES FAITS]
Ces faits sont susceptibles de recevoir les qualifications suivantes :
{infractions_text}
Je vous prie d'agr√©er, Monsieur le Procureur, l'expression de ma consid√©ration distingu√©e.
[SIGNATURE]
Pi√®ces jointes :
- [LISTE DES PI√àCES]
"""

def generate_plainte_cpc(parties_defenderesses: List[str], infractions: List[str], 
                        demandeurs: List[str] = None, options: Dict = None) -> str:
    """G√©n√®re une plainte avec constitution de partie civile"""
    
    parties_text = format_parties_list([{'name': p} for p in parties_defenderesses])
    infractions_text = '\n'.join([f"- {i}" for i in infractions]) if infractions else "- [√Ä COMPL√âTER]"
    
    return f"""PLAINTE AVEC CONSTITUTION DE PARTIE CIVILE
Monsieur le Doyen des Juges d'Instruction
Tribunal Judiciaire de [VILLE]
[ADRESSE]
[VILLE], le {datetime.now().strftime('%d/%m/%Y')}
OBJET : Plainte avec constitution de partie civile
R√âF√âRENCES : [√Ä COMPL√âTER]
Monsieur le Doyen,
Je soussign√©(e) [NOM PR√âNOM]
N√©(e) le [DATE] √† [LIEU]
De nationalit√© fran√ßaise
Profession : [PROFESSION]
Demeurant : [ADRESSE COMPL√àTE]
T√©l√©phone : [T√âL√âPHONE]
Email : [EMAIL]
Ayant pour conseil : [SI APPLICABLE]
Ma√Ætre [NOM AVOCAT]
Avocat au Barreau de [VILLE]
[ADRESSE CABINET]
Ai l'honneur de d√©poser entre vos mains une plainte avec constitution de partie civile contre :
{parties_text}
Et toute autre personne que l'instruction r√©v√®lerait avoir particip√© aux faits ci-apr√®s expos√©s.
I. EXPOS√â D√âTAILL√â DES FAITS
[D√âVELOPPEMENT D√âTAILL√â - √Ä COMPL√âTER]
II. DISCUSSION JURIDIQUE
Les faits expos√©s ci-dessus caract√©risent les infractions suivantes :
{infractions_text}
[ANALYSE JURIDIQUE D√âTAILL√âE - √Ä COMPL√âTER]
III. PR√âJUDICES SUBIS
[D√âTAIL DES PR√âJUDICES - √Ä COMPL√âTER]
IV. CONSTITUTION DE PARTIE CIVILE
Par les pr√©sents, je d√©clare me constituer partie civile et demander r√©paration int√©grale de mon pr√©judice.
Je sollicite :
- La d√©signation d'un juge d'instruction
- L'ouverture d'une information judiciaire
- Tous actes d'instruction utiles √† la manifestation de la v√©rit√©
- La mise en examen des personnes mises en cause
- Le renvoi devant la juridiction de jugement
- La condamnation des pr√©venus
- L'allocation de dommages-int√©r√™ts en r√©paration du pr√©judice subi
V. PI√àCES JUSTIFICATIVES
Vous trouverez ci-joint :
[LISTE D√âTAILL√âE DES PI√àCES]
Je verse la consignation fix√©e par vos soins.
Je vous prie d'agr√©er, Monsieur le Doyen, l'expression de ma consid√©ration distingu√©e.
Fait √† [VILLE], le {datetime.now().strftime('%d/%m/%Y')}
[SIGNATURE]
"""

# ========================= TEMPLATES DE FALLBACK =========================

def generate_plainte_template(parties: List[Any], infractions: List[str]):
    """G√©n√®re un template de plainte sans API"""
    
    template = generate_plainte_cpc(
        parties_defenderesses=[p['name'] if isinstance(p, dict) else p for p in parties],
        infractions=infractions
    )
    
    st.session_state.generated_plainte = template
    st.session_state.search_results = {
        'type': 'plainte_template',
        'content': template
    }

def format_parties_list(parties: List[Any]) -> str:
    """Formate la liste des parties pour le template"""
    
    if not parties:
        return "- [NOM DE LA PARTIE]\n  [FORME JURIDIQUE]\n  [SI√àGE SOCIAL]\n  [SIREN]"
    
    formatted = []
    for party in parties:
        if isinstance(party, dict):
            formatted.append(f"- {party.get('name', '[NOM]')}")
            if party.get('legal_form'):
                formatted.append(f"  {party['legal_form']}")
            if party.get('address'):
                formatted.append(f"  {party['address']}")
            if party.get('siren'):
                formatted.append(f"  SIREN : {party['siren']}")
        else:
            formatted.append(f"- {party}")
            formatted.append("  [FORME JURIDIQUE]")
            formatted.append("  [SI√àGE SOCIAL]")
            formatted.append("  [SIREN]")
    
    return '\n'.join(formatted)

# ========================= COMPARAISON MULTI-IA =========================

async def compare_ai_generations(prompt: str, models: List[str] = None):
    """Compare les g√©n√©rations de plusieurs IA"""
    
    if not HAS_API_UTILS:
        st.warning("Comparaison multi-IA non disponible")
        return
    
    st.markdown("### ü§ñ Comparaison Multi-IA")
    
    if not models:
        models = get_available_models()[:3]  # Top 3 mod√®les
    
    results = {}
    
    # G√©n√©rer avec chaque mod√®le
    cols = st.columns(len(models))
    
    for idx, model in enumerate(models):
        with cols[idx]:
            with st.spinner(f"G√©n√©ration {model}..."):
                try:
                    response = await call_llm_api(
                        prompt=prompt,
                        model=model,
                        temperature=0.3,
                        max_tokens=2000
                    )
                    results[model] = response
                    st.success(f"‚úÖ {model}")
                except Exception as e:
                    st.error(f"‚ùå {model}: {str(e)}")
    
    # Afficher les r√©sultats
    if results:
        st.markdown("#### R√©sultats")
        
        selected_model = st.radio(
            "Choisir le meilleur r√©sultat",
            list(results.keys())
        )
        
        st.text_area(
            f"R√©sultat {selected_model}",
            results[selected_model],
            height=400
        )
        
        if st.button("‚úÖ Utiliser ce r√©sultat"):
            st.session_state.generated_plainte = results[selected_model]
            st.success("R√©sultat s√©lectionn√© !")

# ========================= RECHERCHE JURIDIQUE AVANC√âE =========================

async def perform_legal_search(query: str, options: Dict[str, Any] = None):
    """Effectue une recherche juridique avanc√©e"""
    
    if not MANAGERS['legal_search']:
        st.warning("Module de recherche juridique non disponible")
        return None
    
    with st.spinner("üîç Recherche juridique en cours..."):
        legal_search = LegalSearchManager()
        
        # Options de recherche
        col1, col2, col3 = st.columns(3)
        
        with col1:
            search_type = st.selectbox(
                "Type de recherche",
                ["Jurisprudence", "Doctrine", "Textes l√©gaux", "Tout"],
                index=3
            )
        
        with col2:
            jurisdiction = st.selectbox(
                "Juridiction",
                ["Toutes", "Cour de cassation", "Cours d'appel", "Tribunaux"],
                index=0
            )
        
        with col3:
            date_filter = st.selectbox(
                "P√©riode",
                ["Toutes", "1 an", "5 ans", "10 ans"],
                index=1
            )
        
        # Recherche
        try:
            results = await legal_search.search(
                query=query,
                search_type=search_type,
                jurisdiction=jurisdiction,
                date_filter=date_filter
            )
            
            # Afficher les r√©sultats
            if results:
                st.success(f"‚úÖ {len(results)} r√©sultats trouv√©s")
                
                for idx, result in enumerate(results[:10], 1):
                    with st.expander(f"{idx}. {result.get('title', 'Sans titre')}"):
                        st.write(f"**Source:** {result.get('source', 'Non sp√©cifi√©e')}")
                        st.write(f"**Date:** {result.get('date', 'Non dat√©e')}")
                        st.write(f"**Juridiction:** {result.get('jurisdiction', 'Non sp√©cifi√©e')}")
                        st.markdown("---")
                        st.write(result.get('content', 'Pas de contenu'))
                        
                        if result.get('reference'):
                            st.caption(f"R√©f√©rence: {result['reference']}")
            else:
                st.info("Aucun r√©sultat trouv√©")
                
        except Exception as e:
            st.error(f"Erreur lors de la recherche : {str(e)}")

# ========================= GESTION AVANC√âE DES DOCUMENTS =========================

async def manage_documents_advanced(action: str, documents: List[Any] = None):
    """Gestion avanc√©e des documents avec DocumentManager"""
    
    if not MANAGERS['document_manager']:
        st.warning("Module de gestion documentaire non disponible")
        return None
    
    doc_manager = DocumentManager()
    
    if action == "import":
        st.markdown("### üì• Import avanc√© de documents")
        
        uploaded_files = st.file_uploader(
            "Choisir des fichiers",
            type=['pdf', 'docx', 'txt', 'rtf'],
            accept_multiple_files=True
        )
        
        if uploaded_files:
            with st.spinner(f"Import de {len(uploaded_files)} fichiers..."):
                imported = []
                
                for file in uploaded_files:
                    try:
                        # Traitement avec OCR si n√©cessaire
                        result = await doc_manager.import_document(
                            file,
                            ocr_enabled=st.checkbox(f"OCR pour {file.name}", value=True),
                            extract_metadata=True
                        )
                        imported.append(result)
                        st.success(f"‚úÖ {file.name}")
                    except Exception as e:
                        st.error(f"‚ùå {file.name}: {str(e)}")
                
                return imported
    
    elif action == "analyze":
        st.markdown("### üìä Analyse avanc√©e de documents")
        
        if documents:
            analysis_type = st.multiselect(
                "Types d'analyse",
                ["Structure", "Entit√©s", "Sentiment", "Th√®mes", "Relations"],
                default=["Structure", "Entit√©s"]
            )
            
            results = {}
            for doc in documents:
                with st.spinner(f"Analyse de {doc.get('name', 'document')}..."):
                    try:
                        analysis = await doc_manager.analyze_document(
                            doc,
                            analysis_types=analysis_type
                        )
                        results[doc['id']] = analysis
                    except Exception as e:
                        st.error(f"Erreur : {str(e)}")
            
            # Afficher les r√©sultats d'analyse
            for doc_id, analysis in results.items():
                with st.expander(f"Analyse de {doc_id}"):
                    for analysis_type, data in analysis.items():
                        st.write(f"**{analysis_type}:**")
                        st.json(data)

# ========================= COMPARAISON MULTI-LLM AM√âLIOR√âE =========================

async def enhanced_multi_llm_comparison(prompt: str, options: Dict[str, Any] = None):
    """Comparaison multi-LLM avec fonctionnalit√©s avanc√©es"""
    
    if not MANAGERS['multi_llm']:
        # Fallback vers la version simple
        return await compare_ai_generations(prompt)
    
    multi_llm = MultiLLMManager()
    
    st.markdown("### ü§ñ Comparaison Multi-LLM Avanc√©e")
    
    # Options de comparaison
    col1, col2, col3 = st.columns(3)
    
    with col1:
        models = st.multiselect(
            "Mod√®les √† comparer",
            multi_llm.get_available_models(),
            default=multi_llm.get_available_models()[:3]
        )
    
    with col2:
        comparison_mode = st.selectbox(
            "Mode de comparaison",
            ["Parall√®le", "S√©quentiel", "Consensus"],
            help="Parall√®le: tous en m√™me temps | S√©quentiel: un par un | Consensus: trouve le meilleur"
        )
    
    with col3:
        metrics = st.multiselect(
            "M√©triques d'√©valuation",
            ["Qualit√©", "Pertinence", "Cr√©ativit√©", "Coh√©rence"],
            default=["Qualit√©", "Pertinence"]
        )
    
    if st.button("üöÄ Lancer la comparaison", type="primary"):
        results = {}
        
        if comparison_mode == "Parall√®le":
            # G√©n√©ration parall√®le
            tasks = []
            for model in models:
                task = multi_llm.generate_async(prompt, model=model)
                tasks.append((model, task))
            
            # Attendre toutes les r√©ponses
            progress = st.progress(0)
            for idx, (model, task) in enumerate(tasks):
                with st.spinner(f"G√©n√©ration {model}..."):
                    try:
                        response = await task
                        results[model] = response
                        progress.progress((idx + 1) / len(tasks))
                    except Exception as e:
                        st.error(f"‚ùå {model}: {str(e)}")
        
        elif comparison_mode == "S√©quentiel":
            # G√©n√©ration s√©quentielle avec am√©lioration
            previous_response = None
            for model in models:
                with st.spinner(f"G√©n√©ration {model}..."):
                    try:
                        if previous_response:
                            # Enrichir le prompt avec la r√©ponse pr√©c√©dente
                            enriched_prompt = f"{prompt}\n\nAm√©liore cette r√©ponse:\n{previous_response[:500]}..."
                            response = await multi_llm.generate(enriched_prompt, model=model)
                        else:
                            response = await multi_llm.generate(prompt, model=model)
                        
                        results[model] = response
                        previous_response = response
                    except Exception as e:
                        st.error(f"‚ùå {model}: {str(e)}")
        
        else:  # Consensus
            # G√©n√©rer avec tous les mod√®les puis trouver le consensus
            with st.spinner("Recherche du consensus..."):
                consensus = await multi_llm.get_consensus(prompt, models=models)
                results['consensus'] = consensus
        
        # √âvaluation et affichage
        if results:
            st.markdown("#### üìä R√©sultats")
            
            # √âvaluer selon les m√©triques
            if metrics and comparison_mode != "Consensus":
                evaluations = {}
                for model, response in results.items():
                    evaluations[model] = await multi_llm.evaluate_response(
                        response, 
                        metrics=metrics
                    )
                
                # Afficher les scores
                st.markdown("**Scores d'√©valuation:**")
                df_scores = []
                for model, scores in evaluations.items():
                    row = {'Mod√®le': model}
                    row.update(scores)
                    df_scores.append(row)
                
                st.dataframe(df_scores)
                
                # Identifier le meilleur
                best_model = max(evaluations.items(), 
                               key=lambda x: sum(x[1].values()))[0]
                st.success(f"üèÜ Meilleur mod√®le : {best_model}")
            
            # Afficher les r√©ponses
            if comparison_mode == "Consensus":
                st.text_area("Consensus", results['consensus'], height=400)
            else:
                selected = st.selectbox(
                    "Voir la r√©ponse de",
                    list(results.keys())
                )
                
                st.text_area(
                    f"R√©ponse {selected}",
                    results[selected],
                    height=400
                )
                
                # Actions
                col1, col2, col3 = st.columns(3)
                with col1:
                    if st.button("üìã Copier"):
                        st.session_state.clipboard = results[selected]
                        st.success("Copi√© !")
                
                with col2:
                    if st.button("üíæ Utiliser"):
                        st.session_state.generated_content = results[selected]
                        st.success("Contenu s√©lectionn√© !")
                
                with col3:
                    if st.button("üîÑ Reg√©n√©rer"):
                        st.rerun()

# ========================= G√âN√âRATEURS DYNAMIQUES =========================

async def use_dynamic_generators(content_type: str, context: Dict[str, Any]):
    """Utilise les g√©n√©rateurs dynamiques pour enrichir le contenu"""
    
    if not MANAGERS['dynamic_generators']:
        st.warning("G√©n√©rateurs dynamiques non disponibles")
        return None
    
    st.markdown("### ‚ú® G√©n√©ration dynamique")
    
    # Options selon le type de contenu
    if content_type == "plainte":
        # G√©n√©ration de templates dynamiques
        if st.button("G√©n√©rer des templates de plainte"):
            with st.spinner("G√©n√©ration des templates..."):
                try:
                    templates = await generate_dynamic_templates('plainte', context)
                    
                    st.success("‚úÖ Templates g√©n√©r√©s")
                    for name, template in templates.items():
                        with st.expander(name):
                            st.text_area("Contenu", value=template, height=300)
                            st.download_button(
                                "üì• T√©l√©charger",
                                template,
                                file_name=f"{name.replace(' ', '_')}.txt"
                            )
                except Exception as e:
                    st.error(f"Erreur : {str(e)}")
        
        # G√©n√©ration de prompts de recherche
        if st.button("G√©n√©rer des prompts de recherche"):
            with st.spinner("G√©n√©ration des prompts..."):
                try:
                    prompts = await generate_dynamic_search_prompts(
                        context.get('query', 'plainte'),
                        context.get('context', '')
                    )
                    
                    st.success("‚úÖ Prompts g√©n√©r√©s")
                    for category, subcategories in prompts.items():
                        with st.expander(category):
                            for subcat, prompts_list in subcategories.items():
                                st.subheader(subcat)
                                for prompt in prompts_list:
                                    st.write(f"‚Ä¢ {prompt}")
                except Exception as e:
                    st.error(f"Erreur : {str(e)}")

# ========================= GESTION DES PI√àCES =========================

def show_piece_selection_advanced(analysis: Any):
    """Interface avanc√©e de s√©lection de pi√®ces"""
    
    st.markdown("### üìÅ S√©lection avanc√©e des pi√®ces")
    
    # Collecter les documents disponibles
    documents = collect_available_documents(analysis)
    
    if not documents:
        st.warning("Aucun document disponible. Importez d'abord des documents.")
        return
    
    # Grouper par cat√©gorie
    categories = group_documents_by_category(documents)
    
    # Options de filtrage
    col1, col2 = st.columns(2)
    with col1:
        selected_categories = st.multiselect(
            "Cat√©gories",
            list(categories.keys()),
            default=list(categories.keys())
        )
    
    with col2:
        sort_by = st.selectbox(
            "Trier par",
            ["Pertinence", "Date", "Titre", "Cat√©gorie"]
        )
    
    # S√©lection des pi√®ces
    selected_pieces = []
    
    for category in selected_categories:
        if category in categories:
            st.markdown(f"#### {category}")
            
            for doc in categories[category]:
                col1, col2, col3 = st.columns([1, 3, 1])
                
                with col1:
                    selected = st.checkbox(
                        "",
                        key=f"select_{doc['id']}",
                        value=doc['id'] in st.session_state.get('selected_pieces_ids', [])
                    )
                
                with col2:
                    st.write(f"**{doc['title']}**")
                    if doc.get('metadata', {}).get('date'):
                        st.caption(f"Date: {doc['metadata']['date']}")
                
                with col3:
                    relevance = calculate_piece_relevance(doc, analysis)
                    st.progress(relevance)
                    st.caption(f"{relevance*100:.0f}% pertinent")
                
                if selected:
                    selected_pieces.append(doc)
    
    # Actions sur la s√©lection
    if selected_pieces:
        st.markdown("---")
        st.info(f"üìã {len(selected_pieces)} pi√®ces s√©lectionn√©es")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            if st.button("üìã Cr√©er bordereau"):
                show_bordereau_interface_advanced(selected_pieces, analysis)
        
        with col2:
            if st.button("üìÑ Synth√©tiser"):
                asyncio.run(synthesize_selected_pieces(selected_pieces))
        
        with col3:
            if st.button("üì• Exporter liste"):
                export_piece_list(selected_pieces)
        
        with col4:
            if st.button("üóëÔ∏è R√©initialiser"):
                st.session_state.selected_pieces_ids = []
                st.rerun()
        
        # Stocker la s√©lection
        st.session_state.selected_pieces = selected_pieces
        st.session_state.selected_pieces_ids = [p['id'] for p in selected_pieces]

def show_bordereau_interface_advanced(documents: List[Dict], analysis: Any):
    """Interface avanc√©e de cr√©ation de bordereau"""
    
    st.markdown("### üìã Cr√©ation du bordereau")
    
    # Pr√©parer les pi√®ces pour le bordereau
    pieces = []
    for idx, doc in enumerate(documents, 1):
        piece = PieceSelectionnee(
            numero=idx,
            titre=doc.get('title', 'Sans titre'),
            description=doc.get('metadata', {}).get('description', ''),
            categorie=determine_document_category(doc),
            date=doc.get('metadata', {}).get('date'),
            pertinence=calculate_piece_relevance(doc, analysis)
        )
        pieces.append(piece)
    
    # Cr√©er le bordereau
    bordereau = create_bordereau(pieces, analysis)
    
    # Afficher le bordereau
    st.text_area(
        "Aper√ßu du bordereau",
        value=bordereau.export_to_text()[:1000] + "...",
        height=300
    )
    
    # Options d'export
    col1, col2 = st.columns(2)
    
    with col1:
        format_export = st.selectbox(
            "Format d'export",
            ["Texte", "Markdown", "PDF", "Word"]
        )
    
    with col2:
        if st.button("üì• T√©l√©charger le bordereau"):
            if format_export == "Texte":
                content = bordereau.export_to_text()
            elif format_export == "Markdown":
                content = bordereau.export_to_markdown_with_links()
            else:
                content = bordereau.export_to_text()  # Fallback
            
            st.download_button(
                "üíæ T√©l√©charger",
                content.encode('utf-8'),
                f"bordereau_{datetime.now().strftime('%Y%m%d_%H%M%S')}.{'txt' if format_export == 'Texte' else 'md'}",
                "text/plain" if format_export == "Texte" else "text/markdown"
            )
    
    # Statistiques
    st.markdown("#### üìä Statistiques")
    summary = bordereau.generate_summary()
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Total pi√®ces", summary['total_pieces'])
    
    with col2:
        st.metric("Cat√©gories", len(summary['pieces_by_category']))
    
    with col3:
        st.metric("Sources", summary['sources_count'])

def export_piece_list(pieces: List[Any]):
    """Exporte la liste des pi√®ces"""
    content = "LISTE DES PI√àCES S√âLECTIONN√âES\n"
    content += f"Date : {datetime.now().strftime('%d/%m/%Y %H:%M')}\n"
    content += f"Nombre de pi√®ces : {len(pieces)}\n\n"
    
    # Grouper par cat√©gorie
    from collections import defaultdict
    by_category = defaultdict(list)
    for piece in pieces:
        category = piece.get('category', 'Non cat√©goris√©')
        by_category[category].append(piece)
    
    for category, cat_pieces in by_category.items():
        content += f"\n{category.upper()} ({len(cat_pieces)} pi√®ces)\n"
        content += "-" * 50 + "\n"
        
        for i, piece in enumerate(cat_pieces, 1):
            content += f"{i}. {piece.get('title', 'Sans titre')}\n"
            if piece.get('metadata', {}).get('date'):
                content += f"   Date: {piece['metadata']['date']}\n"
            content += "\n"
    
    # Proposer le t√©l√©chargement
    st.download_button(
        "üíæ T√©l√©charger la liste",
        content.encode('utf-8'),
        f"liste_pieces_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
        "text/plain"
    )

async def synthesize_selected_pieces(pieces: List[Any]) -> Dict:
    """Synth√©tise les pi√®ces s√©lectionn√©es"""
    
    if not MANAGERS['multi_llm']:
        return {'error': 'Module Multi-LLM non disponible'}
    
    try:
        from managers.multi_llm_manager import MultiLLMManager
        llm_manager = MultiLLMManager()
        
        if not llm_manager.clients:
            return {'error': 'Aucune IA disponible'}
        
        # Construire le contexte
        context = "PI√àCES √Ä SYNTH√âTISER:\n\n"
        
        for i, piece in enumerate(pieces[:20], 1):  # Limiter √† 20 pi√®ces
            context += f"Pi√®ce {i}: {piece.get('title', 'Sans titre')}\n"
            if piece.get('category'):
                context += f"Cat√©gorie: {piece['category']}\n"
            if piece.get('content'):
                context += f"Extrait: {piece['content'][:200]}...\n"
            context += "\n"
        
        # Prompt de synth√®se
        synthesis_prompt = f"""{context}
Cr√©e une synth√®se structur√©e de ces pi√®ces.
La synth√®se doit inclure:
1. Vue d'ensemble des pi√®ces
2. Points cl√©s par cat√©gorie
3. Chronologie si applicable
4. Points d'attention juridiques
5. Recommandations"""
        
        provider = list(llm_manager.clients.keys())[0]
        response = llm_manager.query_single_llm(
            provider,
            synthesis_prompt,
            "Tu es un expert en analyse de documents juridiques."
        )
        
        if response['success']:
            synthesis_result = {
                'content': response['response'],
                'piece_count': len(pieces),
                'categories': list(set(p.get('category', 'Autre') for p in pieces)),
                'timestamp': datetime.now()
            }
            st.session_state.synthesis_result = synthesis_result
            return synthesis_result
        else:
            return {'error': '√âchec de la synth√®se'}
            
    except Exception as e:
        return {'error': f'Erreur synth√®se: {str(e)}'}

# ========================= STATISTIQUES ET UTILS =========================

def show_document_statistics(content: str):
    """Affiche les statistiques d√©taill√©es d'un document"""
    
    # Calculs de base
    words = content.split()
    sentences = content.split('.')
    paragraphs = content.split('\n\n')
    
    # Analyse avanc√©e
    law_refs = len(re.findall(r'article\s+[LR]?\s*\d+', content, re.IGNORECASE))
    case_refs = len(re.findall(r'(Cass\.|C\.\s*cass\.|Crim\.|Civ\.)', content, re.IGNORECASE))
    
    # Affichage en colonnes
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Mots", f"{len(words):,}")
        st.metric("Phrases", f"{len(sentences):,}")
    
    with col2:
        st.metric("Paragraphes", len(paragraphs))
        st.metric("Mots/phrase", f"{len(words) / max(len(sentences), 1):.1f}")
    
    with col3:
        st.metric("Articles cit√©s", law_refs)
        st.metric("Jurisprudences", case_refs)
    
    with col4:
        avg_word_length = sum(len(w) for w in words) / max(len(words), 1)
        st.metric("Long. moy.", f"{avg_word_length:.1f} car")
        st.metric("Pages est.", f"~{len(words) // 250}")
    
    # Analyse linguistique si StyleAnalyzer disponible
    if MANAGERS['style_analyzer']:
        with st.expander("üìä Analyse linguistique avanc√©e"):
            try:
                analyzer = StyleAnalyzer()
                linguistic_analysis = analyzer.analyze_text_complexity(content)
                
                col1, col2 = st.columns(2)
                with col1:
                    st.write("**Complexit√© lexicale:**")
                    st.progress(linguistic_analysis.get('lexical_diversity', 0.5))
                    
                with col2:
                    st.write("**Lisibilit√©:**")
                    readability_score = linguistic_analysis.get('readability_score', 50)
                    st.progress(readability_score / 100)
                    
            except Exception as e:
                st.error(f"Erreur analyse linguistique: {str(e)}")

def save_current_work() -> Dict:
    """Sauvegarde compl√®te du travail actuel"""
    work_data = {
        'timestamp': datetime.now().isoformat(),
        'version': '2.0',
        'session_data': {},
        'results': {},
        'documents': {},
        'analysis': {}
    }
    
    # Sauvegarder l'√©tat de session pertinent
    session_keys = [
        'universal_query', 'last_universal_query', 
        'redaction_result', 'ai_analysis_results',
        'search_results', 'selected_pieces',
        'synthesis_result', 'timeline_result',
        'generated_plainte'
    ]
    
    for key in session_keys:
        if key in st.session_state:
            value = st.session_state[key]
            # S√©rialiser les objets complexes
            if hasattr(value, '__dict__'):
                work_data['session_data'][key] = value.__dict__
            else:
                work_data['session_data'][key] = value
    
    # Sauvegarder les documents
    if 'azure_documents' in st.session_state:
        for doc_id, doc in st.session_state.azure_documents.items():
            if hasattr(doc, '__dict__'):
                work_data['documents'][doc_id] = doc.__dict__
            else:
                work_data['documents'][doc_id] = doc
    
    # Cr√©er le JSON
    import json
    
    def default_serializer(obj):
        if hasattr(obj, '__dict__'):
            return obj.__dict__
        elif hasattr(obj, 'isoformat'):
            return obj.isoformat()
        else:
            return str(obj)
    
    json_str = json.dumps(work_data, indent=2, ensure_ascii=False, default=default_serializer)
    
    # Proposer le t√©l√©chargement
    st.download_button(
        "üíæ Sauvegarder le travail",
        json_str,
        f"sauvegarde_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
        "application/json",
        key="save_work_btn"
    )
    
    return work_data

async def show_work_statistics():
    """Affiche des statistiques d√©taill√©es du travail"""
    st.markdown("### üìä Statistiques du travail")
    
    # Statistiques de base
    stats = {
        'Documents Azure': len(st.session_state.get('azure_documents', {})),
        'Documents import√©s': len(st.session_state.get('imported_documents', {})),
        'Pi√®ces s√©lectionn√©es': len(st.session_state.get('selected_pieces', [])),
        'Analyses effectu√©es': 1 if st.session_state.get('ai_analysis_results') else 0,
        'R√©dactions': 1 if st.session_state.get('redaction_result') else 0
    }
    
    # Affichage en m√©triques
    cols = st.columns(len(stats))
    for i, (label, value) in enumerate(stats.items()):
        with cols[i]:
            st.metric(label, value)
    
    # Statistiques d√©taill√©es par type
    with st.expander("üìà Statistiques d√©taill√©es"):
        # Documents par cat√©gorie
        if st.session_state.get('azure_documents'):
            all_docs = []
            for doc_id, doc in st.session_state.azure_documents.items():
                all_docs.append({
                    'id': doc_id,
                    'title': doc.title if hasattr(doc, 'title') else doc.get('title', ''),
                    'content': doc.content if hasattr(doc, 'content') else doc.get('content', ''),
                    'source': doc.source if hasattr(doc, 'source') else doc.get('source', '')
                })
            
            categories = group_documents_by_category(all_docs)
            
            st.write("**Documents par cat√©gorie:**")
            for cat, docs in categories.items():
                st.write(f"‚Ä¢ {cat}: {len(docs)} documents")
        
        # Historique des actions
        if 'action_history' in st.session_state:
            st.write("**Historique des actions:**")
            for action in st.session_state.action_history[-10:]:
                st.write(f"‚Ä¢ {action['timestamp']}: {action['type']}")

# ========================= TRAITEMENT DES PLAINTES COMPLET =========================

async def process_plainte_request(query: str, analysis: QueryAnalysis):
    """Traite une demande de plainte avec toutes les options"""
    
    st.markdown("### üìã Configuration de la plainte")
    
    # D√©terminer le type de plainte
    query_lower = query.lower()
    is_partie_civile = any(term in query_lower for term in [
        'partie civile', 'constitution de partie civile', 'cpc', 
        'doyen', 'juge d\'instruction', 'instruction'
    ])
    
    # Extraire les parties et infractions
    parties_demanderesses = []
    parties_defenderesses = []
    infractions = []
    
    if hasattr(analysis, 'parties'):
        parties_demanderesses = analysis.parties.get('demandeurs', [])
        parties_defenderesses = analysis.parties.get('defendeurs', [])
    
    if hasattr(analysis, 'infractions'):
        infractions = analysis.infractions
    
    # Interface de configuration
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**üè¢ Demandeurs (victimes)**")
        demandeurs_text = st.text_area(
            "Un par ligne",
            value='\n'.join(parties_demanderesses),
            height=100,
            key="demandeurs_input"
        )
        parties_demanderesses = [p.strip() for p in demandeurs_text.split('\n') if p.strip()]
        
        st.markdown("**üéØ Infractions**")
        infractions_text = st.text_area(
            "Une par ligne",
            value='\n'.join(infractions),
            height=100,
            key="infractions_input"
        )
        infractions = [i.strip() for i in infractions_text.split('\n') if i.strip()]
    
    with col2:
        st.markdown("**‚öñÔ∏è D√©fendeurs (mis en cause)**")
        defendeurs_text = st.text_area(
            "Un par ligne",
            value='\n'.join(parties_defenderesses),
            height=100,
            key="defendeurs_input"
        )
        parties_defenderesses = [p.strip() for p in defendeurs_text.split('\n') if p.strip()]
        
        st.markdown("**‚öôÔ∏è Options**")
        type_plainte = st.radio(
            "Type de plainte",
            ["Plainte simple", "Plainte avec CPC"],
            index=1 if is_partie_civile else 0,
            key="type_plainte_radio"
        )
        is_partie_civile = (type_plainte == "Plainte avec CPC")
        
        include_chronologie = st.checkbox("Inclure chronologie d√©taill√©e", value=True)
        include_prejudices = st.checkbox("D√©tailler les pr√©judices", value=True)
        include_jurisprudence = st.checkbox("Citer jurisprudences", value=is_partie_civile)
    
    # Enrichissement des parties si CompanyInfoManager disponible
    if st.checkbox("üè¢ Enrichir les informations des soci√©t√©s", value=True):
        if MANAGERS['company_info'] and (parties_demanderesses or parties_defenderesses):
            enriched_parties = await enrich_parties_info(
                parties_demanderesses + parties_defenderesses
            )
            
            if enriched_parties:
                with st.expander("üìä Informations enrichies", expanded=False):
                    for party in enriched_parties:
                        st.json(party)
    
    # Bouton de g√©n√©ration
    if st.button("üöÄ G√©n√©rer la plainte", type="primary", key="generate_plainte_btn"):
        # Pr√©parer l'analyse enrichie
        analysis_dict = {
            'parties': {
                'demandeurs': parties_demanderesses,
                'defendeurs': parties_defenderesses
            },
            'infractions': infractions,
            'reference': analysis.reference if hasattr(analysis, 'reference') else None,
            'options': {
                'is_partie_civile': is_partie_civile,
                'include_chronologie': include_chronologie,
                'include_prejudices': include_prejudices,
                'include_jurisprudence': include_jurisprudence
            }
        }
        
        # G√©n√©rer
        await generate_advanced_plainte(query)

# ========================= INTERFACE UTILISATEUR =========================

class SearchInterface:
    """Interface utilisateur pour le module de recherche"""
    
    def __init__(self):
        """Initialisation avec le service de recherche universelle"""
        if SEARCH_SERVICE_AVAILABLE:
            self.search_service = get_universal_search_service()
        else:
            self.search_service = None
        self.current_phase = PhaseProcedure.ENQUETE_PRELIMINAIRE
    
    async def process_universal_query(self, query: str):
        """Traite une requ√™te en utilisant le service de recherche"""
        
        # Sauvegarder la requ√™te
        st.session_state.last_universal_query = query
        
        # Analyser la requ√™te avec le service
        if self.search_service:
            query_analysis = self.search_service.analyze_query_advanced(query)
        else:
            # Fallback simple si le service n'est pas disponible
            query_analysis = self._simple_query_analysis(query)
        
        # Router selon le type de commande d√©tect√©
        if query_analysis.command_type == 'redaction':
            return await self._process_redaction_request(query, query_analysis)
        elif query_analysis.command_type == 'plainte':
            return await process_plainte_request(query, query_analysis)
        elif query_analysis.command_type == 'plaidoirie':
            return await self._process_plaidoirie_request(query, query_analysis)
        elif query_analysis.command_type == 'preparation_client':
            return await self._process_preparation_client_request(query, query_analysis)
        elif query_analysis.command_type == 'import':
            return await self._process_import_request(query, query_analysis)
        elif query_analysis.command_type == 'export':
            return await self._process_export_request(query, query_analysis)
        elif query_analysis.command_type == 'email':
            return await self._process_email_request(query, query_analysis)
        elif query_analysis.command_type == 'analysis':
            return await self._process_analysis_request(query, query_analysis)
        elif query_analysis.command_type == 'piece_selection':
            return await self._process_piece_selection_request(query, query_analysis)
        elif query_analysis.command_type == 'bordereau':
            return await self._process_bordereau_request(query, query_analysis)
        elif query_analysis.command_type == 'synthesis':
            return await self._process_synthesis_request(query, query_analysis)
        elif query_analysis.command_type == 'template':
            return await self._process_template_request(query, query_analysis)
        elif query_analysis.command_type == 'jurisprudence':
            return await self._process_jurisprudence_request(query, query_analysis)
        elif query_analysis.command_type == 'timeline':
            return await self._process_timeline_request(query, query_analysis)
        elif query_analysis.command_type == 'mapping':
            return await self._process_mapping_request(query, query_analysis)
        elif query_analysis.command_type == 'comparison':
            return await self._process_comparison_request(query, query_analysis)
        else:
            # Recherche par d√©faut
            return await self._process_search_request(query, query_analysis)
    
    def _simple_query_analysis(self, query: str) -> QueryAnalysis:
        """Analyse simple de la requ√™te si le service n'est pas disponible"""
        analysis = QueryAnalysis(
            original_query=query,
            query_lower=query.lower(),
            timestamp=datetime.now()
        )
        
        # D√©tection basique du type de commande
        query_lower = analysis.query_lower
        if any(word in query_lower for word in ['r√©dige', 'r√©diger', '√©crire', 'cr√©er']):
            analysis.command_type = 'redaction'
        else:
            analysis.command_type = 'search'
        
        # Extraction basique de la r√©f√©rence
        ref_match = re.search(r'@(\w+)', query)
        if ref_match:
            analysis.reference = ref_match.group(1)
        
        return analysis
    
    # ===================== PROCESSEURS DE REQU√äTES =====================
    
    async def _process_redaction_request(self, query: str, query_analysis: QueryAnalysis):
        """Traite une demande de r√©daction"""
        st.info("üìù D√©tection d'une demande de r√©daction...")
        
        if 'process_redaction_request' in MODULE_FUNCTIONS:
            return MODULE_FUNCTIONS['process_redaction_request'](query, query_analysis)
        else:
            st.warning("Module de r√©daction non disponible")
    
    async def _process_analysis_request(self, query: str, query_analysis: QueryAnalysis):
        """Traite une demande d'analyse"""
        if 'analyse_ia_page' in MODULE_FUNCTIONS:
            MODULE_FUNCTIONS['analyse_ia_page']()
        else:
            st.warning("Module d'analyse non disponible")
    
    async def _process_plaidoirie_request(self, query: str, query_analysis: QueryAnalysis):
        """Traite une demande de plaidoirie"""
        if 'process_plaidoirie_request' in MODULE_FUNCTIONS:
            return MODULE_FUNCTIONS['process_plaidoirie_request'](query, query_analysis)
        else:
            st.warning("Module plaidoirie non disponible")
    
    async def _process_preparation_client_request(self, query: str, query_analysis: QueryAnalysis):
        """Traite une demande de pr√©paration client"""
        if 'process_preparation_client_request' in MODULE_FUNCTIONS:
            return MODULE_FUNCTIONS['process_preparation_client_request'](query, query_analysis)
        else:
            st.warning("Module pr√©paration client non disponible")
    
    async def _process_import_request(self, query: str, query_analysis: QueryAnalysis):
        """Traite une demande d'import"""
        if 'process_import_request' in MODULE_FUNCTIONS:
            return MODULE_FUNCTIONS['process_import_request'](query, query_analysis)
        else:
            st.warning("Module import non disponible")
    
    async def _process_export_request(self, query: str, query_analysis: QueryAnalysis):
        """Traite une demande d'export"""
        if 'process_export_request' in MODULE_FUNCTIONS:
            return MODULE_FUNCTIONS['process_export_request'](query, query_analysis)
        else:
            st.warning("Module export non disponible")
    
    async def _process_email_request(self, query: str, query_analysis: QueryAnalysis):
        """Traite une demande d'email"""
        if 'process_email_request' in MODULE_FUNCTIONS:
            return MODULE_FUNCTIONS['process_email_request'](query, query_analysis)
        else:
            st.warning("Module email non disponible")
    
    async def _process_piece_selection_request(self, query: str, query_analysis: QueryAnalysis):
        """Traite une demande de s√©lection de pi√®ces"""
        if 'selection_piece_page' in MODULE_FUNCTIONS:
            MODULE_FUNCTIONS['selection_piece_page']()
        else:
            show_piece_selection_advanced(query_analysis)
    
    async def _process_bordereau_request(self, query: str, query_analysis: QueryAnalysis):
        """Traite une demande de bordereau"""
        if 'process_bordereau_request' in MODULE_FUNCTIONS:
            return MODULE_FUNCTIONS['process_bordereau_request'](query, query_analysis)
        else:
            docs = collect_available_documents(query_analysis)
            if docs:
                show_bordereau_interface_advanced(docs, query_analysis)
    
    async def _process_synthesis_request(self, query: str, query_analysis: QueryAnalysis):
        """Traite une demande de synth√®se"""
        if 'process_synthesis_request' in MODULE_FUNCTIONS:
            return MODULE_FUNCTIONS['process_synthesis_request'](query, query_analysis)
        elif st.session_state.get('selected_pieces'):
            return await synthesize_selected_pieces(st.session_state.selected_pieces)
        else:
            st.warning("Module synth√®se non disponible ou aucune pi√®ce s√©lectionn√©e")
    
    async def _process_template_request(self, query: str, query_analysis: QueryAnalysis):
        """Traite une demande de template"""
        if 'process_template_request' in MODULE_FUNCTIONS:
            return MODULE_FUNCTIONS['process_template_request'](query, query_analysis)
        else:
            st.warning("Module templates non disponible")
    
    async def _process_jurisprudence_request(self, query: str, query_analysis: QueryAnalysis):
        """Traite une demande de jurisprudence"""
        if 'process_jurisprudence_request' in MODULE_FUNCTIONS:
            return MODULE_FUNCTIONS['process_jurisprudence_request'](query, query_analysis)
        elif 'show_jurisprudence_interface' in MODULE_FUNCTIONS:
            MODULE_FUNCTIONS['show_jurisprudence_interface']()
        else:
            st.warning("Module jurisprudence non disponible")
    
    async def _process_timeline_request(self, query: str, query_analysis: QueryAnalysis):
        """Traite une demande de timeline"""
        if 'process_timeline_request' in MODULE_FUNCTIONS:
            return MODULE_FUNCTIONS['process_timeline_request'](query, query_analysis)
        else:
            st.warning("Module timeline non disponible")
    
    async def _process_mapping_request(self, query: str, query_analysis: QueryAnalysis):
        """Traite une demande de cartographie"""
        if 'process_mapping_request' in MODULE_FUNCTIONS:
            return MODULE_FUNCTIONS['process_mapping_request'](query, query_analysis)
        else:
            st.warning("Module cartographie non disponible")
    
    async def _process_comparison_request(self, query: str, query_analysis: QueryAnalysis):
        """Traite une demande de comparaison"""
        if 'process_comparison_request' in MODULE_FUNCTIONS:
            return MODULE_FUNCTIONS['process_comparison_request'](query, query_analysis)
        else:
            st.warning("Module comparaison non disponible")
    
    async def _process_search_request(self, query: str, query_analysis: QueryAnalysis):
        """Traite une demande de recherche par d√©faut"""
        st.info("üîç Recherche en cours...")
        
        if self.search_service:
            # Utiliser le service de recherche
            search_result = await self.search_service.search(query)
            
            # Stocker les r√©sultats
            st.session_state.search_results = search_result.documents
            
            if not search_result.documents:
                st.warning("‚ö†Ô∏è Aucun r√©sultat trouv√©")
            else:
                st.success(f"‚úÖ {len(search_result.documents)} r√©sultats trouv√©s")
                
                # Afficher les facettes si disponibles
                if search_result.facets:
                    with st.expander("üîç Filtres disponibles"):
                        for facet_name, facet_values in search_result.facets.items():
                            st.write(f"**{facet_name}**")
                            for value, count in facet_values.items():
                                st.write(f"- {value}: {count}")
                
                # Afficher les suggestions si disponibles
                if search_result.suggestions:
                    st.info("üí° Suggestions de recherche:")
                    cols = st.columns(min(len(search_result.suggestions), 3))
                    for i, suggestion in enumerate(search_result.suggestions):
                        with cols[i]:
                            if st.button(suggestion, key=f"suggestion_{i}", use_container_width=True):
                                st.session_state.pending_query = suggestion
                                st.rerun()
            
            return search_result
        else:
            # Fallback simple
            st.warning("Service de recherche non disponible")
            return []

# ========================= FONCTIONS UTILITAIRES =========================

def get_reference_suggestions(query: str) -> List[str]:
    """Obtient des suggestions de r√©f√©rences bas√©es sur la requ√™te"""
    
    suggestions = []
    
    if SEARCH_SERVICE_AVAILABLE:
        service = get_universal_search_service()
        
        # Extraire la partie apr√®s le dernier @
        if '@' in query:
            parts = query.split('@')
            partial_ref = parts[-1].strip().split()[0] if parts[-1].strip() else ''
            
            if partial_ref:
                suggestions = service.generate_reference_suggestions(partial_ref)
    
    return suggestions[:5]

def collect_all_references() -> List[str]:
    """Collecte toutes les r√©f√©rences de dossiers disponibles"""
    
    if SEARCH_SERVICE_AVAILABLE:
        service = get_universal_search_service()
        return service.collect_all_references()
    
    # Fallback
    references = set()
    
    # Parcourir tous les documents
    all_docs = {}
    all_docs.update(st.session_state.get('azure_documents', {}))
    all_docs.update(st.session_state.get('imported_documents', {}))
    
    for doc in all_docs.values():
        title = doc.get('title', '')
        
        # Patterns simples pour extraire les r√©f√©rences
        patterns = [
            r'affaire[_\s]+(\w+)',
            r'dossier[_\s]+(\w+)',
            r'projet[_\s]+(\w+)',
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, title, re.IGNORECASE)
            references.update(matches)
    
    return sorted(list(references))

def find_matching_documents(reference: str) -> List[Dict]:
    """Trouve les documents correspondant √† une r√©f√©rence partielle"""
    
    matches = []
    ref_lower = reference.lower()
    
    # Parcourir tous les documents
    all_docs = {}
    all_docs.update(st.session_state.get('azure_documents', {}))
    all_docs.update(st.session_state.get('imported_documents', {}))
    
    for doc_id, doc in all_docs.items():
        title = doc.get('title', '')
        content = doc.get('content', '')[:200]  # Aper√ßu du contenu
        
        # V√©rifier la correspondance
        if ref_lower in title.lower() or ref_lower in content.lower():
            # Extraire une r√©f√©rence propre du titre
            clean_ref = extract_clean_reference(title)
            
            matches.append({
                'id': doc_id,
                'title': title,
                'type': doc.get('type', 'Document'),
                'date': doc.get('date', doc.get('metadata', {}).get('date', 'Non dat√©')),
                'preview': content,
                'clean_ref': clean_ref or reference,
                'score': calculate_match_score(title, content, reference)
            })
    
    # Trier par score de pertinence
    matches.sort(key=lambda x: x['score'], reverse=True)
    return matches

def extract_clean_reference(title: str) -> str:
    """Extrait une r√©f√©rence propre du titre"""
    
    # Patterns pour extraire les r√©f√©rences
    patterns = [
        r'affaire[_\s]+(\w+)',
        r'dossier[_\s]+(\w+)',
        r'projet[_\s]+(\w+)',
        r'^(\w+_\d{4})',
        r'^(\w+)[\s_]',
    ]
    
    for pattern in patterns:
        match = re.search(pattern, title, re.IGNORECASE)
        if match:
            return match.group(1)
    
    # Si pas de pattern, prendre le premier mot significatif
    words = title.split()
    for word in words:
        if len(word) > 3 and word.isalnum():
            return word
    
    return None

def calculate_match_score(title: str, content: str, reference: str) -> float:
    """Calcule un score de pertinence pour le tri"""
    
    score = 0
    ref_lower = reference.lower()
    title_lower = title.lower()
    content_lower = content.lower()
    
    # Correspondance exacte dans le titre
    if ref_lower == title_lower:
        score += 100
    # Commence par la r√©f√©rence
    elif title_lower.startswith(ref_lower):
        score += 50
    # Contient la r√©f√©rence dans le titre
    elif ref_lower in title_lower:
        score += 30
    # Contient dans le contenu
    elif ref_lower in content_lower:
        score += 10
    
    # Bonus pour les r√©f√©rences courtes (plus sp√©cifiques)
    if len(reference) >= 5:
        score += 5
    
    return score

def highlight_match(text: str, match: str) -> str:
    """Surligne les correspondances dans le texte"""
    
    # √âchapper les caract√®res HTML
    text = html.escape(text)
    match = html.escape(match)
    
    # Remplacer avec surbrillance (insensible √† la casse)
    pattern = re.compile(re.escape(match), re.IGNORECASE)
    highlighted = pattern.sub(
        lambda m: f'<mark style="background-color: #ffeb3b; padding: 2px;">{m.group()}</mark>',
        text
    )
    
    return highlighted

def show_live_preview(reference: str, full_query: str):
    """Affiche une pr√©visualisation des dossiers correspondants"""
    
    with st.container():
        # Rechercher les correspondances
        matches = find_matching_documents(reference)
        
        if matches:
            st.markdown(f"### üìÅ Aper√ßu des r√©sultats pour **@{reference}**")
            
            # Limiter √† 5 r√©sultats
            for i, match in enumerate(matches[:5]):
                col1, col2, col3 = st.columns([3, 2, 1])
                
                with col1:
                    # Titre avec surbrillance
                    highlighted_title = highlight_match(match['title'], reference)
                    st.markdown(f"**{i+1}.** {highlighted_title}", unsafe_allow_html=True)
                
                with col2:
                    # M√©tadonn√©es
                    doc_type = match.get('type', 'Document')
                    date = match.get('date', 'Non dat√©')
                    st.caption(f"{doc_type} ‚Ä¢ {date}")
                
                with col3:
                    # Action rapide
                    if st.button("Utiliser", key=f"use_{match['id']}", use_container_width=True):
                        # Remplacer la r√©f√©rence partielle par la compl√®te
                        new_query = full_query.replace(f"@{reference}", f"@{match['clean_ref']}")
                        st.session_state.pending_query = new_query
                        st.rerun()
            
            # Afficher le nombre total si plus de 5
            if len(matches) > 5:
                st.info(f"üìä {len(matches) - 5} autres r√©sultats disponibles. Affinez votre recherche ou cliquez sur Rechercher.")
        else:
            st.info(f"üîç Aucun dossier trouv√© pour '@{reference}'. Essayez avec d'autres termes.")

def show_available_references():
    """Affiche toutes les r√©f√©rences disponibles de mani√®re organis√©e"""
    
    references = collect_all_references()
    
    if references:
        st.markdown("### üìö R√©f√©rences disponibles")
        
        # Grouper par premi√®re lettre
        grouped = {}
        for ref in references:
            first_letter = ref[0].upper()
            if first_letter not in grouped:
                grouped[first_letter] = []
            grouped[first_letter].append(ref)
        
        # Afficher en colonnes
        cols = st.columns(4)
        col_idx = 0
        
        for letter in sorted(grouped.keys()):
            with cols[col_idx % 4]:
                st.markdown(f"**{letter}**")
                for ref in grouped[letter]:
                    if st.button(f"@{ref}", key=f"ref_{ref}", use_container_width=True):
                        st.session_state.pending_query = f"@{ref} "
                        st.rerun()
            col_idx += 1
    else:
        st.info("Aucune r√©f√©rence trouv√©e. Importez des documents pour commencer.")

# ========================= FONCTION PRINCIPALE =========================

def show_page():
    """Fonction principale de la page recherche universelle avec toutes les am√©liorations"""
    
    # Initialiser l'interface
    if 'search_interface' not in st.session_state:
        st.session_state.search_interface = SearchInterface()
    
    interface = st.session_state.search_interface
    
    st.markdown("## üîç Recherche Universelle")
    
    # √âtat des modules
    if st.checkbox("üîß Voir l'√©tat des modules"):
        show_modules_status()
    
    # Barre de recherche principale avec auto-compl√©tion
    col1, col2 = st.columns([5, 1])
    
    with col1:
        default_value = ""
        if 'pending_query' in st.session_state:
            default_value = st.session_state.pending_query
            del st.session_state.pending_query
        elif 'universal_query' in st.session_state:
            default_value = st.session_state.universal_query
        
        query = st.text_input(
            "Entrez votre commande ou recherche",
            value=default_value,
            placeholder="Ex: r√©diger conclusions @affaire_martin, analyser risques, importer documents...",
            key="universal_query",
            help="Utilisez @ pour r√©f√©rencer une affaire sp√©cifique"
        )
        
        # Auto-compl√©tion des r√©f√©rences
        if query and '@' in query:
            suggestions = get_reference_suggestions(query)
            if suggestions:
                st.markdown("**Suggestions :**")
                cols = st.columns(min(len(suggestions), 5))
                for i, suggestion in enumerate(suggestions[:5]):
                    with cols[i]:
                        if st.button(suggestion, key=f"sugg_{i}", use_container_width=True):
                            # Remplacer la partie apr√®s @ par la suggestion
                            parts = query.split('@')
                            if len(parts) > 1:
                                # Garder ce qui est avant @ et ajouter la suggestion
                                new_query = parts[0] + suggestion
                                st.session_state.pending_query = new_query
                                st.rerun()
    
    with col2:
        search_button = st.button("üîç Rechercher", key="search_button", use_container_width=True)
    
    # Pr√©visualisation en temps r√©el
    if query and '@' in query:
        # Extraire la r√©f√©rence
        parts = query.split('@')
        if len(parts) > 1:
            ref_part = parts[-1].split()[0] if parts[-1].strip() else ''
            
            if ref_part and len(ref_part) >= 2:  # Au moins 2 caract√®res
                show_live_preview(ref_part, query)
    
    # Afficher les r√©f√©rences disponibles
    if st.checkbox("üìÅ Voir toutes les r√©f√©rences disponibles"):
        show_available_references()
    
    # Suggestions de commandes
    with st.expander("üí° Exemples de commandes", expanded=False):
        st.markdown("""
        **Recherche :**
        - `contrats soci√©t√© XYZ`
        - `@affaire_martin documents comptables`
        - `@mart` (trouvera martin, martinez, etc.)
        - `@2024` (tous les dossiers de 2024)
        
        **Analyse :**
        - `analyser les risques @dossier_p√©nal`
        - `identifier les infractions @affaire_corruption`
        
        **R√©daction :**
        - `r√©diger conclusions d√©fense @affaire_martin abus biens sociaux`
        - `cr√©er plainte avec constitution partie civile escroquerie`
        - `r√©diger plainte contre Vinci, SOGEPROM @projet_26_05_2025`
        
        **Synth√®se :**
        - `synth√©tiser les pi√®ces @dossier_fraude`
        - `r√©sumer les auditions @affaire_martin`
        
        **Gestion :**
        - `s√©lectionner pi√®ces @dossier cat√©gorie proc√©dure`
        - `cr√©er bordereau @pi√®ces_s√©lectionn√©es`
        - `importer documents PDF`
        - `exporter analyse format word`
        """)
    
    # Menu d'actions rapides
    show_quick_actions()
    
    # Traiter la requ√™te
    if query and (search_button or st.session_state.get('process_query', False)):
        with st.spinner("üîÑ Traitement en cours..."):
            # Utiliser une nouvelle boucle d'√©v√©nements
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                loop.run_until_complete(interface.process_universal_query(query))
            finally:
                loop.close()
    
    # Afficher les r√©sultats
    show_unified_results()
    
    # R√©initialiser le flag de traitement
    if 'process_query' in st.session_state:
        st.session_state.process_query = False
    
    # Footer avec actions
    st.markdown("---")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("üíæ Sauvegarder le travail", key="save_work"):
            save_current_work()
    
    with col2:
        if st.button("üìä Afficher les statistiques", key="show_stats"):
            if interface.search_service:
                # Afficher les statistiques du service de recherche
                stats = asyncio.run(interface.search_service.get_search_statistics())
                with st.expander("üìä Statistiques de recherche", expanded=True):
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("Recherches totales", stats['total_searches'])
                        st.metric("R√©sultats moyens", f"{stats['average_results']:.0f}")
                    with col2:
                        st.metric("Taille du cache", stats['cache_size'])
                    
                    if stats['popular_keywords']:
                        st.markdown("**Mots-cl√©s populaires:**")
                        for keyword, count in list(stats['popular_keywords'].items())[:5]:
                            st.write(f"- {keyword}: {count} fois")
            else:
                asyncio.run(show_work_statistics())
    
    with col3:
        if st.button("üîó Partager", key="share_work"):
            st.info("Fonctionnalit√© de partage √† impl√©menter")

def show_modules_status():
    """Affiche l'√©tat d√©taill√© des modules"""
    with st.expander("üîß √âtat des modules et fonctions", expanded=True):
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("Modules disponibles", sum(1 for v in MODULES_AVAILABLE.values() if v))
            st.metric("Fonctions import√©es", len(MODULE_FUNCTIONS))
        
        with col2:
            st.metric("Managers avanc√©s", sum(1 for v in MANAGERS.values() if v))
            st.metric("Service de recherche", "‚úÖ" if SEARCH_SERVICE_AVAILABLE else "‚ùå")
        
        with col3:
            st.metric("Templates", len(BUILTIN_DOCUMENT_TEMPLATES))
            st.metric("Styles", len(DEFAULT_STYLE_CONFIGS))
        
        # Liste d√©taill√©e
        st.markdown("### üìã Modules actifs")
        for module, available in MODULES_AVAILABLE.items():
            if available:
                st.success(f"‚úÖ {module}")
            else:
                st.error(f"‚ùå {module}")

def show_quick_actions():
    """Affiche les actions rapides"""
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        if st.button("üìù Nouvelle r√©daction", key="quick_redaction"):
            st.session_state.pending_query = "r√©diger "
            st.session_state.process_query = True
            st.rerun()
    
    with col2:
        if st.button("ü§ñ Analyser dossier", key="quick_analysis"):
            st.session_state.pending_query = "analyser "
            st.session_state.process_query = True
            st.rerun()
    
    with col3:
        if st.button("üì• Importer", key="quick_import"):
            st.session_state.pending_query = "importer documents"
            st.session_state.process_query = True
            st.rerun()
    
    with col4:
        if st.button("üîÑ R√©initialiser", key="quick_reset"):
            clear_universal_state()

def show_unified_results():
    """Affiche tous les types de r√©sultats de mani√®re unifi√©e"""
    
    # V√©rifier tous les types de r√©sultats possibles
    results_found = False
    
    # R√©sultats de r√©daction
    if st.session_state.get('redaction_result'):
        show_redaction_results()
        results_found = True
    
    # Plainte g√©n√©r√©e
    elif st.session_state.get('generated_plainte'):
        show_plainte_results()
        results_found = True
    
    # R√©sultats d'analyse
    elif st.session_state.get('ai_analysis_results'):
        show_analysis_results()
        results_found = True
    
    # R√©sultats de recherche
    elif st.session_state.get('search_results'):
        show_search_results()
        results_found = True
    
    # R√©sultats de synth√®se
    elif st.session_state.get('synthesis_result'):
        show_synthesis_results()
        results_found = True
    
    # Autres r√©sultats...
    elif st.session_state.get('timeline_result'):
        show_timeline_results()
        results_found = True
    
    elif st.session_state.get('bordereau_result'):
        show_bordereau_results()
        results_found = True
    
    elif st.session_state.get('jurisprudence_results'):
        show_jurisprudence_results()
        results_found = True
    
    if not results_found:
        st.info("üí° Utilisez la barre de recherche universelle pour commencer")

def show_redaction_results():
    """Affiche les r√©sultats de r√©daction"""
    result = st.session_state.redaction_result
    
    st.markdown("### üìù Document juridique g√©n√©r√©")
    
    # Contenu √©ditable
    edited_content = st.text_area(
        "Contenu du document",
        value=result.get('document', result.get('content', '')),
        height=600,
        key="edit_redaction"
    )
    
    # Actions
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.download_button(
            "üì• T√©l√©charger",
            edited_content.encode('utf-8'),
            f"document_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
            "text/plain"
        )
    
    with col2:
        if st.button("üìß Envoyer"):
            st.session_state.pending_email = {'content': edited_content}
    
    with col3:
        if st.button("üîÑ R√©g√©n√©rer"):
            st.session_state.process_query = True
            st.rerun()

def show_plainte_results():
    """Affiche les r√©sultats de g√©n√©ration de plainte"""
    content = st.session_state.generated_plainte
    
    st.markdown("### üìã Plainte g√©n√©r√©e")
    
    # Options avanc√©es si disponibles
    col1, col2 = st.columns([3, 1])
    with col2:
        if st.button("‚ú® Version avanc√©e", key="upgrade_plainte"):
            query = st.session_state.get('last_universal_query', '')
            asyncio.run(generate_advanced_plainte(query))
    
    # Contenu √©ditable
    edited_content = st.text_area(
        "Contenu de la plainte",
        value=content,
        height=600,
        key="edit_plainte"
    )
    
    # Actions
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.download_button(
            "üì• T√©l√©charger",
            edited_content.encode('utf-8'),
            f"plainte_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
            "text/plain"
        )
    
    with col2:
        if st.button("üìä Statistiques", key="stats_plainte"):
            show_plainte_statistics(edited_content)
    
    with col3:
        if st.button("‚úÖ V√©rifier", key="verify_plainte"):
            verify_jurisprudences_in_plainte(edited_content)
    
    with col4:
        if st.button("üîÑ R√©g√©n√©rer", key="regen_plainte"):
            st.session_state.process_query = True
            st.rerun()

def show_analysis_results():
    """Affiche les r√©sultats d'analyse"""
    results = st.session_state.ai_analysis_results
    
    st.markdown("### ü§ñ R√©sultats de l'analyse")
    
    # Contenu
    st.text_area(
        "Analyse",
        value=results.get('content', ''),
        height=400,
        key="analysis_content"
    )
    
    # M√©tadonn√©es
    if results.get('document_count'):
        st.info(f"üìÑ Documents analys√©s : {results['document_count']}")

def show_search_results():
    """Affiche les r√©sultats de recherche avec highlights"""
    results = st.session_state.search_results
    
    if isinstance(results, list) and results:
        st.markdown(f"### üîç R√©sultats de recherche ({len(results)} documents)")
        
        # Options de tri
        col1, col2 = st.columns([3, 1])
        with col2:
            sort_option = st.selectbox(
                "Trier par",
                ["Pertinence", "Date", "Type"],
                key="sort_results"
            )
        
        # Afficher les r√©sultats
        for i, result in enumerate(results[:10], 1):
            # Si c'est un objet Document
            if hasattr(result, 'highlights'):
                with st.expander(f"{i}. {result.title}"):
                    # Afficher les highlights s'ils existent
                    if result.highlights:
                        st.markdown("**üìå Extraits pertinents:**")
                        for highlight in result.highlights:
                            st.info(f"...{highlight}...")
                    else:
                        st.write(result.content[:500] + '...')
                    
                    # M√©tadonn√©es
                    if hasattr(result, 'metadata') and result.metadata:
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.caption(f"üìä Score: {result.metadata.get('score', 0):.0f}")
                        with col2:
                            st.caption(f"üìÅ Source: {result.source}")
                        with col3:
                            match_type = result.metadata.get('match_type', 'standard')
                            if match_type == 'exact':
                                st.caption("‚úÖ Correspondance exacte")
                            elif match_type == 'partial':
                                st.caption("üìç Correspondance partielle")
            else:
                # Format dictionnaire
                with st.expander(f"{i}. {result.get('title', 'Sans titre')}"):
                    st.write(result.get('content', '')[:500] + '...')
                    st.caption(f"Score: {result.get('score', 0):.0%}")
        
        # Pagination si plus de 10 r√©sultats
        if len(results) > 10:
            st.info(f"üìÑ Affichage des 10 premiers r√©sultats sur {len(results)}. Utilisez les filtres pour affiner.")

def show_synthesis_results():
    """Affiche les r√©sultats de synth√®se"""
    result = st.session_state.synthesis_result
    
    st.markdown("### üìù Synth√®se des documents")
    
    st.text_area(
        "Contenu de la synth√®se",
        value=result.get('content', ''),
        height=400,
        key="synthesis_content"
    )
    
    if result.get('piece_count'):
        st.info(f"üìÑ Pi√®ces analys√©es : {result['piece_count']}")

def show_timeline_results():
    """Affiche les r√©sultats de timeline"""
    st.markdown("### ‚è±Ô∏è Chronologie des √©v√©nements")
    st.info("Timeline g√©n√©r√©e")

def show_bordereau_results():
    """Affiche les r√©sultats de bordereau"""
    st.markdown("### üìä Bordereau de communication")
    st.info("Bordereau g√©n√©r√©")

def show_jurisprudence_results():
    """Affiche les r√©sultats de jurisprudence"""
    st.markdown("### ‚öñÔ∏è Jurisprudences trouv√©es")
    st.info("R√©sultats de jurisprudence")

def clear_universal_state():
    """Efface l'√©tat de l'interface universelle"""
    keys_to_clear = [
        'universal_query', 'last_universal_query', 'current_analysis',
        'redaction_result', 'ai_analysis_results', 'search_results',
        'synthesis_result', 'selected_pieces', 'import_files',
        'generated_plainte', 'timeline_result', 'bordereau_result',
        'jurisprudence_results'
    ]
    
    for key in keys_to_clear:
        if key in st.session_state:
            del st.session_state[key]
    
    # Effacer aussi le cache du service
    if hasattr(st.session_state, 'search_interface') and st.session_state.search_interface.search_service:
        st.session_state.search_interface.search_service.clear_cache()
    
    st.success("‚úÖ Interface r√©initialis√©e")
    st.rerun()

# ========================= POINT D'ENTR√âE =========================

if __name__ == "__main__":
    show_page()