# modules/advanced_features.py
"""Fonctionnalit√©s avanc√©es de l'assistant juridique - √Ä pr√©server"""

import streamlit as st
from datetime import datetime
from typing import Dict, Any, List, Optional, Tuple
import re
import asyncio

# Managers avanc√©s - Import conditionnel
MANAGERS = {
    'company_info': False,
    'jurisprudence_verifier': False,
    'style_analyzer': False,
    'dynamic_generators': False,
    'document_manager': False,
    'legal_search': False,
    'multi_llm': False
}

# Import des managers avec gestion d'erreur individuelle
try:
    from managers.company_info_manager import CompanyInfoManager
    MANAGERS['company_info'] = True
except ImportError as e:
    print(f"Import CompanyInfoManager failed: {e}")

try:
    from managers.jurisprudence_verifier import JurisprudenceVerifier
    MANAGERS['jurisprudence_verifier'] = True
except ImportError as e:
    print(f"Import JurisprudenceVerifier failed: {e}")

try:
    from managers.style_analyzer import StyleAnalyzer
    MANAGERS['style_analyzer'] = True
except ImportError as e:
    print(f"Import StyleAnalyzer failed: {e}")

try:
    # Essayer d'importer DynamicGenerators - peut-√™tre que la classe a un nom diff√©rent
    from managers.dynamic_generators import DynamicGenerator  # ou DynamicGen ou autre
    MANAGERS['dynamic_generators'] = True
    DynamicGenerators = DynamicGenerator  # Alias si n√©cessaire
except ImportError:
    try:
        from managers.dynamic_generators import DynamicGenerators
        MANAGERS['dynamic_generators'] = True
    except ImportError as e:
        print(f"Import DynamicGenerators failed: {e}")

try:
    from managers.document_manager import DocumentManager
    MANAGERS['document_manager'] = True
except ImportError as e:
    print(f"Import DocumentManager failed: {e}")

try:
    from managers.legal_search import LegalSearchManager
    MANAGERS['legal_search'] = True
except ImportError as e:
    print(f"Import LegalSearchManager failed: {e}")

try:
    from managers.multi_llm_manager import MultiLLMManager
    MANAGERS['multi_llm'] = True
except ImportError as e:
    print(f"Import MultiLLMManager failed: {e}")

# V√©rifier si au moins un manager est disponible
HAS_MANAGERS = any(MANAGERS.values())

# Ne pas afficher de message ici car √ßa peut interf√©rer avec Streamlit

# APIs - Import conditionnel
try:
    from utils.api_utils import get_available_models, call_llm_api
    HAS_API_UTILS = True
except ImportError:
    HAS_API_UTILS = False

# ========================= CONFIGURATION =========================

# Styles de r√©daction
REDACTION_STYLES = {
    'formel': {
        'name': 'Formel',
        'description': 'Style juridique classique et solennel',
        'tone': 'respectueux et distant',
        'vocabulary': 'technique et pr√©cis'
    },
    'persuasif': {
        'name': 'Persuasif',
        'description': 'Style argumentatif et convaincant',
        'tone': 'assertif et engag√©',
        'vocabulary': 'percutant et imag√©'
    },
    'technique': {
        'name': 'Technique',
        'description': 'Style factuel et d√©taill√©',
        'tone': 'neutre et objectif',
        'vocabulary': 'sp√©cialis√© et exhaustif'
    },
    'synth√©tique': {
        'name': 'Synth√©tique',
        'description': 'Style concis et efficace',
        'tone': 'direct et clair',
        'vocabulary': 'simple et pr√©cis'
    },
    'p√©dagogique': {
        'name': 'P√©dagogique',
        'description': 'Style explicatif et accessible',
        'tone': 'bienveillant et didactique',
        'vocabulary': 'vulgaris√© et illustr√©'
    }
}

# Templates de documents pr√©d√©finis
DOCUMENT_TEMPLATES = {
    'conclusions_defense': {
        'name': 'Conclusions en d√©fense',
        'structure': [
            'I. FAITS ET PROC√âDURE',
            'II. DISCUSSION',
            ' A. Sur la recevabilit√©',
            ' B. Sur le fond',
            ' 1. Sur l\'√©l√©ment mat√©riel',
            ' 2. Sur l\'√©l√©ment intentionnel',
            ' 3. Sur le pr√©judice',
            'III. PAR CES MOTIFS'
        ],
        'style': 'formel'
    },
    'plainte_simple': {
        'name': 'Plainte simple',
        'structure': [
            'Objet : Plainte',
            'EXPOS√â DES FAITS',
            'QUALIFICATION JURIDIQUE',
            'PR√âJUDICES SUBIS',
            'DEMANDES',
            'PI√àCES JOINTES'
        ],
        'style': 'formel'
    },
    'plainte_avec_cpc': {
        'name': 'Plainte avec constitution de partie civile',
        'structure': [
            'Objet : Plainte avec constitution de partie civile',
            'EXPOS√â DES FAITS',
            'QUALIFICATION JURIDIQUE',
            'PR√âJUDICES SUBIS',
            'CONSTITUTION DE PARTIE CIVILE',
            '√âVALUATION DU PR√âJUDICE',
            'DEMANDES',
            'PI√àCES JOINTES'
        ],
        'style': 'formel'
    },
    'mise_en_demeure': {
        'name': 'Mise en demeure',
        'structure': [
            'MISE EN DEMEURE',
            'Rappel des faits',
            'Obligations non respect√©es',
            'D√©lai accord√©',
            'Cons√©quences du d√©faut',
            'R√©serves'
        ],
        'style': 'persuasif'
    },
    'note_synthese': {
        'name': 'Note de synth√®se',
        'structure': [
            'SYNTH√àSE EX√âCUTIVE',
            'I. CONTEXTE',
            'II. ANALYSE',
            'III. RECOMMANDATIONS',
            'IV. PLAN D\'ACTION'
        ],
        'style': 'synth√©tique'
    }
}

# ========================= G√âN√âRATION AVANC√âE DE PLAINTES =========================

async def generate_advanced_plainte(query: str):
    """G√©n√®re une plainte avanc√©e avec toutes les fonctionnalit√©s"""
    
    st.markdown("### üöÄ G√©n√©ration avanc√©e de plainte")
    
    # Analyser la requ√™te
    analysis = analyze_plainte_request(query)
    
    # V√©rifier si CPC
    is_cpc = check_if_cpc_required(query)
    
    if is_cpc:
        st.info("üìã G√©n√©ration d'une plainte avec constitution de partie civile EXHAUSTIVE")
        await generate_exhaustive_cpc_plainte(analysis)
    else:
        await generate_standard_plainte(analysis)

def analyze_plainte_request(query: str) -> Dict[str, Any]:
    """Analyse la requ√™te pour extraire les informations"""
    
    # Extraction des parties
    parties_pattern = r'contre\s+([A-Z][A-Za-z\s,&]+?)(?:\s+et\s+|,\s*|$)'
    parties = re.findall(parties_pattern, query, re.IGNORECASE)
    
    # Extraction des infractions
    infractions = []
    infractions_keywords = {
        'abus de biens sociaux': 'Abus de biens sociaux',
        'abs': 'Abus de biens sociaux',
        'corruption': 'Corruption',
        'escroquerie': 'Escroquerie',
        'abus de confiance': 'Abus de confiance',
        'blanchiment': 'Blanchiment'
    }
    
    query_lower = query.lower()
    for keyword, infraction in infractions_keywords.items():
        if keyword in query_lower:
            infractions.append(infraction)
    
    return {
        'parties': parties,
        'infractions': infractions or ['Abus de biens sociaux'],  # Par d√©faut
        'query': query
    }

def check_if_cpc_required(query: str) -> bool:
    """V√©rifie si une CPC est requise"""
    cpc_indicators = [
        'constitution de partie civile',
        'cpc',
        'partie civile',
        'exhaustive',
        'compl√®te'
    ]
    
    query_lower = query.lower()
    return any(indicator in query_lower for indicator in cpc_indicators)

async def generate_exhaustive_cpc_plainte(analysis: Dict[str, Any]):
    """G√©n√®re une plainte CPC exhaustive de 8000+ mots"""
    
    with st.spinner("‚è≥ G√©n√©ration d'une plainte exhaustive en cours... (cela peut prendre 2-3 minutes)"):
        
        # Options de g√©n√©ration
        col1, col2, col3 = st.columns(3)
        
        with col1:
            temperature = st.slider(
                "üå°Ô∏è Cr√©ativit√©",
                min_value=0.0,
                max_value=1.0,
                value=0.3,
                step=0.1,
                help="Plus bas = plus factuel, Plus haut = plus cr√©atif"
            )
        
        with col2:
            model = "claude-3-sonnet" 
            if HAS_API_UTILS:
                models = get_available_models()
                if models:
                    model = st.selectbox("ü§ñ Mod√®le", models, index=0)
        
        with col3:
            enrich_parties = st.checkbox(
                "üè¢ Enrichir les parties",
                value=True,
                help="Rechercher des informations sur les soci√©t√©s"
            )
        
        # Enrichissement des parties si demand√©
        enriched_parties = analysis['parties']
        if enrich_parties and HAS_MANAGERS:
            enriched_parties = await enrich_parties_info(analysis['parties'])
        
        # G√©n√©rer le prompt d√©taill√©
        prompt = create_exhaustive_cpc_prompt(
            parties=enriched_parties,
            infractions=analysis['infractions']
        )
        
        # Appel √† l'API
        try:
            if HAS_API_UTILS:
                response = await call_llm_api(
                    prompt=prompt,
                    model=model,
                    temperature=temperature,
                    max_tokens=8000
                )
                
                # Stocker le r√©sultat
                st.session_state.generated_plainte = response
                st.session_state.search_results = {
                    'type': 'plainte_avancee',
                    'content': response,
                    'metadata': {
                        'parties': enriched_parties,
                        'infractions': analysis['infractions'],
                        'model': model,
                        'length': len(response.split())
                    }
                }
                
                # Afficher les statistiques
                show_plainte_statistics(response)
                
                # V√©rifier les jurisprudences si disponible
                if HAS_MANAGERS:
                    verify_jurisprudences_in_plainte(response)
                
                # Suggestions d'am√©lioration
                show_improvement_suggestions(response)
                
            else:
                # Fallback sans API
                st.warning("API non disponible - G√©n√©ration d'un mod√®le de plainte")
                generate_plainte_template(enriched_parties, analysis['infractions'])
                
        except Exception as e:
            st.error(f"Erreur lors de la g√©n√©ration : {str(e)}")

async def generate_standard_plainte(analysis: Dict[str, Any]):
    """G√©n√®re une plainte standard"""
    
    with st.spinner("‚è≥ G√©n√©ration de la plainte..."):
        
        # Options simplifi√©es
        col1, col2 = st.columns(2)
        
        with col1:
            plainte_type = st.selectbox(
                "Type de plainte",
                ["Simple", "Avec constitution de partie civile"],
                index=1
            )
        
        with col2:
            include_jurisprudence = st.checkbox(
                "üìö Inclure jurisprudences",
                value=True
            )
        
        # G√©n√©rer
        if HAS_API_UTILS:
            prompt = create_standard_plainte_prompt(
                parties=analysis['parties'],
                infractions=analysis['infractions'],
                plainte_type=plainte_type,
                include_jurisprudence=include_jurisprudence
            )
            
            try:
                response = await call_llm_api(
                    prompt=prompt,
                    model="claude-3-sonnet",
                    temperature=0.3
                )
                
                st.session_state.generated_plainte = response
                st.session_state.search_results = {
                    'type': 'plainte',
                    'content': response
                }
                
            except Exception as e:
                st.error(f"Erreur : {str(e)}")
        else:
            generate_plainte_template(analysis['parties'], analysis['infractions'])

# ========================= ENRICHISSEMENT DES PARTIES =========================

async def enrich_parties_info(parties: List[str]) -> List[Dict[str, Any]]:
    """Enrichit les informations sur les parties"""
    
    if not HAS_MANAGERS:
        return [{'name': p} for p in parties]
    
    enriched = []
    company_manager = CompanyInfoManager()
    
    for party in parties:
        with st.spinner(f"üîç Recherche d'informations sur {party}..."):
            info = await company_manager.get_company_info(party)
            
            if info:
                enriched.append({
                    'name': party,
                    'siren': info.get('siren'),
                    'address': info.get('address'),
                    'legal_form': info.get('legal_form'),
                    'capital': info.get('capital'),
                    'executives': info.get('executives', [])
                })
            else:
                enriched.append({'name': party})
    
    return enriched

# ========================= CR√âATION DES PROMPTS =========================

def create_exhaustive_cpc_prompt(parties: List[Any], infractions: List[str]) -> str:
    """Cr√©e un prompt pour une plainte CPC exhaustive"""
    
    parties_text = format_parties_for_prompt(parties)
    infractions_text = ', '.join(infractions)
    
    return f"""
R√©digez une plainte avec constitution de partie civile EXHAUSTIVE et D√âTAILL√âE d'au moins 8000 mots.

PARTIES MISES EN CAUSE :
{parties_text}

INFRACTIONS √Ä D√âVELOPPER :
{infractions_text}

STRUCTURE IMPOS√âE :

1. EN-T√äTE COMPLET
   - Destinataire (Doyen des juges d'instruction)
   - Plaignant (√† compl√©ter)
   - Objet d√©taill√©

2. EXPOS√â EXHAUSTIF DES FAITS (3000+ mots)
   - Contexte d√©taill√© de l'affaire
   - Chronologie pr√©cise et compl√®te
   - Description minutieuse de chaque fait
   - Liens entre les protagonistes
   - Montants et pr√©judices d√©taill√©s

3. DISCUSSION JURIDIQUE APPROFONDIE (3000+ mots)
   Pour chaque infraction :
   - Rappel complet des textes
   - Analyse d√©taill√©e des √©l√©ments constitutifs
   - Application aux faits esp√®ce par esp√®ce
   - Jurisprudences pertinentes cit√©es
   - R√©futation des arguments contraires

4. PR√âJUDICES D√âTAILL√âS (1000+ mots)
   - Pr√©judice financier chiffr√©
   - Pr√©judice moral d√©velopp√©
   - Pr√©judice d'image
   - Autres pr√©judices

5. DEMANDES ET CONCLUSION (1000+ mots)
   - Constitution de partie civile motiv√©e
   - Demandes d'actes pr√©cises
   - Mesures conservatoires
   - Provision sur dommages-int√©r√™ts

CONSIGNES :
- Style juridique soutenu et pr√©cis
- Citations de jurisprudences r√©centes
- Argumentation implacable
- Aucune zone d'ombre
- Anticipation des contre-arguments
"""

def create_standard_plainte_prompt(parties: List[str], infractions: List[str], 
                                  plainte_type: str, include_jurisprudence: bool) -> str:
    """Cr√©e un prompt pour une plainte standard"""
    
    parties_text = ', '.join(parties)
    infractions_text = ', '.join(infractions)
    
    jurisprudence_instruction = ""
    if include_jurisprudence:
        jurisprudence_instruction = "\n- Citez au moins 3 jurisprudences pertinentes"
    
    return f"""
R√©digez une {plainte_type} concernant :
- Parties : {parties_text}
- Infractions : {infractions_text}

Structure :
1. En-t√™te et qualit√©s
2. Expos√© des faits
3. Discussion juridique
4. Pr√©judices
5. Demandes

Consignes :
- Style juridique professionnel
- Argumentation structur√©e{jurisprudence_instruction}
- Environ 2000-3000 mots
"""

def format_parties_for_prompt(parties: List[Any]) -> str:
    """Formate les parties pour le prompt"""
    
    if not parties:
        return "√Ä COMPL√âTER"
    
    formatted = []
    for party in parties:
        if isinstance(party, dict):
            text = f"- {party['name']}"
            if party.get('siren'):
                text += f" (SIREN: {party['siren']})"
            if party.get('address'):
                text += f"\n  Si√®ge: {party['address']}"
            if party.get('executives'):
                text += f"\n  Dirigeants: {', '.join(party['executives'][:3])}"
            formatted.append(text)
        else:
            formatted.append(f"- {party}")
    
    return '\n'.join(formatted)

# ========================= V√âRIFICATION ET ANALYSE =========================

def verify_jurisprudences_in_plainte(content: str):
    """V√©rifie les jurisprudences cit√©es dans la plainte"""
    
    if not HAS_MANAGERS:
        return
    
    with st.expander("üîç V√©rification des jurisprudences"):
        verifier = JurisprudenceVerifier()
        
        # Extraire les r√©f√©rences
        jurisprudence_pattern = r'(Cass\.\s+\w+\.?,?\s+\d{1,2}\s+\w+\s+\d{4}|C\.\s*cass\.\s*\w+\.?\s*\d{1,2}\s+\w+\s+\d{4})'
        references = re.findall(jurisprudence_pattern, content)
        
        if references:
            st.write(f"**{len(references)} r√©f√©rences trouv√©es**")
            
            verified = 0
            for ref in references[:5]:  # V√©rifier les 5 premi√®res
                if verifier.verify_reference(ref):
                    st.success(f"‚úÖ {ref}")
                    verified += 1
                else:
                    st.warning(f"‚ö†Ô∏è {ref} - Non v√©rifi√©e")
            
            reliability = (verified / len(references[:5])) * 100
            st.metric("Taux de fiabilit√©", f"{reliability:.0f}%")
        else:
            st.info("Aucune jurisprudence d√©tect√©e")

def show_plainte_statistics(content: str):
    """Affiche les statistiques de la plainte"""
    
    with st.expander("üìä Statistiques du document"):
        words = content.split()
        sentences = content.split('.')
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("Mots", len(words))
        
        with col2:
            st.metric("Phrases", len(sentences))
        
        with col3:
            st.metric("Pages estim√©es", f"~{len(words) // 250}")
        
        # Analyse du style si disponible
        if HAS_MANAGERS:
            analyzer = StyleAnalyzer()
            style_score = analyzer.analyze_style(content)
            
            st.markdown("**Analyse du style :**")
            st.progress(style_score / 100)
            st.caption(f"Score de qualit√© : {style_score}/100")

def show_improvement_suggestions(content: str):
    """Sugg√®re des am√©liorations pour la plainte"""
    
    with st.expander("üí° Suggestions d'am√©lioration"):
        suggestions = []
        
        # V√©rifier la longueur
        word_count = len(content.split())
        if word_count < 2000:
            suggestions.append("üìù D√©velopper davantage l'expos√© des faits")
        
        # V√©rifier les citations
        if content.count('"') < 4:
            suggestions.append("üìö Ajouter plus de citations de jurisprudence")
        
        # V√©rifier les montants
        if not re.search(r'\d+\s*‚Ç¨|\d+\s*euros', content):
            suggestions.append("üí∞ Chiffrer pr√©cis√©ment les pr√©judices")
        
        # V√©rifier la structure
        required_sections = ['FAITS', 'DISCUSSION', 'PR√âJUDICE', 'DEMANDE']
        missing = [s for s in required_sections if s not in content.upper()]
        if missing:
            suggestions.append(f"üìã Ajouter sections : {', '.join(missing)}")
        
        if suggestions:
            for suggestion in suggestions:
                st.write(suggestion)
        else:
            st.success("‚úÖ La plainte semble compl√®te !")

# ========================= COMPARAISON MULTI-IA =========================

async def compare_ai_generations(prompt: str, models: List[str] = None):
    """Compare les g√©n√©rations de plusieurs IA"""
    
    if not HAS_API_UTILS:
        st.warning("Comparaison multi-IA non disponible")
        return
    
    st.markdown("### ü§ñ Comparaison Multi-IA")
    
    if not models:
        models = get_available_models()[:3]  # Top 3 mod√®les
    
    results = {}
    
    # G√©n√©rer avec chaque mod√®le
    cols = st.columns(len(models))
    
    for idx, model in enumerate(models):
        with cols[idx]:
            with st.spinner(f"G√©n√©ration {model}..."):
                try:
                    response = await call_llm_api(
                        prompt=prompt,
                        model=model,
                        temperature=0.3,
                        max_tokens=2000
                    )
                    results[model] = response
                    st.success(f"‚úÖ {model}")
                except Exception as e:
                    st.error(f"‚ùå {model}: {str(e)}")
    
    # Afficher les r√©sultats
    if results:
        st.markdown("#### R√©sultats")
        
        selected_model = st.radio(
            "Choisir le meilleur r√©sultat",
            list(results.keys())
        )
        
        st.text_area(
            f"R√©sultat {selected_model}",
            results[selected_model],
            height=400
        )
        
        if st.button("‚úÖ Utiliser ce r√©sultat"):
            st.session_state.generated_plainte = results[selected_model]
            st.success("R√©sultat s√©lectionn√© !")

# ========================= TEMPLATES DE FALLBACK =========================

def generate_plainte_template(parties: List[Any], infractions: List[str]):
    """G√©n√®re un template de plainte sans API"""
    
    parties_text = format_parties_list(parties)
    infractions_text = '\n'.join([f"- {inf}" for inf in infractions])
    
    template = f"""
PLAINTE AVEC CONSTITUTION DE PARTIE CIVILE

Monsieur le Doyen des Juges d'Instruction
Tribunal Judiciaire de [VILLE]
[ADRESSE]

[VILLE], le {datetime.now().strftime('%d/%m/%Y')}

OBJET : Plainte avec constitution de partie civile

Monsieur le Doyen,

Je soussign√©(e) [NOM PR√âNOM]
N√©(e) le [DATE] √† [LIEU]
De nationalit√© fran√ßaise
Profession : [PROFESSION]
Demeurant : [ADRESSE COMPL√àTE]
T√©l√©phone : [T√âL√âPHONE]
Email : [EMAIL]

Ai l'honneur de porter plainte avec constitution de partie civile contre :

{parties_text}

Pour les faits suivants :

I. EXPOS√â DES FAITS

[D√âVELOPPER ICI L'EXPOS√â D√âTAILL√â DES FAITS EN SUIVANT UN ORDRE CHRONOLOGIQUE]

II. DISCUSSION JURIDIQUE

Les faits expos√©s ci-dessus sont susceptibles de recevoir les qualifications suivantes :

{infractions_text}

[D√âVELOPPER L'ANALYSE JURIDIQUE POUR CHAQUE INFRACTION]

III. PR√âJUDICES

Les agissements d√©crits m'ont caus√© un pr√©judice :
- Mat√©riel : [MONTANT] euros
- Moral : [DESCRIPTION]

IV. CONSTITUTION DE PARTIE CIVILE

Je me constitue partie civile et demande :
- La d√©signation d'un juge d'instruction
- La condamnation des mis en cause
- La r√©paration int√©grale de mon pr√©judice

Je verse la consignation fix√©e par Monsieur le Doyen.

Je vous prie d'agr√©er, Monsieur le Doyen, l'expression de ma consid√©ration distingu√©e.

[SIGNATURE]

Pi√®ces jointes :
- [LISTE DES PI√àCES]
"""
    
    st.session_state.generated_plainte = template
    st.session_state.search_results = {
        'type': 'plainte_template',
        'content': template
    }

def format_parties_list(parties: List[Any]) -> str:
    """Formate la liste des parties pour le template"""
    
    if not parties:
        return "- [NOM DE LA PARTIE]\n  [FORME JURIDIQUE]\n  [SI√àGE SOCIAL]\n  [SIREN]"
    
    formatted = []
    for party in parties:
        if isinstance(party, dict):
            formatted.append(f"- {party.get('name', '[NOM]')}")
            if party.get('legal_form'):
                formatted.append(f"  {party['legal_form']}")
            if party.get('address'):
                formatted.append(f"  {party['address']}")
            if party.get('siren'):
                formatted.append(f"  SIREN : {party['siren']}")
        else:
            formatted.append(f"- {party}")
            formatted.append("  [FORME JURIDIQUE]")
            formatted.append("  [SI√àGE SOCIAL]")
            formatted.append("  [SIREN]")
    
    return '\n'.join(formatted)

# ========================= RECHERCHE JURIDIQUE AVANC√âE =========================

async def perform_legal_search(query: str, options: Dict[str, Any] = None):
    """Effectue une recherche juridique avanc√©e"""
    
    if not MANAGERS['legal_search']:
        st.warning("Module de recherche juridique non disponible")
        return None
    
    with st.spinner("üîç Recherche juridique en cours..."):
        legal_search = LegalSearchManager()
        
        # Options de recherche
        col1, col2, col3 = st.columns(3)
        
        with col1:
            search_type = st.selectbox(
                "Type de recherche",
                ["Jurisprudence", "Doctrine", "Textes l√©gaux", "Tout"],
                index=3
            )
        
        with col2:
            jurisdiction = st.selectbox(
                "Juridiction",
                ["Toutes", "Cour de cassation", "Cours d'appel", "Tribunaux"],
                index=0
            )
        
        with col3:
            date_filter = st.selectbox(
                "P√©riode",
                ["Toutes", "1 an", "5 ans", "10 ans"],
                index=1
            )
        
        # Recherche
        try:
            results = await legal_search.search(
                query=query,
                search_type=search_type,
                jurisdiction=jurisdiction,
                date_filter=date_filter
            )
            
            # Afficher les r√©sultats
            if results:
                st.success(f"‚úÖ {len(results)} r√©sultats trouv√©s")
                
                for idx, result in enumerate(results[:10], 1):
                    with st.expander(f"{idx}. {result.get('title', 'Sans titre')}"):
                        st.write(f"**Source:** {result.get('source', 'Non sp√©cifi√©e')}")
                        st.write(f"**Date:** {result.get('date', 'Non dat√©e')}")
                        st.write(f"**Juridiction:** {result.get('jurisdiction', 'Non sp√©cifi√©e')}")
                        st.markdown("---")
                        st.write(result.get('content', 'Pas de contenu'))
                        
                        if result.get('reference'):
                            st.caption(f"R√©f√©rence: {result['reference']}")
            else:
                st.info("Aucun r√©sultat trouv√©")
                
        except Exception as e:
            st.error(f"Erreur lors de la recherche : {str(e)}")

# ========================= GESTION AVANC√âE DES DOCUMENTS =========================

async def manage_documents_advanced(action: str, documents: List[Any] = None):
    """Gestion avanc√©e des documents avec DocumentManager"""
    
    if not MANAGERS['document_manager']:
        st.warning("Module de gestion documentaire non disponible")
        return None
    
    doc_manager = DocumentManager()
    
    if action == "import":
        st.markdown("### üì• Import avanc√© de documents")
        
        uploaded_files = st.file_uploader(
            "Choisir des fichiers",
            type=['pdf', 'docx', 'txt', 'rtf'],
            accept_multiple_files=True
        )
        
        if uploaded_files:
            with st.spinner(f"Import de {len(uploaded_files)} fichiers..."):
                imported = []
                
                for file in uploaded_files:
                    try:
                        # Traitement avec OCR si n√©cessaire
                        result = await doc_manager.import_document(
                            file,
                            ocr_enabled=st.checkbox(f"OCR pour {file.name}", value=True),
                            extract_metadata=True
                        )
                        imported.append(result)
                        st.success(f"‚úÖ {file.name}")
                    except Exception as e:
                        st.error(f"‚ùå {file.name}: {str(e)}")
                
                return imported
    
    elif action == "analyze":
        st.markdown("### üìä Analyse avanc√©e de documents")
        
        if documents:
            analysis_type = st.multiselect(
                "Types d'analyse",
                ["Structure", "Entit√©s", "Sentiment", "Th√®mes", "Relations"],
                default=["Structure", "Entit√©s"]
            )
            
            results = {}
            for doc in documents:
                with st.spinner(f"Analyse de {doc.get('name', 'document')}..."):
                    try:
                        analysis = await doc_manager.analyze_document(
                            doc,
                            analysis_types=analysis_type
                        )
                        results[doc['id']] = analysis
                    except Exception as e:
                        st.error(f"Erreur : {str(e)}")
            
            # Afficher les r√©sultats d'analyse
            for doc_id, analysis in results.items():
                with st.expander(f"Analyse de {doc_id}"):
                    for analysis_type, data in analysis.items():
                        st.write(f"**{analysis_type}:**")
                        st.json(data)
    
    elif action == "classify":
        st.markdown("### üè∑Ô∏è Classification automatique")
        
        if documents:
            with st.spinner("Classification en cours..."):
                classifications = await doc_manager.classify_documents(documents)
                
                # Afficher les classifications
                df_data = []
                for doc, classification in classifications.items():
                    df_data.append({
                        'Document': doc,
                        'Type': classification.get('type', 'Inconnu'),
                        'Confiance': f"{classification.get('confidence', 0)*100:.1f}%",
                        'Tags': ', '.join(classification.get('tags', []))
                    })
                
                st.dataframe(df_data)

# ========================= COMPARAISON MULTI-LLM AM√âLIOR√âE =========================

async def enhanced_multi_llm_comparison(prompt: str, options: Dict[str, Any] = None):
    """Comparaison multi-LLM avec fonctionnalit√©s avanc√©es"""
    
    if not MANAGERS['multi_llm']:
        # Fallback vers la version simple
        return await compare_ai_generations(prompt)
    
    multi_llm = MultiLLMManager()
    
    st.markdown("### ü§ñ Comparaison Multi-LLM Avanc√©e")
    
    # Options de comparaison
    col1, col2, col3 = st.columns(3)
    
    with col1:
        models = st.multiselect(
            "Mod√®les √† comparer",
            multi_llm.get_available_models(),
            default=multi_llm.get_available_models()[:3]
        )
    
    with col2:
        comparison_mode = st.selectbox(
            "Mode de comparaison",
            ["Parall√®le", "S√©quentiel", "Consensus"],
            help="Parall√®le: tous en m√™me temps | S√©quentiel: un par un | Consensus: trouve le meilleur"
        )
    
    with col3:
        metrics = st.multiselect(
            "M√©triques d'√©valuation",
            ["Qualit√©", "Pertinence", "Cr√©ativit√©", "Coh√©rence"],
            default=["Qualit√©", "Pertinence"]
        )
    
    if st.button("üöÄ Lancer la comparaison", type="primary"):
        results = {}
        
        if comparison_mode == "Parall√®le":
            # G√©n√©ration parall√®le
            tasks = []
            for model in models:
                task = multi_llm.generate_async(prompt, model=model)
                tasks.append((model, task))
            
            # Attendre toutes les r√©ponses
            progress = st.progress(0)
            for idx, (model, task) in enumerate(tasks):
                with st.spinner(f"G√©n√©ration {model}..."):
                    try:
                        response = await task
                        results[model] = response
                        progress.progress((idx + 1) / len(tasks))
                    except Exception as e:
                        st.error(f"‚ùå {model}: {str(e)}")
        
        elif comparison_mode == "S√©quentiel":
            # G√©n√©ration s√©quentielle avec am√©lioration
            previous_response = None
            for model in models:
                with st.spinner(f"G√©n√©ration {model}..."):
                    try:
                        if previous_response:
                            # Enrichir le prompt avec la r√©ponse pr√©c√©dente
                            enriched_prompt = f"{prompt}\n\nAm√©liore cette r√©ponse:\n{previous_response[:500]}..."
                            response = await multi_llm.generate(enriched_prompt, model=model)
                        else:
                            response = await multi_llm.generate(prompt, model=model)
                        
                        results[model] = response
                        previous_response = response
                    except Exception as e:
                        st.error(f"‚ùå {model}: {str(e)}")
        
        else:  # Consensus
            # G√©n√©rer avec tous les mod√®les puis trouver le consensus
            with st.spinner("Recherche du consensus..."):
                consensus = await multi_llm.get_consensus(prompt, models=models)
                results['consensus'] = consensus
        
        # √âvaluation et affichage
        if results:
            st.markdown("#### üìä R√©sultats")
            
            # √âvaluer selon les m√©triques
            if metrics and comparison_mode != "Consensus":
                evaluations = {}
                for model, response in results.items():
                    evaluations[model] = await multi_llm.evaluate_response(
                        response, 
                        metrics=metrics
                    )
                
                # Afficher les scores
                st.markdown("**Scores d'√©valuation:**")
                df_scores = []
                for model, scores in evaluations.items():
                    row = {'Mod√®le': model}
                    row.update(scores)
                    df_scores.append(row)
                
                st.dataframe(df_scores)
                
                # Identifier le meilleur
                best_model = max(evaluations.items(), 
                               key=lambda x: sum(x[1].values()))[0]
                st.success(f"üèÜ Meilleur mod√®le : {best_model}")
            
            # Afficher les r√©ponses
            if comparison_mode == "Consensus":
                st.text_area("Consensus", results['consensus'], height=400)
            else:
                selected = st.selectbox(
                    "Voir la r√©ponse de",
                    list(results.keys())
                )
                
                st.text_area(
                    f"R√©ponse {selected}",
                    results[selected],
                    height=400
                )
                
                # Actions
                col1, col2, col3 = st.columns(3)
                with col1:
                    if st.button("üìã Copier"):
                        st.session_state.clipboard = results[selected]
                        st.success("Copi√© !")
                
                with col2:
                    if st.button("üíæ Utiliser"):
                        st.session_state.generated_content = results[selected]
                        st.success("Contenu s√©lectionn√© !")
                
                with col3:
                    if st.button("üîÑ Reg√©n√©rer"):
                        st.rerun()

# ========================= G√âN√âRATEURS DYNAMIQUES =========================

async def use_dynamic_generators(content_type: str, context: Dict[str, Any]):
    """Utilise les g√©n√©rateurs dynamiques pour enrichir le contenu"""
    
    if not MANAGERS['dynamic_generators']:
        st.warning("G√©n√©rateurs dynamiques non disponibles")
        return None
    
    generators = DynamicGenerators()
    
    st.markdown("### ‚ú® G√©n√©ration dynamique")
    
    # Options selon le type de contenu
    if content_type == "plainte":
        templates = generators.get_templates('plainte')
        selected_template = st.selectbox(
            "Mod√®le de plainte",
            templates,
            format_func=lambda x: x.get('name', 'Sans nom')
        )
        
        # Personnalisation
        tone = st.select_slider(
            "Ton",
            ["Tr√®s formel", "Formel", "Neutre", "Direct", "Agressif"],
            value="Formel"
        )
        
        length = st.slider(
            "Longueur cible (mots)",
            1000, 10000, 3000, 500
        )
        
        # G√©n√©ration
        if st.button("G√©n√©rer avec template"):
            with st.spinner("G√©n√©ration en cours..."):
                result = await generators.generate_from_template(
                    template=selected_template,
                    context=context,
                    parameters={
                        'tone': tone,
                        'target_length': length
                    }
                )
                
                st.session_state.generated_content = result
                st.success("‚úÖ Contenu g√©n√©r√© !")
    
    elif content_type == "conclusions":
        # Options sp√©cifiques aux conclusions
        structure = st.multiselect(
            "Structure des conclusions",
            ["Introduction", "Faits", "Proc√©dure", "Discussion", "Dispositif"],
            default=["Introduction", "Faits", "Discussion", "Dispositif"]
        )
        
        style = st.radio(
            "Style argumentatif",
            ["Classique", "Percutant", "Acad√©mique", "Synth√©tique"]
        )
        
        if st.button("G√©n√©rer conclusions"):
            with st.spinner("R√©daction des conclusions..."):
                result = await generators.generate_conclusions(
                    context=context,
                    structure=structure,
                    style=style
                )
                
                st.session_state.generated_content = result
                st.success("‚úÖ Conclusions r√©dig√©es !")

# ========================= GESTION DES PI√àCES =========================

def collect_available_documents(analysis: Any) -> List[Dict[str, Any]]:
    """Collecte tous les documents disponibles"""
    documents = []
    
    # Documents locaux
    for doc_id, doc in st.session_state.get('azure_documents', {}).items():
        if hasattr(doc, 'title'):
            documents.append({
                'id': doc_id,
                'title': doc.title,
                'content': doc.content,
                'source': doc.source,
                'metadata': getattr(doc, 'metadata', {})
            })
        else:
            documents.append({
                'id': doc_id,
                'title': doc.get('title', 'Sans titre'),
                'content': doc.get('content', ''),
                'source': doc.get('source', 'Local'),
                'metadata': doc.get('metadata', {})
            })
    
    # Documents import√©s
    for doc_id, doc in st.session_state.get('imported_documents', {}).items():
        documents.append(doc)
    
    return documents

def group_documents_by_category(documents: List[Dict]) -> Dict[str, List]:
    """Groupe les documents par cat√©gorie"""
    from collections import defaultdict
    categories = defaultdict(list)
    
    for doc in documents:
        category = determine_document_category(doc)
        categories[category].append(doc)
    
    return dict(categories)

def determine_document_category(doc: Dict) -> str:
    """D√©termine la cat√©gorie d'un document"""
    title_lower = doc.get('title', '').lower()
    content_lower = doc.get('content', '')[:500].lower()
    
    category_patterns = {
        'Proc√©dure': ['plainte', 'proc√®s-verbal', 'audition', 'assignation'],
        'Expertise': ['expertise', 'expert', 'rapport technique'],
        'Comptabilit√©': ['bilan', 'compte', 'facture', 'comptable'],
        'Contrats': ['contrat', 'convention', 'accord', 'avenant'],
        'Correspondance': ['courrier', 'email', 'lettre', 'mail']
    }
    
    for category, keywords in category_patterns.items():
        if any(kw in title_lower or kw in content_lower for kw in keywords):
            return category
    
    return 'Autres'

def calculate_piece_relevance(doc: Dict, analysis: Any) -> float:
    """Calcule la pertinence d'une pi√®ce"""
    score = 0.5
    
    # Augmenter le score si le document contient des mots-cl√©s pertinents
    if hasattr(analysis, 'subject_matter') and analysis.subject_matter:
        if analysis.subject_matter.lower() in doc.get('content', '').lower():
            score += 0.3
    
    if hasattr(analysis, 'reference') and analysis.reference:
        if analysis.reference.lower() in doc.get('title', '').lower():
            score += 0.2
    
    return min(score, 1.0)

def create_bordereau(pieces: List[Any], analysis: Any) -> Dict:
    """Cr√©e un bordereau structur√©"""
    
    bordereau = {
        'header': f"""BORDEREAU DE COMMUNICATION DE PI√àCES

AFFAIRE : {analysis.reference.upper() if hasattr(analysis, 'reference') and analysis.reference else 'N/A'}
DATE : {datetime.now().strftime('%d/%m/%Y')}
NOMBRE DE PI√àCES : {len(pieces)}

""",
        'pieces': pieces,
        'footer': f"""
Je certifie que les pi√®ces communiqu√©es sont conformes aux originaux.

Fait le {datetime.now().strftime('%d/%m/%Y')}

[Signature]""",
        'metadata': {
            'created_at': datetime.now(),
            'piece_count': len(pieces),
            'reference': analysis.reference if hasattr(analysis, 'reference') else None
        }
    }
    
    return bordereau

def create_bordereau_document(bordereau: Dict) -> bytes:
    """Cr√©e le document du bordereau"""
    content = bordereau['header'] + '\n'
    content += "LISTE DES PI√àCES COMMUNIQU√âES :\n\n"
    
    for piece in bordereau['pieces']:
        content += f"{piece.numero}. {piece.titre}\n"
        if hasattr(piece, 'description') and piece.description:
            content += f"   {piece.description}\n"
        if hasattr(piece, 'categorie'):
            content += f"   Cat√©gorie: {piece.categorie}\n"
        if hasattr(piece, 'date') and piece.date:
            content += f"   Date: {piece.date.strftime('%d/%m/%Y') if hasattr(piece.date, 'strftime') else piece.date}\n"
        content += "\n"
    
    content += bordereau['footer']
    
    return content.encode('utf-8')

def export_piece_list(pieces: List[Any]):
    """Exporte la liste des pi√®ces"""
    from collections import defaultdict
    
    content = "LISTE DES PI√àCES S√âLECTIONN√âES\n"
    content += f"Date : {datetime.now().strftime('%d/%m/%Y %H:%M')}\n"
    content += f"Nombre de pi√®ces : {len(pieces)}\n\n"
    
    # Grouper par cat√©gorie
    by_category = defaultdict(list)
    for piece in pieces:
        category = piece.categorie if hasattr(piece, 'categorie') else 'Non cat√©goris√©'
        by_category[category].append(piece)
    
    for category, cat_pieces in by_category.items():
        content += f"\n{category.upper()} ({len(cat_pieces)} pi√®ces)\n"
        content += "-" * 50 + "\n"
        
        for piece in cat_pieces:
            content += f"{piece.numero}. {piece.titre}\n"
            if hasattr(piece, 'description') and piece.description:
                content += f"   {piece.description}\n"
            content += "\n"
    
    # Proposer le t√©l√©chargement
    st.download_button(
        "üíæ T√©l√©charger la liste",
        content.encode('utf-8'),
        f"liste_pieces_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
        "text/plain"
    )

async def synthesize_selected_pieces(pieces: List[Any]) -> Dict:
    """Synth√©tise les pi√®ces s√©lectionn√©es"""
    
    if not MANAGERS['multi_llm']:
        return {'error': 'Module Multi-LLM non disponible'}
    
    try:
        from managers.multi_llm_manager import MultiLLMManager
        llm_manager = MultiLLMManager()
        
        if not llm_manager.clients:
            return {'error': 'Aucune IA disponible'}
        
        # Construire le contexte
        context = "PI√àCES √Ä SYNTH√âTISER:\n\n"
        
        for piece in pieces[:20]:  # Limiter √† 20 pi√®ces
            context += f"Pi√®ce {piece.numero}: {piece.titre}\n"
            if hasattr(piece, 'categorie'):
                context += f"Cat√©gorie: {piece.categorie}\n"
            if hasattr(piece, 'description') and piece.description:
                context += f"Description: {piece.description}\n"
            context += "\n"
        
        # Prompt de synth√®se
        synthesis_prompt = f"""{context}

Cr√©e une synth√®se structur√©e de ces pi√®ces.

La synth√®se doit inclure:
1. Vue d'ensemble des pi√®ces
2. Points cl√©s par cat√©gorie
3. Chronologie si applicable
4. Points d'attention juridiques
5. Recommandations"""
        
        provider = list(llm_manager.clients.keys())[0]
        response = llm_manager.query_single_llm(
            provider,
            synthesis_prompt,
            "Tu es un expert en analyse de documents juridiques."
        )
        
        if response['success']:
            synthesis_result = {
                'content': response['response'],
                'piece_count': len(pieces),
                'categories': list(set(p.categorie for p in pieces if hasattr(p, 'categorie'))),
                'timestamp': datetime.now()
            }
            st.session_state.synthesis_result = synthesis_result
            return synthesis_result
        else:
            return {'error': '√âchec de la synth√®se'}
            
    except Exception as e:
        return {'error': f'Erreur synth√®se: {str(e)}'}

# ========================= STATISTIQUES ET UTILS =========================

def show_document_statistics(content: str):
    """Affiche les statistiques d√©taill√©es d'un document"""
    
    # Calculs de base
    words = content.split()
    sentences = content.split('.')
    paragraphs = content.split('\n\n')
    
    # Analyse avanc√©e
    law_refs = len(re.findall(r'article\s+[LR]?\s*\d+', content, re.IGNORECASE))
    case_refs = len(re.findall(r'(Cass\.|C\.\s*cass\.|Crim\.|Civ\.)', content, re.IGNORECASE))
    
    # Affichage en colonnes
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Mots", f"{len(words):,}")
        st.metric("Phrases", f"{len(sentences):,}")
    
    with col2:
        st.metric("Paragraphes", len(paragraphs))
        st.metric("Mots/phrase", f"{len(words) / max(len(sentences), 1):.1f}")
    
    with col3:
        st.metric("Articles cit√©s", law_refs)
        st.metric("Jurisprudences", case_refs)
    
    with col4:
        avg_word_length = sum(len(w) for w in words) / max(len(words), 1)
        st.metric("Long. moy.", f"{avg_word_length:.1f} car")
        st.metric("Pages est.", f"~{len(words) // 250}")
    
    # Analyse linguistique si StyleAnalyzer disponible
    if MANAGERS['style_analyzer']:
        with st.expander("üìä Analyse linguistique avanc√©e"):
            try:
                analyzer = StyleAnalyzer()
                linguistic_analysis = analyzer.analyze_text_complexity(content)
                
                col1, col2 = st.columns(2)
                with col1:
                    st.write("**Complexit√© lexicale:**")
                    st.progress(linguistic_analysis.get('lexical_diversity', 0.5))
                    
                with col2:
                    st.write("**Lisibilit√©:**")
                    readability_score = linguistic_analysis.get('readability_score', 50)
                    st.progress(readability_score / 100)
                    
            except Exception as e:
                st.error(f"Erreur analyse linguistique: {str(e)}")

def save_current_work() -> Dict:
    """Sauvegarde compl√®te du travail actuel"""
    work_data = {
        'timestamp': datetime.now().isoformat(),
        'version': '2.0',
        'session_data': {},
        'results': {},
        'documents': {},
        'analysis': {}
    }
    
    # Sauvegarder l'√©tat de session pertinent
    session_keys = [
        'universal_query', 'last_universal_query', 
        'redaction_result', 'ai_analysis_results',
        'search_results', 'selected_pieces',
        'synthesis_result', 'timeline_result'
    ]
    
    for key in session_keys:
        if key in st.session_state:
            value = st.session_state[key]
            # S√©rialiser les objets complexes
            if hasattr(value, '__dict__'):
                work_data['session_data'][key] = value.__dict__
            else:
                work_data['session_data'][key] = value
    
    # Sauvegarder les documents
    if 'azure_documents' in st.session_state:
        for doc_id, doc in st.session_state.azure_documents.items():
            if hasattr(doc, '__dict__'):
                work_data['documents'][doc_id] = doc.__dict__
            else:
                work_data['documents'][doc_id] = doc
    
    # Cr√©er le JSON
    import json
    
    def default_serializer(obj):
        if hasattr(obj, '__dict__'):
            return obj.__dict__
        elif hasattr(obj, 'isoformat'):
            return obj.isoformat()
        else:
            return str(obj)
    
    json_str = json.dumps(work_data, indent=2, ensure_ascii=False, default=default_serializer)
    
    # Proposer le t√©l√©chargement
    st.download_button(
        "üíæ Sauvegarder le travail",
        json_str,
        f"sauvegarde_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
        "application/json",
        key="save_work_btn"
    )
    
    return work_data

async def show_work_statistics():
    """Affiche des statistiques d√©taill√©es du travail"""
    st.markdown("### üìä Statistiques du travail")
    
    # Statistiques de base
    stats = {
        'Documents Azure': len(st.session_state.get('azure_documents', {})),
        'Documents import√©s': len(st.session_state.get('imported_documents', {})),
        'Pi√®ces s√©lectionn√©es': len(st.session_state.get('selected_pieces', [])),
        'Analyses effectu√©es': 1 if st.session_state.get('ai_analysis_results') else 0,
        'R√©dactions': 1 if st.session_state.get('redaction_result') else 0
    }
    
    # Affichage en m√©triques
    cols = st.columns(len(stats))
    for i, (label, value) in enumerate(stats.items()):
        with cols[i]:
            st.metric(label, value)
    
    # Statistiques d√©taill√©es par type
    with st.expander("üìà Statistiques d√©taill√©es"):
        # Documents par cat√©gorie
        if st.session_state.get('azure_documents'):
            all_docs = collect_available_documents(None)
            categories = group_documents_by_category(all_docs)
            
            st.write("**Documents par cat√©gorie:**")
            for cat, docs in categories.items():
                st.write(f"‚Ä¢ {cat}: {len(docs)} documents")
        
        # Historique des actions
        if 'action_history' in st.session_state:
            st.write("**Historique des actions:**")
            for action in st.session_state.action_history[-10:]:
                st.write(f"‚Ä¢ {action['timestamp']}: {action['type']}")

# ========================= TRAITEMENT DES PLAINTES COMPLET =========================

async def process_plainte_request(query: str, analysis: Any):
    """Traite une demande de plainte avec toutes les options"""
    
    st.markdown("### üìã Configuration de la plainte")
    
    # D√©terminer le type de plainte
    query_lower = query.lower()
    is_partie_civile = any(term in query_lower for term in [
        'partie civile', 'constitution de partie civile', 'cpc', 
        'doyen', 'juge d\'instruction', 'instruction'
    ])
    
    # Extraire les parties et infractions
    parties_demanderesses = []
    parties_defenderesses = []
    infractions = []
    
    if hasattr(analysis, 'parties'):
        parties_demanderesses = analysis.parties.get('demandeurs', [])
        parties_defenderesses = analysis.parties.get('defendeurs', [])
    
    if hasattr(analysis, 'infractions'):
        infractions = analysis.infractions
    
    # Interface de configuration
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**üè¢ Demandeurs (victimes)**")
        demandeurs_text = st.text_area(
            "Un par ligne",
            value='\n'.join(parties_demanderesses),
            height=100,
            key="demandeurs_input"
        )
        parties_demanderesses = [p.strip() for p in demandeurs_text.split('\n') if p.strip()]
        
        st.markdown("**üéØ Infractions**")
        infractions_text = st.text_area(
            "Une par ligne",
            value='\n'.join(infractions),
            height=100,
            key="infractions_input"
        )
        infractions = [i.strip() for i in infractions_text.split('\n') if i.strip()]
    
    with col2:
        st.markdown("**‚öñÔ∏è D√©fendeurs (mis en cause)**")
        defendeurs_text = st.text_area(
            "Un par ligne",
            value='\n'.join(parties_defenderesses),
            height=100,
            key="defendeurs_input"
        )
        parties_defenderesses = [p.strip() for p in defendeurs_text.split('\n') if p.strip()]
        
        st.markdown("**‚öôÔ∏è Options**")
        type_plainte = st.radio(
            "Type de plainte",
            ["Plainte simple", "Plainte avec CPC"],
            index=1 if is_partie_civile else 0,
            key="type_plainte_radio"
        )
        is_partie_civile = (type_plainte == "Plainte avec CPC")
        
        include_chronologie = st.checkbox("Inclure chronologie d√©taill√©e", value=True)
        include_prejudices = st.checkbox("D√©tailler les pr√©judices", value=True)
        include_jurisprudence = st.checkbox("Citer jurisprudences", value=is_partie_civile)
    
    # Enrichissement des parties si CompanyInfoManager disponible
    if st.checkbox("üè¢ Enrichir les informations des soci√©t√©s", value=True):
        if MANAGERS['company_info'] and (parties_demanderesses or parties_defenderesses):
            enriched_parties = await enrich_parties_info(
                parties_demanderesses + parties_defenderesses
            )
            
            if enriched_parties:
                with st.expander("üìä Informations enrichies", expanded=False):
                    for party in enriched_parties:
                        st.json(party)
    
    # Bouton de g√©n√©ration
    if st.button("üöÄ G√©n√©rer la plainte", type="primary", key="generate_plainte_btn"):
        # Pr√©parer l'analyse enrichie
        analysis_dict = {
            'parties': {
                'demandeurs': parties_demanderesses,
                'defendeurs': parties_defenderesses
            },
            'infractions': infractions,
            'reference': analysis.reference if hasattr(analysis, 'reference') else None,
            'options': {
                'is_partie_civile': is_partie_civile,
                'include_chronologie': include_chronologie,
                'include_prejudices': include_prejudices,
                'include_jurisprudence': include_jurisprudence
            }
        }
        
        # G√©n√©rer
        await generate_advanced_plainte(query)

# ========================= EXPORT DES NOUVELLES FONCTIONS =========================

__all__ = [
    # G√©n√©ration avanc√©e
    'generate_advanced_plainte',
    'verify_jurisprudences_in_plainte',
    'compare_ai_generations',
    'show_plainte_statistics',
    'show_improvement_suggestions',
    # Recherche et analyse
    'perform_legal_search',
    'manage_documents_advanced',
    'enhanced_multi_llm_comparison',
    'use_dynamic_generators',
    # Gestion des pi√®ces
    'collect_available_documents',
    'group_documents_by_category',
    'determine_document_category',
    'calculate_piece_relevance',
    'create_bordereau',
    'create_bordereau_document',
    'export_piece_list',
    'synthesize_selected_pieces',
    # Statistiques et utils
    'show_document_statistics',
    'save_current_work',
    'show_work_statistics',
    'process_plainte_request',
    # Configuration
    'REDACTION_STYLES',
    'DOCUMENT_TEMPLATES'
]