"""Module d'extraction d'informations juridiques - Version am√©lior√©e"""

import hashlib
import json
import logging
import re
import sys
import time
from collections import Counter, defaultdict
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import pandas as pd
import streamlit as st

# Configuration du logger
logger = logging.getLogger(__name__)

# Ajout du chemin parent pour importer utils
sys.path.append(str(Path(__file__).parent.parent))
try:
    from utils import clean_key, format_legal_date, truncate_text
except ImportError:
    # Fonctions utilitaires de base si import √©choue
    def truncate_text(text, max_length=100):
        return text[:max_length] + "..." if len(text) > max_length else text
    def clean_key(key):
        return re.sub(r'[^a-zA-Z0-9_]', '_', str(key))
    def format_legal_date(date):
        return date.strftime("%d/%m/%Y") if isinstance(date, datetime) else str(date)

def run():
    """Fonction principale du module - Point d'entr√©e pour lazy loading"""
    module = ExtractionModule()
    module.render()

class ExtractionModule:
    """Module d'extraction intelligente d'informations avec IA multi-mod√®les"""
    
    def __init__(self):
        self.name = "Extraction d'informations"
        self.description = "Extraction intelligente multi-mod√®les avec fusion des r√©sultats"
        self.icon = "üéØ"
        self.available = True
        
        # Configuration des mod√®les d'IA disponibles
        self.ai_models = {
            'gpt4': {
                'name': 'GPT-4 Turbo',
                'icon': 'ü§ñ',
                'strengths': ['Compr√©hension contextuelle', 'Raisonnement complexe'],
                'speed': 'Rapide',
                'accuracy': 0.95
            },
            'claude': {
                'name': 'Claude 3 Opus',
                'icon': 'üß†',
                'strengths': ['Analyse juridique', 'Nuances linguistiques'],
                'speed': 'Moyen',
                'accuracy': 0.96
            },
            'gemini': {
                'name': 'Gemini Pro',
                'icon': '‚ú®',
                'strengths': ['Traitement multimodal', 'Vitesse'],
                'speed': 'Tr√®s rapide',
                'accuracy': 0.92
            },
            'mistral': {
                'name': 'Mistral Large',
                'icon': 'üå™Ô∏è',
                'strengths': ['Efficacit√©', 'Fran√ßais natif'],
                'speed': 'Rapide',
                'accuracy': 0.90
            }
        }
        
        # Patterns d'extraction am√©lior√©s
        self.extraction_patterns = {
            'persons': {
                'patterns': [
                    r'(?:M\.|Mme|Mlle|Dr|Me|Pr|Juge)\s+([A-Z][a-z√Ä-√ø]+(?:\s+[A-Z][a-z√Ä-√ø]+)*)',
                    r'([A-Z][a-z√Ä-√ø]+\s+[A-Z]+)(?:\s|,|\.|$)',
                    r'(?:demandeur|d√©fendeur|t√©moin|expert|partie)\s+([A-Z][a-z√Ä-√ø]+(?:\s+[A-Z][a-z√Ä-√ø]+)*)'
                ],
                'icon': 'üë§',
                'name': 'Personnes',
                'color': '#FF6B6B'
            },
            'organizations': {
                'patterns': [
                    r'(?:soci√©t√©|entreprise|SARL|SAS|SA|SCI|EURL|association)\s+([A-Z][A-Za-z√Ä-√ø\s&\'-]+)',
                    r'([A-Z][A-Z\s&\'-]{2,})\s+(?:Inc|Ltd|GmbH|AG|SAS|SARL|SA)',
                    r'(?:Tribunal|Cour|Conseil)\s+(?:de|d\')\s+([A-Za-z√Ä-√ø\s\'-]+)'
                ],
                'icon': 'üè¢',
                'name': 'Organisations',
                'color': '#4ECDC4'
            },
            'dates': {
                'patterns': [
                    r'\d{1,2}[/-]\d{1,2}[/-]\d{2,4}',
                    r'\d{1,2}\s+(?:janvier|f√©vrier|mars|avril|mai|juin|juillet|ao√ªt|septembre|octobre|novembre|d√©cembre)\s+\d{4}',
                    r'(?:le|du|au)\s+\d{1,2}\s+\w+\s+\d{4}'
                ],
                'icon': 'üìÖ',
                'name': 'Dates',
                'color': '#FFE66D'
            },
            'amounts': {
                'patterns': [
                    r'(\d+(?:\s?\d{3})*(?:,\d{2})?)\s*(?:‚Ç¨|EUR|euros?)',
                    r'(\d+(?:\.\d{3})*(?:,\d{2})?)\s*(?:‚Ç¨|EUR|euros?)',
                    r'(?:montant|somme|indemnit√©)\s+de\s+(\d+(?:\s?\d{3})*(?:,\d{2})?)\s*(?:‚Ç¨|EUR|euros?)'
                ],
                'icon': 'üí∞',
                'name': 'Montants',
                'color': '#95E1D3'
            },
            'references': {
                'patterns': [
                    r'(?:article|Article)\s+\d+(?:[\.-]\d+)*(?:\s+du\s+Code\s+[a-z√Ä-√ø]+)?',
                    r'(?:RG|TGI|CA|Cass\.)\s*[:\s]\s*\d+[/-]\d+',
                    r'n¬∞\s*\d+(?:[/-]\d+)*',
                    r'(?:loi|d√©cret|arr√™t√©)\s+(?:n¬∞\s*)?\d{4}-\d+'
                ],
                'icon': 'üìé',
                'name': 'R√©f√©rences',
                'color': '#A8E6CF'
            },
            'locations': {
                'patterns': [
                    r'(?:√†|de|depuis)\s+([A-Z][a-z√Ä-√ø]+(?:-[A-Z][a-z√Ä-√ø]+)*)',
                    r'\d{5}\s+([A-Z][a-z√Ä-√ø]+(?:-[A-Z][a-z√Ä-√ø]+)*)',
                    r'(?:domicili√©|r√©sidant|situ√©)\s+(?:√†|au)\s+([A-Z][a-z√Ä-√ø\s\'-]+)'
                ],
                'icon': 'üìç',
                'name': 'Lieux',
                'color': '#C7CEEA'
            }
        }
        
        # Initialisation de l'√©tat
        self._initialize_session_state()
    
    def _initialize_session_state(self):
        """Initialise l'√©tat de la session"""
        if 'extraction_state' not in st.session_state:
            st.session_state.extraction_state = {
                'current_extraction': None,
                'history': [],
                'preferences': {
                    'default_models': ['gpt4'],
                    'auto_fusion': False,
                    'confidence_threshold': 0.7,
                    'context_window': 100
                },
                'cache': {},
                'statistics': {
                    'total_extractions': 0,
                    'total_entities': 0,
                    'favorite_types': Counter()
                }
            }
    
    def render(self):
        """Interface principale du module avec design am√©lior√©"""
        # En-t√™te avec animation
        st.markdown("""
            <style>
            @keyframes pulse {
                0% { transform: scale(1); }
                50% { transform: scale(1.05); }
                100% { transform: scale(1); }
            }
            .module-header {
                padding: 2rem;
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                border-radius: 15px;
                color: white;
                margin-bottom: 2rem;
                animation: pulse 2s ease-in-out infinite;
            }
            .stat-card {
                background: #f8f9fa;
                border-radius: 10px;
                padding: 1.5rem;
                text-align: center;
                box-shadow: 0 2px 10px rgba(0,0,0,0.1);
                transition: transform 0.3s ease;
            }
            .stat-card:hover {
                transform: translateY(-5px);
                box-shadow: 0 5px 20px rgba(0,0,0,0.15);
            }
            .model-card {
                background: white;
                border: 2px solid #e9ecef;
                border-radius: 12px;
                padding: 1rem;
                margin: 0.5rem 0;
                transition: all 0.3s ease;
            }
            .model-card:hover {
                border-color: #667eea;
                box-shadow: 0 4px 15px rgba(102, 126, 234, 0.2);
            }
            .result-card {
                background: white;
                border-left: 4px solid;
                border-radius: 8px;
                padding: 1rem;
                margin: 0.5rem 0;
                box-shadow: 0 2px 8px rgba(0,0,0,0.08);
            }
            .fusion-indicator {
                background: linear-gradient(90deg, #667eea, #764ba2, #f093fb);
                color: white;
                padding: 0.25rem 0.75rem;
                border-radius: 20px;
                font-size: 0.85rem;
                display: inline-block;
            }
            </style>
        """, unsafe_allow_html=True)
        
        # En-t√™te anim√©
        st.markdown(f"""
            <div class="module-header">
                <h1 style="margin: 0; font-size: 2.5rem;">{self.icon} {self.name}</h1>
                <p style="margin: 0.5rem 0 0 0; opacity: 0.9; font-size: 1.2rem;">{self.description}</p>
            </div>
        """, unsafe_allow_html=True)
        
        # Statistiques rapides
        self._render_quick_stats()
        
        # Navigation principale avec ic√¥nes am√©lior√©es
        tab1, tab2, tab3, tab4, tab5 = st.tabs([
            "üöÄ Extraction Rapide",
            "ü§ñ Configuration IA",
            "üìä Analyse Avanc√©e",
            "üìö Historique",
            "‚öôÔ∏è Param√®tres"
        ])
        
        with tab1:
            self._render_extraction_tab_enhanced()
        
        with tab2:
            self._render_ai_config_tab()
        
        with tab3:
            self._render_analysis_tab_enhanced()
        
        with tab4:
            self._render_history_tab()
        
        with tab5:
            self._render_settings_tab()
    
    def _render_quick_stats(self):
        """Affiche les statistiques rapides avec design moderne"""
        stats = st.session_state.extraction_state['statistics']
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.markdown(f"""
                <div class="stat-card">
                    <h3 style="color: #667eea; margin: 0;">üìà</h3>
                    <h2 style="margin: 0.5rem 0;">{stats['total_extractions']}</h2>
                    <p style="margin: 0; color: #6c757d;">Extractions totales</p>
                </div>
            """, unsafe_allow_html=True)
        
        with col2:
            st.markdown(f"""
                <div class="stat-card">
                    <h3 style="color: #764ba2; margin: 0;">üéØ</h3>
                    <h2 style="margin: 0.5rem 0;">{stats['total_entities']}</h2>
                    <p style="margin: 0; color: #6c757d;">Entit√©s extraites</p>
                </div>
            """, unsafe_allow_html=True)
        
        with col3:
            favorite_type = stats['favorite_types'].most_common(1)
            fav_icon = self.extraction_patterns[favorite_type[0][0]]['icon'] if favorite_type else '‚ùì'
            fav_name = self.extraction_patterns[favorite_type[0][0]]['name'] if favorite_type else 'Aucun'
            
            st.markdown(f"""
                <div class="stat-card">
                    <h3 style="color: #f093fb; margin: 0;">{fav_icon}</h3>
                    <h2 style="margin: 0.5rem 0; font-size: 1.3rem;">{fav_name}</h2>
                    <p style="margin: 0; color: #6c757d;">Type favori</p>
                </div>
            """, unsafe_allow_html=True)
        
        with col4:
            success_rate = 95.7  # Simul√©
            st.markdown(f"""
                <div class="stat-card">
                    <h3 style="color: #4ade80; margin: 0;">‚úÖ</h3>
                    <h2 style="margin: 0.5rem 0;">{success_rate}%</h2>
                    <p style="margin: 0; color: #6c757d;">Taux de succ√®s</p>
                </div>
            """, unsafe_allow_html=True)
    
    def _render_extraction_tab_enhanced(self):
        """Onglet d'extraction avec interface am√©lior√©e"""
        # Mode d'extraction avec cards visuelles
        st.markdown("### üéØ Mode d'extraction")
        
        col1, col2, col3, col4 = st.columns(4)
        
        extraction_modes = {
            "Automatique": {"icon": "ü§ñ", "desc": "Extraction compl√®te intelligente"},
            "Favorable": {"icon": "‚úÖ", "desc": "Points positifs pour la d√©fense"},
            "√Ä charge": {"icon": "‚ö†Ô∏è", "desc": "√âl√©ments d√©favorables"},
            "Personnalis√©": {"icon": "üé®", "desc": "Configuration sur mesure"}
        }
        
        selected_mode = None
        for i, (mode, info) in enumerate(extraction_modes.items()):
            with [col1, col2, col3, col4][i]:
                if st.button(
                    f"{info['icon']}\n**{mode}**\n_{info['desc']}_",
                    key=f"mode_{mode}",
                    use_container_width=True,
                    help=info['desc']
                ):
                    selected_mode = mode
        
        if selected_mode:
            st.session_state.extraction_mode = selected_mode
        
        current_mode = st.session_state.get('extraction_mode', 'Automatique')
        st.info(f"Mode s√©lectionn√© : **{current_mode}**")
        
        # Source des documents avec interface moderne
        st.markdown("### üìÅ Source des documents")
        
        source_container = st.container()
        with source_container:
            source_cols = st.columns([1, 1, 1])
            
            with source_cols[0]:
                if st.button("üìÑ Documents charg√©s", use_container_width=True):
                    st.session_state.doc_source = "loaded"
            
            with source_cols[1]:
                if st.button("‚úçÔ∏è Texte direct", use_container_width=True):
                    st.session_state.doc_source = "direct"
            
            with source_cols[2]:
                if st.button("üîç Recherche Azure", use_container_width=True):
                    st.session_state.doc_source = "search"
        
        # Zone de contenu selon la source
        current_source = st.session_state.get('doc_source', 'loaded')
        documents = self._get_documents_enhanced(current_source)
        
        if documents:
            # Aper√ßu des documents
            with st.expander(f"üìã Aper√ßu des documents ({len(documents)} documents)", expanded=True):
                for i, doc in enumerate(documents[:3]):  # Limiter l'aper√ßu
                    st.markdown(f"""
                        <div style="background: #f8f9fa; padding: 1rem; border-radius: 8px; margin: 0.5rem 0;">
                            <strong>{doc['title']}</strong><br>
                            <small>{truncate_text(doc['content'], 200)}</small>
                        </div>
                    """, unsafe_allow_html=True)
                
                if len(documents) > 3:
                    st.caption(f"... et {len(documents) - 3} autres documents")
            
            # Configuration avanc√©e si mode personnalis√©
            if current_mode == "Personnalis√©":
                self._render_custom_config()
            
            # S√©lection des mod√®les d'IA
            st.markdown("### ü§ñ Mod√®les d'IA")
            self._render_model_selection()
            
            # Bouton d'extraction avec animation
            col1, col2, col3 = st.columns([1, 2, 1])
            with col2:
                if st.button(
                    "üöÄ Lancer l'extraction intelligente",
                    type="primary",
                    use_container_width=True,
                    disabled=not documents
                ):
                    self._perform_enhanced_extraction(documents, current_mode)
    
    def _render_model_selection(self):
        """Interface de s√©lection des mod√®les d'IA"""
        col1, col2 = st.columns([3, 1])
        
        with col1:
            selected_models = []
            model_cols = st.columns(len(self.ai_models))
            
            for i, (model_id, model_info) in enumerate(self.ai_models.items()):
                with model_cols[i]:
                    selected = st.checkbox(
                        f"{model_info['icon']} {model_info['name']}",
                        key=f"model_{model_id}",
                        value=model_id in st.session_state.extraction_state['preferences']['default_models']
                    )
                    if selected:
                        selected_models.append(model_id)
                    
                    # Info-bulle avec d√©tails
                    with st.expander("‚ÑπÔ∏è D√©tails"):
                        st.caption(f"**Vitesse:** {model_info['speed']}")
                        st.caption(f"**Pr√©cision:** {model_info['accuracy']*100:.0f}%")
                        st.caption(f"**Points forts:**")
                        for strength in model_info['strengths']:
                            st.caption(f"‚Ä¢ {strength}")
        
        with col2:
            fusion_mode = st.checkbox(
                "üîÄ Mode Fusion",
                value=st.session_state.extraction_state['preferences']['auto_fusion'],
                help="Combine les r√©sultats de tous les mod√®les s√©lectionn√©s"
            )
            
            if fusion_mode and len(selected_models) > 1:
                st.markdown('<span class="fusion-indicator">Mode Fusion Actif</span>', unsafe_allow_html=True)
        
        st.session_state.selected_models = selected_models
        st.session_state.fusion_mode = fusion_mode
    
    def _render_custom_config(self):
        """Configuration personnalis√©e avanc√©e"""
        with st.expander("‚öôÔ∏è Configuration personnalis√©e", expanded=True):
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("#### üìå Types d'entit√©s")
                for entity_type, entity_info in self.extraction_patterns.items():
                    st.checkbox(
                        f"{entity_info['icon']} {entity_info['name']}",
                        value=True,
                        key=f"extract_{entity_type}_custom"
                    )
                
                # Pattern personnalis√© avec aide
                st.markdown("#### üîß Pattern personnalis√©")
                custom_pattern = st.text_area(
                    "Expression r√©guli√®re",
                    placeholder="Ex: \\b[A-Z]{2,}\\b",
                    height=100,
                    help="Testez votre regex sur regex101.com"
                )
                
                if custom_pattern:
                    # Test en temps r√©el
                    test_text = st.text_input("Texte de test")
                    if test_text:
                        try:
                            matches = re.findall(custom_pattern, test_text)
                            if matches:
                                st.success(f"‚úÖ Trouv√© : {matches}")
                            else:
                                st.warning("‚ùå Aucune correspondance")
                        except re.error as e:
                            st.error(f"Erreur regex : {e}")
            
            with col2:
                st.markdown("#### üéõÔ∏è Param√®tres avanc√©s")
                
                context_window = st.slider(
                    "üìè Fen√™tre de contexte",
                    50, 500, 
                    st.session_state.extraction_state['preferences']['context_window'],
                    step=50,
                    help="Caract√®res de contexte autour des extractions"
                )
                
                confidence_threshold = st.slider(
                    "üéØ Seuil de confiance",
                    0.0, 1.0,
                    st.session_state.extraction_state['preferences']['confidence_threshold'],
                    step=0.05,
                    help="Confiance minimale pour conserver une extraction"
                )
                
                st.markdown("#### üîç Options de recherche")
                
                case_sensitive = st.checkbox("Respecter la casse", value=False)
                whole_word = st.checkbox("Mots entiers uniquement", value=True)
                fuzzy_matching = st.checkbox(
                    "Correspondance approximative",
                    value=False,
                    help="Tol√®re les fautes de frappe"
                )
                
                if fuzzy_matching:
                    fuzzy_threshold = st.slider(
                        "Seuil de similarit√©",
                        0.5, 1.0, 0.8,
                        help="1.0 = correspondance exacte"
                    )
    
    def _get_documents_enhanced(self, source: str) -> List[Dict[str, Any]]:
        """R√©cup√®re les documents avec gestion am√©lior√©e"""
        documents = []
        
        if source == "loaded":
            # Documents depuis la session avec m√©tadonn√©es enrichies
            if 'selected_documents' in st.session_state and st.session_state.selected_documents:
                st.success(f"‚úÖ {len(st.session_state.selected_documents)} documents pr√™ts")
                
                for doc_name in st.session_state.selected_documents:
                    # Simulation avec m√©tadonn√©es
                    documents.append({
                        'id': hashlib.md5(doc_name.encode()).hexdigest()[:8],
                        'title': doc_name,
                        'content': f"Contenu du document {doc_name}...",  # √Ä remplacer
                        'source': 'Session',
                        'type': 'PDF',
                        'size': '2.3 MB',
                        'date': datetime.now(),
                        'confidence': 1.0
                    })
            else:
                st.warning("‚ö†Ô∏è Aucun document s√©lectionn√©. Veuillez charger des documents.")
        
        elif source == "direct":
            # √âditeur de texte am√©lior√©
            st.markdown("#### ‚úçÔ∏è Saisie directe")
            
            # Templates de texte
            template = st.selectbox(
                "Utiliser un template",
                ["Vide", "Contrat type", "Jugement", "Proc√®s-verbal"],
                help="Templates pr√©-remplis pour tester"
            )
            
            if template != "Vide":
                default_text = self._get_template_text(template)
            else:
                default_text = ""
            
            text = st.text_area(
                "Texte √† analyser",
                value=default_text,
                height=400,
                placeholder="Collez ou tapez votre texte juridique ici..."
            )
            
            if text:
                # Statistiques du texte
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Caract√®res", len(text))
                with col2:
                    st.metric("Mots", len(text.split()))
                with col3:
                    st.metric("Lignes", text.count('\n') + 1)
                
                documents.append({
                    'id': hashlib.md5(text.encode()).hexdigest()[:8],
                    'title': 'Texte direct',
                    'content': text,
                    'source': 'Saisie',
                    'type': 'TXT',
                    'size': f"{len(text)} caract√®res",
                    'date': datetime.now(),
                    'confidence': 1.0
                })
        
        else:  # search
            st.markdown("#### üîç Recherche Azure Cognitive Search")
            
            col1, col2 = st.columns([3, 1])
            
            with col1:
                search_query = st.text_input(
                    "Requ√™te de recherche",
                    placeholder="Ex: contrat de vente 2024 Paris",
                    help="Utilisez des mots-cl√©s pertinents"
                )
            
            with col2:
                max_results = st.number_input(
                    "R√©sultats max",
                    min_value=1,
                    max_value=50,
                    value=10
                )
            
            # Filtres avanc√©s
            with st.expander("üîß Filtres avanc√©s"):
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    doc_types = st.multiselect(
                        "Types de documents",
                        ["Contrats", "Jugements", "Expertises", "Correspondances"],
                        default=["Contrats", "Jugements"]
                    )
                
                with col2:
                    date_range = st.date_input(
                        "P√©riode",
                        value=[datetime.now().date(), datetime.now().date()],
                        key="date_range_search"
                    )
                
                with col3:
                    relevance_threshold = st.slider(
                        "Pertinence minimale",
                        0.0, 1.0, 0.7
                    )
            
            if search_query and st.button("üîç Rechercher", type="primary"):
                with st.spinner("Recherche en cours..."):
                    # Simulation de recherche avec barre de progression
                    progress_bar = st.progress(0)
                    for i in range(100):
                        time.sleep(0.01)
                        progress_bar.progress(i + 1)
                    
                    # R√©sultats simul√©s
                    for i in range(min(5, max_results)):
                        relevance = 0.95 - (i * 0.1)
                        if relevance >= relevance_threshold:
                            documents.append({
                                'id': f"search_{i}",
                                'title': f'Document pertinent {i+1} - {search_query}',
                                'content': f'Contenu trouv√© relatif √† "{search_query}"...',
                                'source': 'Azure Search',
                                'type': 'PDF',
                                'size': f"{2.1 + i*0.3:.1f} MB",
                                'date': datetime.now(),
                                'confidence': relevance,
                                'relevance': relevance,
                                'highlights': [search_query]
                            })
                    
                    st.success(f"‚úÖ {len(documents)} documents trouv√©s")
        
        return documents
    
    def _get_template_text(self, template: str) -> str:
        """Retourne un texte template selon le type"""
        templates = {
            "Contrat type": """CONTRAT DE PRESTATION DE SERVICES

Entre les soussign√©s :

La soci√©t√© TECH INNOVATIONS SAS, au capital de 50.000 ‚Ç¨, immatricul√©e au RCS de Paris sous le num√©ro 123 456 789, dont le si√®ge social est situ√© au 123 Avenue des Champs-√âlys√©es, 75008 Paris, repr√©sent√©e par M. Jean DUPONT en sa qualit√© de Pr√©sident,

Ci-apr√®s d√©nomm√©e "le Prestataire"

ET

La soci√©t√© CLIENT ENTREPRISE SARL, au capital de 20.000 ‚Ç¨, immatricul√©e au RCS de Lyon sous le num√©ro 987 654 321, dont le si√®ge social est situ√© au 45 Rue de la R√©publique, 69002 Lyon, repr√©sent√©e par Mme Marie MARTIN en sa qualit√© de G√©rante,

Ci-apr√®s d√©nomm√©e "le Client"

Article 1 - Objet
Le pr√©sent contrat a pour objet la fourniture de prestations de d√©veloppement informatique pour un montant total de 25.000 ‚Ç¨ HT.

Article 2 - Dur√©e
Le contrat est conclu pour une dur√©e de 6 mois √† compter du 1er janvier 2024.

Fait √† Paris, le 15 d√©cembre 2023
En deux exemplaires originaux""",
            
            "Jugement": """TRIBUNAL DE GRANDE INSTANCE DE PARIS
3√®me Chambre Civile

JUGEMENT
Audience publique du 20 novembre 2023
RG n¬∞ 22/14567

DEMANDEUR :
M. Pierre LAMBERT, n√© le 12 mars 1975 √† Marseille, demeurant 78 Boulevard Saint-Michel, 75005 Paris

D√âFENDEUR :
IMMOBILI√àRE DU CENTRE SA, RCS Paris 456 789 123, si√®ge social 90 Avenue Montaigne, 75008 Paris

FAITS ET PROC√âDURE :
Par acte du 15 janvier 2022, M. Pierre LAMBERT a assign√© la soci√©t√© IMMOBILI√àRE DU CENTRE en paiement de dommages-int√©r√™ts d'un montant de 45.000 ‚Ç¨ pour troubles de jouissance.

MOTIFS :
Attendu que les troubles invoqu√©s sont √©tablis par les attestations produites...

PAR CES MOTIFS :
Le Tribunal, statuant publiquement, par jugement contradictoire et en premier ressort,
CONDAMNE la soci√©t√© IMMOBILI√àRE DU CENTRE √† verser √† M. Pierre LAMBERT la somme de 35.000 ‚Ç¨ √† titre de dommages-int√©r√™ts.""",
            
            "Proc√®s-verbal": """PROC√àS-VERBAL DE CONSTAT

L'an deux mille vingt-trois et le quinze octobre √† quatorze heures,

Je soussign√©, Ma√Ætre Fran√ßois DURAND, Huissier de Justice associ√© pr√®s le Tribunal Judiciaire de Paris, y demeurant 25 Rue du Faubourg Saint-Honor√©,

Me suis transport√© au 45 Rue de la Paix, 75002 Paris, √† la demande de la soci√©t√© ENTREPRISE ABC SARL.

CONSTATATIONS :
J'ai constat√© la pr√©sence d'une infiltration d'eau importante au niveau du plafond du local commercial. Les d√©g√¢ts s'√©tendent sur une surface d'environ 20 m¬≤.

T√âMOIN PR√âSENT :
M. Jacques BERNARD, g√©rant de la soci√©t√© voisine, atteste avoir constat√© les m√™mes d√©gradations depuis le 10 octobre 2023.

Dont proc√®s-verbal pour servir et valoir ce que de droit."""
        }
        
        return templates.get(template, "")
    
    def _perform_enhanced_extraction(self, documents: List[Dict[str, Any]], mode: str):
        """Extraction am√©lior√©e avec multi-mod√®les et fusion"""
        # Animation de d√©but
        placeholder = st.empty()
        
        with placeholder.container():
            st.markdown("""
                <div style="text-align: center; padding: 2rem;">
                    <h2>üöÄ Extraction en cours...</h2>
                    <p>Analyse intelligente multi-mod√®les</p>
                </div>
            """, unsafe_allow_html=True)
            
            # Barre de progression principale
            main_progress = st.progress(0)
            status_text = st.empty()
            
            # Phases d'extraction
            phases = [
                ("üìÑ Pr√©paration des documents", 10),
                ("üîç Analyse pr√©liminaire", 20),
                ("ü§ñ Traitement par IA", 60),
                ("üîÄ Fusion des r√©sultats", 80),
                ("üìä G√©n√©ration du rapport", 100)
            ]
            
            results = {
                'documents_analyzed': len(documents),
                'extractions_by_model': {},
                'fusion_results': {},
                'statistics': {},
                'insights': [],
                'quality_metrics': {}
            }
            
            # Simulation du traitement par phases
            for phase, progress in phases:
                status_text.text(phase)
                time.sleep(0.5)  # Simulation
                main_progress.progress(progress / 100)
                
                if phase == "ü§ñ Traitement par IA":
                    # Traitement par chaque mod√®le
                    selected_models = st.session_state.get('selected_models', ['gpt4'])
                    
                    model_cols = st.columns(len(selected_models))
                    model_progress_bars = {}
                    
                    for i, model_id in enumerate(selected_models):
                        with model_cols[i]:
                            st.caption(f"{self.ai_models[model_id]['icon']} {self.ai_models[model_id]['name']}")
                            model_progress_bars[model_id] = st.progress(0)
                    
                    # Simulation du traitement parall√®le
                    for prog in range(101):
                        for model_id, progress_bar in model_progress_bars.items():
                            progress_bar.progress(prog)
                        time.sleep(0.01)
                    
                    # R√©sultats simul√©s par mod√®le
                    for model_id in selected_models:
                        results['extractions_by_model'][model_id] = self._simulate_model_extraction(
                            documents, mode, model_id
                        )
                
                elif phase == "üîÄ Fusion des r√©sultats" and st.session_state.get('fusion_mode', False):
                    # Fusion des r√©sultats si mode fusion actif
                    if len(results['extractions_by_model']) > 1:
                        results['fusion_results'] = self._fusion_results(
                            results['extractions_by_model']
                        )
        
        # Effacer l'animation
        placeholder.empty()
        
        # Calculer les statistiques finales
        results['statistics'] = self._calculate_enhanced_statistics(results)
        results['insights'] = self._generate_enhanced_insights(results, mode)
        results['quality_metrics'] = self._calculate_quality_metrics(results)
        
        # Sauvegarder dans l'historique
        extraction_record = {
            'id': hashlib.md5(str(datetime.now()).encode()).hexdigest()[:8],
            'timestamp': datetime.now(),
            'mode': mode,
            'documents': len(documents),
            'models_used': st.session_state.get('selected_models', ['gpt4']),
            'fusion_enabled': st.session_state.get('fusion_mode', False),
            'results': results
        }
        
        st.session_state.extraction_state['history'].append(extraction_record)
        st.session_state.extraction_state['current_extraction'] = extraction_record
        st.session_state.extraction_state['statistics']['total_extractions'] += 1
        st.session_state.extraction_state['statistics']['total_entities'] += results['statistics']['total_entities']
        
        # Afficher les r√©sultats
        self._display_enhanced_results(results, mode)
    
    def _simulate_model_extraction(self, documents: List[Dict[str, Any]], mode: str, model_id: str) -> Dict[str, Any]:
        """Simule l'extraction par un mod√®le sp√©cifique"""
        # Ajuster les r√©sultats selon les caract√©ristiques du mod√®le
        model_info = self.ai_models[model_id]
        accuracy = model_info['accuracy']
        
        extractions = defaultdict(list)
        
        for doc in documents:
            if mode == "Favorable":
                # Points favorables avec variation selon le mod√®le
                num_points = int(5 * accuracy + (hash(model_id) % 3))
                for i in range(num_points):
                    extractions['favorable_points'].append({
                        'type': 'favorable',
                        'text': f"Point favorable {i+1} identifi√© par {model_info['name']}",
                        'confidence': accuracy - (i * 0.05),
                        'importance': 8 - i,
                        'model': model_id,
                        'document_id': doc['id']
                    })
            
            elif mode == "√Ä charge":
                # √âl√©ments √† charge
                num_elements = int(4 * accuracy + (hash(model_id) % 2))
                for i in range(num_elements):
                    severity = ['Critique', 'Important', 'Mod√©r√©'][i % 3]
                    extractions['charge_elements'].append({
                        'type': 'charge',
                        'text': f"√âl√©ment √† charge d√©tect√© par {model_info['name']}",
                        'confidence': accuracy - (i * 0.03),
                        'severity': severity,
                        'model': model_id,
                        'document_id': doc['id']
                    })
            
            else:  # Automatique ou Personnalis√©
                # Extraction de toutes les entit√©s
                for entity_type, entity_info in self.extraction_patterns.items():
                    if mode == "Personnalis√©":
                        # V√©rifier si le type est s√©lectionn√©
                        if not st.session_state.get(f'extract_{entity_type}_custom', True):
                            continue
                    
                    # Nombre d'entit√©s selon la pr√©cision du mod√®le
                    num_entities = int((3 + hash(f"{model_id}{entity_type}") % 5) * accuracy)
                    
                    for i in range(num_entities):
                        extractions[entity_type].append({
                            'value': f"{entity_info['name']} {i+1}",
                            'context': f"Contexte de l'extraction par {model_info['name']}",
                            'confidence': accuracy - (i * 0.02),
                            'position': i * 100,
                            'model': model_id,
                            'document_id': doc['id']
                        })
        
        return {
            'model_id': model_id,
            'model_name': model_info['name'],
            'extractions': dict(extractions),
            'processing_time': 2.5 / (1 + accuracy),  # Temps simul√©
            'confidence_avg': accuracy
        }
    
    def _fusion_results(self, model_results: Dict[str, Dict]) -> Dict[str, Any]:
        """Fusionne les r√©sultats de plusieurs mod√®les"""
        fusion = defaultdict(list)
        consensus_scores = defaultdict(lambda: defaultdict(float))
        
        # Agr√©gation des r√©sultats
        for model_id, results in model_results.items():
            model_weight = self.ai_models[model_id]['accuracy']
            
            for entity_type, entities in results['extractions'].items():
                for entity in entities:
                    # Cr√©er une cl√© unique pour l'entit√©
                    if isinstance(entity, dict):
                        entity_key = entity.get('value', str(entity))
                        
                        # Calculer le score de consensus
                        consensus_scores[entity_type][entity_key] += model_weight
                        
                        # Ajouter √† la fusion avec m√©tadonn√©es
                        entity_copy = entity.copy()
                        entity_copy['contributing_models'] = [model_id]
                        entity_copy['fusion_confidence'] = model_weight
                        fusion[entity_type].append(entity_copy)
        
        # D√©dupliquer et calculer la confiance finale
        final_fusion = {}
        for entity_type, entities in fusion.items():
            # Grouper par valeur
            grouped = defaultdict(list)
            for entity in entities:
                key = entity.get('value', str(entity))
                grouped[key].append(entity)
            
            # Cr√©er l'entit√© fusionn√©e
            final_entities = []
            for key, duplicates in grouped.items():
                # Moyenner les scores de confiance
                avg_confidence = sum(e.get('confidence', 0) for e in duplicates) / len(duplicates)
                contributing_models = list(set(
                    model for e in duplicates 
                    for model in e.get('contributing_models', [e.get('model')])
                ))
                
                fused_entity = duplicates[0].copy()
                fused_entity.update({
                    'confidence': avg_confidence,
                    'contributing_models': contributing_models,
                    'fusion_score': len(contributing_models) / len(model_results),
                    'consensus_level': '√âlev√©' if len(contributing_models) >= 3 else 'Moyen' if len(contributing_models) >= 2 else 'Faible'
                })
                
                final_entities.append(fused_entity)
            
            final_fusion[entity_type] = final_entities
        
        return final_fusion
    
    def _calculate_enhanced_statistics(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """Calcule des statistiques d√©taill√©es"""
        stats = {
            'total_entities': 0,
            'by_type': {},
            'by_model': {},
            'fusion_stats': {},
            'confidence_distribution': {
                'high': 0,  # > 0.8
                'medium': 0,  # 0.5-0.8
                'low': 0  # < 0.5
            }
        }
        
        # Choisir la source des donn√©es selon le mode
        if results.get('fusion_results'):
            data_source = results['fusion_results']
        else:
            # Prendre le premier mod√®le s'il n'y a pas de fusion
            first_model = list(results['extractions_by_model'].values())[0]
            data_source = first_model['extractions']
        
        # Statistiques par type
        for entity_type, entities in data_source.items():
            unique_values = set()
            confidence_sum = 0
            
            for entity in entities:
                if isinstance(entity, dict):
                    unique_values.add(entity.get('value', str(entity)))
                    conf = entity.get('confidence', 0)
                    confidence_sum += conf
                    
                    # Distribution de confiance
                    if conf > 0.8:
                        stats['confidence_distribution']['high'] += 1
                    elif conf > 0.5:
                        stats['confidence_distribution']['medium'] += 1
                    else:
                        stats['confidence_distribution']['low'] += 1
                
                stats['total_entities'] += 1
            
            stats['by_type'][entity_type] = {
                'total': len(entities),
                'unique': len(unique_values),
                'avg_confidence': confidence_sum / len(entities) if entities else 0
            }
        
        # Statistiques par mod√®le
        for model_id, model_results in results['extractions_by_model'].items():
            total_model_entities = sum(
                len(entities) 
                for entities in model_results['extractions'].values()
            )
            stats['by_model'][model_id] = {
                'total': total_model_entities,
                'processing_time': model_results['processing_time'],
                'avg_confidence': model_results['confidence_avg']
            }
        
        # Statistiques de fusion
        if results.get('fusion_results'):
            high_consensus = sum(
                1 for entities in results['fusion_results'].values()
                for e in entities
                if e.get('consensus_level') == '√âlev√©'
            )
            stats['fusion_stats'] = {
                'high_consensus_entities': high_consensus,
                'fusion_improvement': 15.7  # Simul√©
            }
        
        return stats
    
    def _generate_enhanced_insights(self, results: Dict[str, Any], mode: str) -> List[str]:
        """G√©n√®re des insights intelligents et contextualis√©s"""
        insights = []
        stats = results['statistics']
        
        # Insight sur le volume
        if stats['total_entities'] > 100:
            insights.append(f"üìä Volume important : {stats['total_entities']} entit√©s extraites, sugg√©rant un document riche en informations")
        elif stats['total_entities'] < 20:
            insights.append(f"üìâ Volume mod√©r√© : {stats['total_entities']} entit√©s seulement, le document pourrait n√©cessiter une analyse manuelle compl√©mentaire")
        
        # Insights sur la qualit√©
        high_conf_ratio = stats['confidence_distribution']['high'] / max(stats['total_entities'], 1)
        if high_conf_ratio > 0.7:
            insights.append(f"‚úÖ Excellente qualit√© : {high_conf_ratio*100:.0f}% des extractions ont une confiance √©lev√©e")
        elif high_conf_ratio < 0.3:
            insights.append(f"‚ö†Ô∏è Qualit√© √† v√©rifier : seulement {high_conf_ratio*100:.0f}% des extractions ont une confiance √©lev√©e")
        
        # Insights sp√©cifiques au mode
        if mode == "Favorable":
            favorable_count = stats['by_type'].get('favorable_points', {}).get('total', 0)
            if favorable_count > 10:
                insights.append(f"üí™ Position forte : {favorable_count} points favorables identifi√©s pour construire la d√©fense")
            elif favorable_count < 3:
                insights.append(f"‚ö° Attention : peu de points favorables ({favorable_count}), envisager des arguments compl√©mentaires")
        
        elif mode == "√Ä charge":
            charge_count = stats['by_type'].get('charge_elements', {}).get('total', 0)
            if charge_count > 5:
                insights.append(f"üö® Vigilance requise : {charge_count} √©l√©ments √† charge n√©cessitent une strat√©gie de d√©fense solide")
        
        # Insights sur la fusion
        if results.get('fusion_results') and stats.get('fusion_stats'):
            consensus = stats['fusion_stats']['high_consensus_entities']
            insights.append(f"üîÄ Consensus inter-mod√®les : {consensus} entit√©s valid√©es par plusieurs IA, fiabilit√© accrue")
        
        # Insights sur les types dominants
        if stats['by_type']:
            dominant_type = max(stats['by_type'].items(), key=lambda x: x[1]['total'])
            type_info = self.extraction_patterns.get(dominant_type[0], {'name': dominant_type[0]})
            insights.append(f"{type_info.get('icon', 'üìå')} Type dominant : {type_info['name']} avec {dominant_type[1]['total']} occurrences")
        
        # Performance des mod√®les
        if len(results['extractions_by_model']) > 1:
            best_model = max(
                stats['by_model'].items(),
                key=lambda x: x[1]['total'] * x[1]['avg_confidence']
            )
            model_name = self.ai_models[best_model[0]]['name']
            insights.append(f"üèÜ Meilleure performance : {model_name} avec {best_model[1]['total']} extractions")
        
        return insights
    
    def _calculate_quality_metrics(self, results: Dict[str, Any]) -> Dict[str, float]:
        """Calcule des m√©triques de qualit√© avanc√©es"""
        metrics = {
            'completeness': 0.0,
            'accuracy': 0.0,
            'consistency': 0.0,
            'coverage': 0.0,
            'overall_score': 0.0
        }
        
        stats = results['statistics']
        
        # Compl√©tude (bas√©e sur le nombre d'entit√©s par rapport aux attentes)
        expected_entities = 50  # Baseline
        metrics['completeness'] = min(stats['total_entities'] / expected_entities, 1.0)
        
        # Pr√©cision (bas√©e sur la distribution de confiance)
        if stats['total_entities'] > 0:
            metrics['accuracy'] = (
                stats['confidence_distribution']['high'] * 1.0 +
                stats['confidence_distribution']['medium'] * 0.6 +
                stats['confidence_distribution']['low'] * 0.2
            ) / stats['total_entities']
        
        # Coh√©rence (si fusion activ√©e)
        if results.get('fusion_results'):
            # Bas√©e sur le consensus entre mod√®les
            metrics['consistency'] = 0.85  # Simul√©
        else:
            metrics['consistency'] = 1.0  # Pas de fusion = pas d'incoh√©rence
        
        # Couverture (types d'entit√©s trouv√©s vs disponibles)
        types_found = len([t for t, data in stats['by_type'].items() if data['total'] > 0])
        types_available = len(self.extraction_patterns)
        metrics['coverage'] = types_found / types_available
        
        # Score global
        metrics['overall_score'] = (
            metrics['completeness'] * 0.25 +
            metrics['accuracy'] * 0.35 +
            metrics['consistency'] * 0.20 +
            metrics['coverage'] * 0.20
        )
        
        return metrics
    
    def _display_enhanced_results(self, results: Dict[str, Any], mode: str):
        """Affichage am√©lior√© des r√©sultats avec visualisations"""
        # En-t√™te de succ√®s avec animation
        st.markdown("""
            <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                        color: white; padding: 1.5rem; border-radius: 10px; margin-bottom: 2rem;">
                <h2 style="margin: 0;">‚úÖ Extraction Termin√©e avec Succ√®s!</h2>
                <p style="margin: 0.5rem 0 0 0;">Analyse intelligente compl√©t√©e en {:.1f} secondes</p>
            </div>
        """.format(sum(m['processing_time'] for m in results['extractions_by_model'].values())), 
        unsafe_allow_html=True)
        
        # M√©triques principales avec style
        col1, col2, col3, col4 = st.columns(4)
        
        metrics_data = [
            ("üìÑ", "Documents", results['documents_analyzed'], None),
            ("üîç", "Entit√©s", results['statistics']['total_entities'], None),
            ("üéØ", "Pr√©cision", f"{results['quality_metrics']['accuracy']*100:.1f}%", "+2.3%"),
            ("üìä", "Score Global", f"{results['quality_metrics']['overall_score']*100:.0f}/100", None)
        ]
        
        for col, (icon, label, value, delta) in zip([col1, col2, col3, col4], metrics_data):
            with col:
                st.metric(f"{icon} {label}", value, delta)
        
        # Insights avec cards stylis√©es
        if results['insights']:
            st.markdown("### üí° Insights Cl√©s")
            
            # Organiser les insights en grille
            insight_cols = st.columns(2)
            for i, insight in enumerate(results['insights']):
                with insight_cols[i % 2]:
                    st.info(insight)
        
        # Tabs pour diff√©rentes vues
        tab1, tab2, tab3, tab4 = st.tabs([
            "üìä Vue d'ensemble",
            "üîç D√©tails par type",
            "ü§ñ Analyse par mod√®le",
            "üìà Visualisations"
        ])
        
        with tab1:
            self._display_overview_tab(results, mode)
        
        with tab2:
            self._display_details_tab(results)
        
        with tab3:
            self._display_model_analysis_tab(results)
        
        with tab4:
            self._display_visualizations_tab(results)
        
        # Actions finales
        st.markdown("### üéØ Actions")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            if st.button("üíæ Sauvegarder", use_container_width=True):
                st.success("‚úÖ R√©sultats sauvegard√©s!")
        
        with col2:
            if st.button("üì§ Exporter", use_container_width=True):
                self._show_export_dialog(results)
        
        with col3:
            if st.button("üîÑ Nouvelle extraction", use_container_width=True):
                st.session_state.extraction_state['current_extraction'] = None
                st.rerun()
        
        with col4:
            if st.button("üìß Partager", use_container_width=True):
                st.info("üìß Fonctionnalit√© de partage bient√¥t disponible")
    
    def _display_overview_tab(self, results: Dict[str, Any], mode: str):
        """Onglet vue d'ensemble"""
        # R√©sum√© ex√©cutif
        st.markdown("#### üìã R√©sum√© Ex√©cutif")
        
        summary = f"""
        L'analyse a trait√© **{results['documents_analyzed']} documents** en utilisant 
        **{len(results['extractions_by_model'])} mod√®les d'IA**. 
        Au total, **{results['statistics']['total_entities']} entit√©s** ont √©t√© extraites 
        avec une pr√©cision moyenne de **{results['quality_metrics']['accuracy']*100:.1f}%**.
        """
        
        if results.get('fusion_results'):
            summary += f"""
            Le mode fusion a permis d'identifier **{results['statistics']['fusion_stats']['high_consensus_entities']} 
            entit√©s** avec un consensus √©lev√© entre les mod√®les.
            """
        
        st.markdown(summary)
        
        # M√©triques de qualit√© avec graphique
        st.markdown("#### üìä M√©triques de Qualit√©")
        
        quality_cols = st.columns(4)
        quality_metrics = [
            ("Compl√©tude", results['quality_metrics']['completeness']),
            ("Pr√©cision", results['quality_metrics']['accuracy']),
            ("Coh√©rence", results['quality_metrics']['consistency']),
            ("Couverture", results['quality_metrics']['coverage'])
        ]
        
        for col, (metric, value) in zip(quality_cols, quality_metrics):
            with col:
                # Graphique circulaire simple avec CSS
                color = '#4ade80' if value > 0.8 else '#fbbf24' if value > 0.6 else '#f87171'
                st.markdown(f"""
                    <div style="text-align: center;">
                        <div style="width: 100px; height: 100px; margin: 0 auto; 
                                    border-radius: 50%; border: 8px solid {color};
                                    display: flex; align-items: center; justify-content: center;">
                            <span style="font-size: 1.5rem; font-weight: bold;">{value*100:.0f}%</span>
                        </div>
                        <p style="margin-top: 0.5rem;">{metric}</p>
                    </div>
                """, unsafe_allow_html=True)
        
        # Distribution de confiance
        st.markdown("#### üéØ Distribution de Confiance")
        
        conf_dist = results['statistics']['confidence_distribution']
        total = sum(conf_dist.values())
        
        if total > 0:
            conf_data = pd.DataFrame({
                'Niveau': ['√âlev√©e (>80%)', 'Moyenne (50-80%)', 'Faible (<50%)'],
                'Nombre': [conf_dist['high'], conf_dist['medium'], conf_dist['low']],
                'Pourcentage': [
                    conf_dist['high']/total*100,
                    conf_dist['medium']/total*100,
                    conf_dist['low']/total*100
                ]
            })
            
            # Barres horizontales avec style
            for _, row in conf_data.iterrows():
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.markdown(f"**{row['Niveau']}**")
                    st.progress(row['Pourcentage'] / 100)
                with col2:
                    st.markdown(f"{row['Nombre']} ({row['Pourcentage']:.1f}%)")
    
    def _display_details_tab(self, results: Dict[str, Any]):
        """Onglet d√©tails par type d'entit√©"""
        # S√©lectionner la source de donn√©es
        if results.get('fusion_results'):
            data_source = results['fusion_results']
            st.info("üîÄ Affichage des r√©sultats fusionn√©s")
        else:
            first_model = list(results['extractions_by_model'].values())[0]
            data_source = first_model['extractions']
        
        # Afficher chaque type d'entit√©
        for entity_type, entities in data_source.items():
            if entities:
                entity_info = self.extraction_patterns.get(
                    entity_type,
                    {'icon': 'üìå', 'name': entity_type.title(), 'color': '#gray'}
                )
                
                # En-t√™te du type avec couleur
                st.markdown(f"""
                    <div style="border-left: 4px solid {entity_info['color']}; 
                                padding-left: 1rem; margin: 1rem 0;">
                        <h4>{entity_info['icon']} {entity_info['name']} 
                            <span style="color: #6c757d; font-size: 0.9rem;">
                                ({len(entities)} trouv√©s)
                            </span>
                        </h4>
                    </div>
                """, unsafe_allow_html=True)
                
                # Options d'affichage
                col1, col2, col3 = st.columns([2, 1, 1])
                
                with col1:
                    view_mode = st.radio(
                        "Mode d'affichage",
                        ["Liste", "Tableau", "Cartes"],
                        key=f"view_{entity_type}",
                        horizontal=True
                    )
                
                with col2:
                    sort_by = st.selectbox(
                        "Trier par",
                        ["Confiance", "Alphab√©tique", "Position"],
                        key=f"sort_{entity_type}"
                    )
                
                with col3:
                    show_context = st.checkbox(
                        "Afficher contexte",
                        key=f"context_{entity_type}"
                    )
                
                # Affichage selon le mode choisi
                if view_mode == "Liste":
                    self._display_entities_list(entities, show_context, sort_by)
                elif view_mode == "Tableau":
                    self._display_entities_table(entities, entity_type)
                else:  # Cartes
                    self._display_entities_cards(entities, entity_info['color'])
    
    def _display_entities_list(self, entities: List[Dict], show_context: bool, sort_by: str):
        """Affiche les entit√©s en liste"""
        # Trier les entit√©s
        if sort_by == "Confiance":
            sorted_entities = sorted(entities, key=lambda x: x.get('confidence', 0), reverse=True)
        elif sort_by == "Alphab√©tique":
            sorted_entities = sorted(entities, key=lambda x: x.get('value', str(x)))
        else:  # Position
            sorted_entities = sorted(entities, key=lambda x: x.get('position', 0))
        
        # Afficher les 10 premi√®res
        for i, entity in enumerate(sorted_entities[:10]):
            col1, col2 = st.columns([4, 1])
            
            with col1:
                value = entity.get('value', str(entity))
                confidence = entity.get('confidence', 0)
                
                # Badge de confiance
                conf_color = '#4ade80' if confidence > 0.8 else '#fbbf24' if confidence > 0.5 else '#f87171'
                
                st.markdown(f"""
                    <div style="display: flex; align-items: center; gap: 0.5rem;">
                        <span style="font-weight: 500;">{value}</span>
                        <span style="background: {conf_color}; color: white; 
                                     padding: 0.2rem 0.5rem; border-radius: 12px; 
                                     font-size: 0.8rem;">
                            {confidence*100:.0f}%
                        </span>
                    </div>
                """, unsafe_allow_html=True)
                
                if show_context and entity.get('context'):
                    st.caption(f"üìù {entity['context']}")
            
            with col2:
                # Actions
                if st.button("üëÅÔ∏è", key=f"view_{i}_{entity.get('value', i)}", help="Voir d√©tails"):
                    st.info(f"D√©tails: {json.dumps(entity, indent=2, default=str)}")
        
        # Afficher plus si n√©cessaire
        if len(sorted_entities) > 10:
            if st.button(f"Voir tous ({len(sorted_entities)} au total)"):
                for entity in sorted_entities[10:]:
                    st.write(f"‚Ä¢ {entity.get('value', str(entity))}")
    
    def _display_entities_table(self, entities: List[Dict], entity_type: str):
        """Affiche les entit√©s en tableau"""
        # Pr√©parer les donn√©es pour le DataFrame
        table_data = []
        
        for entity in entities:
            row = {
                'Valeur': entity.get('value', str(entity)),
                'Confiance': f"{entity.get('confidence', 0)*100:.0f}%",
                'Document': entity.get('document_id', 'N/A')
            }
            
            # Ajouter des colonnes sp√©cifiques selon le type
            if entity_type == 'favorable_points':
                row['Importance'] = entity.get('importance', 'N/A')
            elif entity_type == 'charge_elements':
                row['S√©v√©rit√©'] = entity.get('severity', 'N/A')
            
            # Mod√®les contributeurs si fusion
            if entity.get('contributing_models'):
                row['Mod√®les'] = ', '.join([
                    self.ai_models[m]['icon'] for m in entity['contributing_models']
                ])
            
            table_data.append(row)
        
        # Cr√©er et afficher le DataFrame
        df = pd.DataFrame(table_data)
        st.dataframe(
            df,
            use_container_width=True,
            hide_index=True,
            column_config={
                "Confiance": st.column_config.ProgressColumn(
                    "Confiance",
                    help="Niveau de confiance de l'extraction",
                    format="%d%%",
                    min_value=0,
                    max_value=100,
                )
            }
        )
    
    def _display_entities_cards(self, entities: List[Dict], color: str):
        """Affiche les entit√©s sous forme de cartes"""
        # Grille de cartes
        cols = st.columns(3)
        
        for i, entity in enumerate(entities[:9]):  # Limiter √† 9 pour la grille 3x3
            with cols[i % 3]:
                value = entity.get('value', str(entity))
                confidence = entity.get('confidence', 0)
                
                # Carte stylis√©e
                st.markdown(f"""
                    <div class="result-card" style="border-left-color: {color};">
                        <h5 style="margin: 0 0 0.5rem 0;">{value}</h5>
                        <div style="display: flex; justify-content: space-between; align-items: center;">
                            <span style="color: #6c757d; font-size: 0.9rem;">
                                Confiance: {confidence*100:.0f}%
                            </span>
                        </div>
                    </div>
                """, unsafe_allow_html=True)
                
                # D√©tails au survol (simul√© avec expander)
                with st.expander("D√©tails"):
                    for key, val in entity.items():
                        if key not in ['value', 'confidence']:
                            st.caption(f"**{key}:** {val}")
    
    def _display_model_analysis_tab(self, results: Dict[str, Any]):
        """Onglet d'analyse par mod√®le"""
        st.markdown("#### ü§ñ Performance des Mod√®les")
        
        # Comparaison des mod√®les
        model_comparison = []
        
        for model_id, model_results in results['extractions_by_model'].items():
            model_info = self.ai_models[model_id]
            stats = results['statistics']['by_model'][model_id]
            
            model_comparison.append({
                'Mod√®le': f"{model_info['icon']} {model_info['name']}",
                'Entit√©s': stats['total'],
                'Temps (s)': f"{stats['processing_time']:.2f}",
                'Confiance': f"{stats['avg_confidence']*100:.0f}%",
                'Efficacit√©': stats['total'] / stats['processing_time']
            })
        
        # Afficher le tableau de comparaison
        df_comparison = pd.DataFrame(model_comparison)
        st.dataframe(df_comparison, use_container_width=True, hide_index=True)
        
        # Graphique de performance
        if len(model_comparison) > 1:
            st.markdown("#### üìä Analyse Comparative")
            
            # Barres de comparaison
            metrics_to_compare = ['Entit√©s', 'Efficacit√©']
            
            for metric in metrics_to_compare:
                st.markdown(f"**{metric}**")
                
                metric_data = df_comparison[['Mod√®le', metric]].copy()
                
                # Barres horizontales
                for _, row in metric_data.iterrows():
                    col1, col2 = st.columns([1, 3])
                    with col1:
                        st.write(row['Mod√®le'])
                    with col2:
                        # Normaliser pour la barre de progression
                        max_val = metric_data[metric].max()
                        normalized = row[metric] / max_val if max_val > 0 else 0
                        st.progress(normalized)
                        st.caption(f"{row[metric]:.1f}")
        
        # Analyse de consensus si fusion activ√©e
        if results.get('fusion_results'):
            st.markdown("#### üîÄ Analyse de Consensus")
            
            consensus_stats = {
                'Consensus √©lev√©': 0,
                'Consensus moyen': 0,
                'Consensus faible': 0
            }
            
            # Compter les niveaux de consensus
            for entities in results['fusion_results'].values():
                for entity in entities:
                    level = entity.get('consensus_level', 'Faible')
                    key = f"Consensus {level.lower()}"
                    if key in consensus_stats:
                        consensus_stats[key] += 1
            
            # Afficher les statistiques de consensus
            consensus_df = pd.DataFrame({
                'Niveau': list(consensus_stats.keys()),
                'Nombre': list(consensus_stats.values())
            })
            
            st.bar_chart(consensus_df.set_index('Niveau'))
            
            # Exemples d'entit√©s avec consensus √©lev√©
            st.markdown("##### üèÜ Entit√©s avec Consensus √âlev√©")
            
            high_consensus_entities = []
            for entity_type, entities in results['fusion_results'].items():
                for entity in entities:
                    if entity.get('consensus_level') == '√âlev√©':
                        high_consensus_entities.append({
                            'Type': self.extraction_patterns.get(entity_type, {'name': entity_type})['name'],
                            'Valeur': entity.get('value', 'N/A'),
                            'Mod√®les': ', '.join([
                                self.ai_models[m]['icon'] 
                                for m in entity.get('contributing_models', [])
                            ])
                        })
            
            if high_consensus_entities:
                df_consensus = pd.DataFrame(high_consensus_entities[:5])
                st.table(df_consensus)
    
    def _display_visualizations_tab(self, results: Dict[str, Any]):
        """Onglet de visualisations avanc√©es"""
        st.markdown("#### üìà Visualisations des Donn√©es")
        
        # S√©lecteur de visualisation
        viz_type = st.selectbox(
            "Type de visualisation",
            ["Distribution par type", "Carte de confiance", "Timeline", "R√©seau d'entit√©s"]
        )
        
        if viz_type == "Distribution par type":
            # Graphique en secteurs simul√© avec m√©triques
            st.markdown("##### üéØ Distribution des Entit√©s par Type")
            
            total = results['statistics']['total_entities']
            if total > 0:
                cols = st.columns(3)
                
                for i, (entity_type, stats) in enumerate(results['statistics']['by_type'].items()):
                    if stats['total'] > 0:
                        entity_info = self.extraction_patterns.get(entity_type, {'icon': 'üìå', 'name': entity_type})
                        percentage = (stats['total'] / total) * 100
                        
                        with cols[i % 3]:
                            st.markdown(f"""
                                <div style="text-align: center; padding: 1rem; 
                                           background: {entity_info.get('color', '#e9ecef')}20; 
                                           border-radius: 10px;">
                                    <h2 style="margin: 0;">{entity_info['icon']}</h2>
                                    <h3 style="margin: 0.5rem 0;">{percentage:.1f}%</h3>
                                    <p style="margin: 0;">{entity_info['name']}</p>
                                    <small>{stats['total']} entit√©s</small>
                                </div>
                            """, unsafe_allow_html=True)
        
        elif viz_type == "Carte de confiance":
            st.markdown("##### üé® Carte de Chaleur de Confiance")
            
            # Cr√©er une matrice de confiance
            if results.get('fusion_results'):
                # Matrice mod√®les x types d'entit√©s
                models = list(results['extractions_by_model'].keys())
                entity_types = list(self.extraction_patterns.keys())
                
                # Simuler une matrice de confiance
                st.markdown("""
                    <div style="background: linear-gradient(to right, #f87171, #fbbf24, #4ade80); 
                                height: 20px; border-radius: 10px; margin: 1rem 0;">
                    </div>
                    <p style="text-align: center;">Faible ‚Üê Confiance ‚Üí √âlev√©e</p>
                """, unsafe_allow_html=True)
                
                # Tableau de confiance
                confidence_data = []
                for model in models:
                    row = {'Mod√®le': self.ai_models[model]['name']}
                    for entity_type in entity_types[:3]:  # Limiter pour l'affichage
                        # Simuler une valeur de confiance
                        confidence = 0.7 + (hash(f"{model}{entity_type}") % 30) / 100
                        row[self.extraction_patterns[entity_type]['name']] = f"{confidence*100:.0f}%"
                    confidence_data.append(row)
                
                df_conf = pd.DataFrame(confidence_data)
                st.dataframe(df_conf, use_container_width=True, hide_index=True)
        
        elif viz_type == "Timeline":
            st.markdown("##### üìÖ Timeline des Dates Extraites")
            
            # Extraire toutes les dates
            dates_found = []
            data_source = results.get('fusion_results') or list(results['extractions_by_model'].values())[0]['extractions']
            
            if 'dates' in data_source:
                for date_entity in data_source['dates']:
                    dates_found.append(date_entity.get('value', 'Date'))
            
            if dates_found:
                # Afficher les dates sur une timeline
                st.markdown("""
                    <div style="position: relative; height: 100px; background: #f8f9fa; 
                                border-radius: 10px; margin: 1rem 0;">
                        <div style="position: absolute; left: 0; right: 0; top: 50%; 
                                    height: 2px; background: #667eea;"></div>
                """, unsafe_allow_html=True)
                
                # Points sur la timeline
                cols = st.columns(len(dates_found[:5]))
                for i, date in enumerate(dates_found[:5]):
                    with cols[i]:
                        st.markdown(f"""
                            <div style="text-align: center;">
                                <div style="width: 20px; height: 20px; background: #667eea; 
                                           border-radius: 50%; margin: 0 auto;"></div>
                                <small>{date}</small>
                            </div>
                        """, unsafe_allow_html=True)
                
                st.markdown("</div>", unsafe_allow_html=True)
            else:
                st.info("Aucune date trouv√©e dans les documents")
        
        else:  # R√©seau d'entit√©s
            st.markdown("##### üï∏Ô∏è R√©seau d'Entit√©s")
            st.info("üöß Visualisation du r√©seau d'entit√©s en cours de d√©veloppement")
            
            # Placeholder pour un futur graphe de r√©seau
            st.markdown("""
                <div style="height: 400px; background: #f8f9fa; border-radius: 10px; 
                           display: flex; align-items: center; justify-content: center;">
                    <p style="color: #6c757d;">Graphe de r√©seau des relations entre entit√©s</p>
                </div>
            """, unsafe_allow_html=True)
    
    def _render_ai_config_tab(self):
        """Configuration avanc√©e des mod√®les d'IA"""
        st.markdown("### ü§ñ Configuration des Mod√®les d'IA")
        
        # Configuration globale
        with st.expander("‚öôÔ∏è Param√®tres Globaux", expanded=True):
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("#### üéØ Strat√©gie d'extraction")
                
                strategy = st.radio(
                    "Mode de traitement",
                    ["üöÄ Vitesse (1 mod√®le)", "‚öñÔ∏è √âquilibr√© (2-3 mod√®les)", "üî¨ Pr√©cision maximale (tous)"],
                    help="Choisissez entre vitesse et pr√©cision"
                )
                
                parallel_processing = st.checkbox(
                    "‚ö° Traitement parall√®le",
                    value=True,
                    help="Ex√©cute les mod√®les simultan√©ment"
                )
                
                auto_select = st.checkbox(
                    "üé≤ S√©lection automatique des mod√®les",
                    help="Choisit les meilleurs mod√®les selon le type de document"
                )
            
            with col2:
                st.markdown("#### üîÄ Param√®tres de Fusion")
                
                fusion_strategy = st.selectbox(
                    "Strat√©gie de fusion",
                    ["Vote majoritaire", "Moyenne pond√©r√©e", "Consensus strict", "Union totale"],
                    help="Comment combiner les r√©sultats des mod√®les"
                )
                
                min_models_for_fusion = st.slider(
                    "Mod√®les minimum pour fusion",
                    2, len(self.ai_models), 2,
                    help="Nombre minimum de mod√®les requis"
                )
                
                confidence_boost = st.slider(
                    "Boost de confiance (fusion)",
                    0.0, 0.3, 0.1,
                    help="Augmentation de confiance pour les consensus"
                )
        
        # Configuration par mod√®le
        st.markdown("### üéõÔ∏è Configuration Individuelle des Mod√®les")
        
        for model_id, model_info in self.ai_models.items():
            with st.expander(f"{model_info['icon']} {model_info['name']}", expanded=False):
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    enabled = st.checkbox(
                        "Activ√©",
                        value=True,
                        key=f"enable_{model_id}"
                    )
                    
                    weight = st.slider(
                        "Poids dans la fusion",
                        0.1, 2.0, 1.0,
                        key=f"weight_{model_id}",
                        help="Importance relative du mod√®le"
                    )
                
                with col2:
                    temperature = st.slider(
                        "Temp√©rature",
                        0.0, 1.0, 0.3,
                        key=f"temp_{model_id}",
                        help="Cr√©ativit√© vs pr√©cision"
                    )
                    
                    max_tokens = st.number_input(
                        "Tokens max",
                        100, 4000, 1000,
                        key=f"tokens_{model_id}"
                    )
                
                with col3:
                    st.markdown("**Sp√©cialit√©s:**")
                    for strength in model_info['strengths']:
                        st.caption(f"‚úì {strength}")
                    
                    # Statistiques du mod√®le
                    if 'extraction_history' in st.session_state.extraction_state:
                        uses = sum(
                            1 for h in st.session_state.extraction_state['history']
                            if model_id in h.get('models_used', [])
                        )
                        st.metric("Utilisations", uses)
        
        # Presets de configuration
        st.markdown("### üìã Configurations Pr√©enregistr√©es")
        
        preset_col1, preset_col2, preset_col3 = st.columns(3)
        
        presets = {
            "Juridique Standard": {
                "models": ["claude", "gpt4"],
                "fusion": True,
                "description": "Optimal pour documents juridiques"
            },
            "Analyse Rapide": {
                "models": ["gemini"],
                "fusion": False,
                "description": "Traitement ultra-rapide"
            },
            "Audit Complet": {
                "models": ["claude", "gpt4", "gemini", "mistral"],
                "fusion": True,
                "description": "Analyse exhaustive"
            }
        }
        
        for col, (preset_name, preset_config) in zip([preset_col1, preset_col2, preset_col3], presets.items()):
            with col:
                if st.button(
                    f"**{preset_name}**\n_{preset_config['description']}_",
                    use_container_width=True,
                    key=f"preset_{preset_name}"
                ):
                    st.session_state.extraction_state['preferences']['default_models'] = preset_config['models']
                    st.session_state.extraction_state['preferences']['auto_fusion'] = preset_config['fusion']
                    st.success(f"‚úÖ Configuration '{preset_name}' appliqu√©e")
                    st.rerun()
        
        # Test de configuration
        with st.expander("üß™ Tester la Configuration"):
            test_text = st.text_area(
                "Texte de test",
                value="La soci√©t√© EXEMPLE SAS, repr√©sent√©e par M. Jean TEST, a conclu un contrat le 15 janvier 2024 pour un montant de 50.000 euros.",
                height=100
            )
            
            if st.button("üöÄ Lancer le test", type="primary"):
                with st.spinner("Test en cours..."):
                    time.sleep(1)  # Simulation
                    
                    st.success("‚úÖ Test r√©ussi!")
                    
                    # R√©sultats simul√©s
                    st.markdown("**R√©sultats du test:**")
                    test_results = {
                        "Personnes": ["M. Jean TEST"],
                        "Organisations": ["EXEMPLE SAS"],
                        "Dates": ["15 janvier 2024"],
                        "Montants": ["50.000 euros"]
                    }
                    
                    for entity_type, values in test_results.items():
                        st.write(f"‚Ä¢ **{entity_type}:** {', '.join(values)}")
    
    def _render_history_tab(self):
        """Onglet historique des extractions"""
        st.markdown("### üìö Historique des Extractions")
        
        history = st.session_state.extraction_state.get('history', [])
        
        if not history:
            st.info("Aucune extraction dans l'historique. Effectuez votre premi√®re extraction!")
            return
        
        # Filtres et recherche
        col1, col2, col3 = st.columns([2, 1, 1])
        
        with col1:
            search_term = st.text_input(
                "üîç Rechercher",
                placeholder="Filtrer par mode, date, mod√®les..."
            )
        
        with col2:
            filter_mode = st.selectbox(
                "Mode",
                ["Tous"] + ["Automatique", "Favorable", "√Ä charge", "Personnalis√©"]
            )
        
        with col3:
            sort_order = st.selectbox(
                "Trier par",
                ["Plus r√©cent", "Plus ancien", "Plus d'entit√©s", "Meilleur score"]
            )
        
        # Filtrer et trier l'historique
        filtered_history = history
        
        if search_term:
            filtered_history = [
                h for h in filtered_history
                if search_term.lower() in h['mode'].lower() or
                search_term.lower() in str(h['models_used']).lower()
            ]
        
        if filter_mode != "Tous":
            filtered_history = [h for h in filtered_history if h['mode'] == filter_mode]
        
        # Trier
        if sort_order == "Plus r√©cent":
            filtered_history.sort(key=lambda x: x['timestamp'], reverse=True)
        elif sort_order == "Plus ancien":
            filtered_history.sort(key=lambda x: x['timestamp'])
        elif sort_order == "Plus d'entit√©s":
            filtered_history.sort(
                key=lambda x: x['results']['statistics']['total_entities'],
                reverse=True
            )
        else:  # Meilleur score
            filtered_history.sort(
                key=lambda x: x['results']['quality_metrics']['overall_score'],
                reverse=True
            )
        
        # Afficher l'historique
        st.markdown(f"**{len(filtered_history)} extractions trouv√©es**")
        
        for extraction in filtered_history[:10]:  # Limiter l'affichage
            # Carte d'historique
            with st.container():
                col1, col2, col3, col4, col5 = st.columns([3, 2, 2, 1, 1])
                
                with col1:
                    st.markdown(f"""
                        **{extraction['timestamp'].strftime('%d/%m/%Y %H:%M')}**  
                        Mode: {extraction['mode']}
                    """)
                
                with col2:
                    models_icons = ' '.join([
                        self.ai_models[m]['icon']
                        for m in extraction['models_used']
                    ])
                    st.markdown(f"**Mod√®les:** {models_icons}")
                    
                    if extraction.get('fusion_enabled'):
                        st.markdown('<span class="fusion-indicator">Fusion</span>', unsafe_allow_html=True)
                
                with col3:
                    stats = extraction['results']['statistics']
                    quality = extraction['results']['quality_metrics']['overall_score']
                    
                    st.metric(
                        "Entit√©s",
                        stats['total_entities'],
                        delta=f"{quality*100:.0f}% qualit√©"
                    )
                
                with col4:
                    if st.button("üëÅÔ∏è", key=f"view_history_{extraction['id']}", help="Voir d√©tails"):
                        st.session_state.extraction_state['current_extraction'] = extraction
                        st.rerun()
                
                with col5:
                    if st.button("üóëÔ∏è", key=f"delete_history_{extraction['id']}", help="Supprimer"):
                        st.session_state.extraction_state['history'].remove(extraction)
                        st.rerun()
                
                st.divider()
        
        # Statistiques globales
        if history:
            st.markdown("### üìä Statistiques Globales")
            
            total_extractions = len(history)
            total_entities = sum(h['results']['statistics']['total_entities'] for h in history)
            avg_quality = sum(
                h['results']['quality_metrics']['overall_score'] 
                for h in history
            ) / total_extractions
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("Total Extractions", total_extractions)
            
            with col2:
                st.metric("Total Entit√©s", f"{total_entities:,}")
            
            with col3:
                st.metric("Qualit√© Moyenne", f"{avg_quality*100:.1f}%")
            
            with col4:
                most_used_model = Counter(
                    model
                    for h in history
                    for model in h['models_used']
                ).most_common(1)[0][0]
                
                st.metric(
                    "Mod√®le Favori",
                    self.ai_models[most_used_model]['name']
                )
            
            # Actions sur l'historique
            st.markdown("### üéØ Actions")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                if st.button("üì• Exporter l'historique", use_container_width=True):
                    self._export_history(history)
            
            with col2:
                if st.button("üìä Rapport de synth√®se", use_container_width=True):
                    self._generate_history_report(history)
            
            with col3:
                if st.button("üóëÔ∏è Effacer l'historique", use_container_width=True, type="secondary"):
                    if st.checkbox("Confirmer la suppression"):
                        st.session_state.extraction_state['history'] = []
                        st.success("‚úÖ Historique effac√©")
                        st.rerun()
    
    def _render_settings_tab(self):
        """Onglet des param√®tres du module"""
        st.markdown("### ‚öôÔ∏è Param√®tres du Module")
        
        # Pr√©f√©rences g√©n√©rales
        with st.expander("üé® Pr√©f√©rences G√©n√©rales", expanded=True):
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("#### Interface")
                
                theme = st.selectbox(
                    "Th√®me de couleur",
                    ["Violet (d√©faut)", "Bleu", "Vert", "Orange"],
                    help="Change les couleurs de l'interface"
                )
                
                animations = st.checkbox(
                    "Animations activ√©es",
                    value=True,
                    help="Active/d√©sactive les animations"
                )
                
                compact_mode = st.checkbox(
                    "Mode compact",
                    value=False,
                    help="R√©duit l'espacement pour plus de contenu"
                )
            
            with col2:
                st.markdown("#### Comportement")
                
                auto_save = st.checkbox(
                    "Sauvegarde automatique",
                    value=True,
                    help="Sauvegarde automatiquement les extractions"
                )
                
                notifications = st.checkbox(
                    "Notifications",
                    value=True,
                    help="Affiche des notifications pour les actions"
                )
                
                debug_mode = st.checkbox(
                    "Mode debug",
                    value=False,
                    help="Affiche des informations techniques"
                )
        
        # Param√®tres d'extraction
        with st.expander("üîç Param√®tres d'Extraction"):
            st.markdown("#### Valeurs par d√©faut")
            
            default_confidence = st.slider(
                "Seuil de confiance par d√©faut",
                0.0, 1.0,
                st.session_state.extraction_state['preferences']['confidence_threshold'],
                help="Confiance minimale pour conserver une extraction"
            )
            
            default_context = st.slider(
                "Fen√™tre de contexte par d√©faut",
                50, 500,
                st.session_state.extraction_state['preferences']['context_window'],
                help="Caract√®res de contexte autour des extractions"
            )
            
            st.markdown("#### Limites")
            
            max_entities_per_type = st.number_input(
                "Entit√©s max par type",
                10, 1000, 100,
                help="Limite le nombre d'entit√©s extraites par type"
            )
            
            timeout_seconds = st.number_input(
                "Timeout (secondes)",
                10, 300, 60,
                help="Temps maximum pour une extraction"
            )
        
        # Gestion des donn√©es
        with st.expander("üíæ Gestion des Donn√©es"):
            st.markdown("#### Cache et Stockage")
            
            cache_size = len(st.session_state.extraction_state.get('cache', {}))
            history_size = len(st.session_state.extraction_state.get('history', []))
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric("√âl√©ments en cache", cache_size)
                if st.button("üßπ Vider le cache", use_container_width=True):
                    st.session_state.extraction_state['cache'] = {}
                    st.success("‚úÖ Cache vid√©")
            
            with col2:
                st.metric("Extractions en historique", history_size)
                max_history = st.number_input(
                    "Historique maximum",
                    10, 1000, 100,
                    help="Nombre maximum d'extractions √† conserver"
                )
            
            st.markdown("#### Export/Import")
            
            col1, col2 = st.columns(2)
            
            with col1:
                if st.button("üì§ Exporter configuration", use_container_width=True):
                    config_data = json.dumps(
                        st.session_state.extraction_state['preferences'],
                        indent=2
                    )
                    st.download_button(
                        "üíæ T√©l√©charger",
                        data=config_data,
                        file_name="extraction_config.json",
                        mime="application/json"
                    )
            
            with col2:
                uploaded_config = st.file_uploader(
                    "üì• Importer configuration",
                    type=['json']
                )
                
                if uploaded_config:
                    try:
                        config = json.load(uploaded_config)
                        st.session_state.extraction_state['preferences'].update(config)
                        st.success("‚úÖ Configuration import√©e")
                        st.rerun()
                    except Exception as e:
                        st.error(f"Erreur : {e}")
        
        # Int√©grations
        with st.expander("üîå Int√©grations"):
            st.markdown("#### APIs Externes")
            
            st.info("üöß Configuration des APIs en cours de d√©veloppement")
            
            # Placeholder pour futures int√©grations
            integrations = {
                "Azure Cognitive Services": False,
                "OpenAI API": False,
                "Google Cloud AI": False,
                "Anthropic Claude": False
            }
            
            for service, enabled in integrations.items():
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.write(service)
                with col2:
                    st.checkbox("Activ√©", value=enabled, key=f"int_{service}", disabled=True)
        
        # Actions
        st.markdown("### üíæ Actions")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("üíæ Sauvegarder", type="primary", use_container_width=True):
                # Sauvegarder les pr√©f√©rences
                st.session_state.extraction_state['preferences'].update({
                    'confidence_threshold': default_confidence,
                    'context_window': default_context
                })
                st.success("‚úÖ Param√®tres sauvegard√©s")
        
        with col2:
            if st.button("üîÑ R√©initialiser", use_container_width=True):
                if st.checkbox("Confirmer la r√©initialisation"):
                    self._initialize_session_state()
                    st.success("‚úÖ Param√®tres r√©initialis√©s")
                    st.rerun()
        
        with col3:
            if st.button("‚ÑπÔ∏è √Ä propos", use_container_width=True):
                st.info(
                    """
                    **Module d'Extraction v2.0**  
                    Extraction intelligente multi-mod√®les avec fusion  
                    ¬© 2024 Nexora Law IA
                    """
                )
    
    def _show_export_dialog(self, results: Dict[str, Any]):
        """Dialogue d'export des r√©sultats"""
        with st.expander("üì§ Options d'Export", expanded=True):
            format_type = st.selectbox(
                "Format",
                ["JSON", "CSV", "PDF", "Word", "Excel"]
            )
            
            include_options = st.multiselect(
                "Inclure",
                ["R√©sultats bruts", "Statistiques", "Insights", "M√©tadonn√©es"],
                default=["R√©sultats bruts", "Statistiques"]
            )
            
            if st.button("üíæ G√©n√©rer l'export", type="primary"):
                with st.spinner("G√©n√©ration en cours..."):
                    time.sleep(1)  # Simulation
                    
                    # G√©n√©rer le contenu selon le format
                    if format_type == "JSON":
                        export_data = json.dumps(results, indent=2, default=str)
                        file_name = f"extraction_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                        mime_type = "application/json"
                    else:
                        # Placeholder pour autres formats
                        export_data = "Export simul√©"
                        file_name = f"extraction_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
                        mime_type = "text/plain"
                    
                    st.download_button(
                        f"üì• T√©l√©charger {format_type}",
                        data=export_data,
                        file_name=file_name,
                        mime=mime_type,
                        use_container_width=True
                    )
                    
                    st.success(f"‚úÖ Export {format_type} g√©n√©r√© avec succ√®s!")
    
    def _export_history(self, history: List[Dict]):
        """Exporte l'historique complet"""
        export_data = {
            'export_date': datetime.now().isoformat(),
            'total_extractions': len(history),
            'extractions': history
        }
        
        json_data = json.dumps(export_data, indent=2, default=str)
        
        st.download_button(
            "üíæ T√©l√©charger l'historique",
            data=json_data,
            file_name=f"historique_extractions_{datetime.now().strftime('%Y%m%d')}.json",
            mime="application/json"
        )
    
    def _generate_history_report(self, history: List[Dict]):
        """G√©n√®re un rapport de synth√®se de l'historique"""
        with st.spinner("G√©n√©ration du rapport..."):
            time.sleep(1)  # Simulation
            
            # Cr√©er le rapport
            report = f"""
# Rapport de Synth√®se des Extractions
Date: {datetime.now().strftime('%d/%m/%Y %H:%M')}

## R√©sum√© Ex√©cutif
- Total d'extractions: {len(history)}
- P√©riode couverte: {history[-1]['timestamp'].strftime('%d/%m/%Y')} - {history[0]['timestamp'].strftime('%d/%m/%Y')}
- Entit√©s totales extraites: {sum(h['results']['statistics']['total_entities'] for h in history):,}

## Statistiques par Mode
"""
            
            # Statistiques par mode
            mode_stats = Counter(h['mode'] for h in history)
            for mode, count in mode_stats.most_common():
                report += f"- {mode}: {count} extractions\n"
            
            report += "\n## Mod√®les d'IA Utilis√©s\n"
            
            # Statistiques par mod√®le
            model_stats = Counter(
                model
                for h in history
                for model in h['models_used']
            )
            
            for model, count in model_stats.most_common():
                model_name = self.ai_models[model]['name']
                report += f"- {model_name}: {count} utilisations\n"
            
            # Qualit√© moyenne
            avg_quality = sum(
                h['results']['quality_metrics']['overall_score']
                for h in history
            ) / len(history)
            
            report += f"\n## Qualit√© Moyenne: {avg_quality*100:.1f}%\n"
            
            # Afficher le rapport
            st.text_area(
                "Rapport de synth√®se",
                value=report,
                height=400
            )
            
            # Option de t√©l√©chargement
            st.download_button(
                "üì• T√©l√©charger le rapport",
                data=report,
                file_name=f"rapport_synthese_{datetime.now().strftime('%Y%m%d')}.txt",
                mime="text/plain"
            )

# Point d'entr√©e pour lazy loading et tests
if __name__ == "__main__":
    run()