"""Template de module am√©lior√© pour Nexora Law IA avec IA Multi-Mod√®les"""

import asyncio
import hashlib
import json
import os
import sys
import time
from config.ai_models import AI_MODELS
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st

# Ajouter le chemin parent pour importer utils
sys.path.append(str(Path(__file__).parent.parent))
from utils import clean_key, format_legal_date, truncate_text
from utils.decorators import decorate_public_functions

# Enregistrement automatique des fonctions publiques pour le module
decorate_public_functions(sys.modules[__name__])


# Configuration des mod√®les IA disponibles import√©e depuis config.ai_models

def run():
    """Fonction principale du module avec am√©lioration UX et IA multi-mod√®les"""
    
    # CSS personnalis√© pour am√©liorer le design
    st.markdown("""
    <style>
    /* Animations */
    @keyframes fadeIn {
        from { opacity: 0; transform: translateY(10px); }
        to { opacity: 1; transform: translateY(0); }
    }
    
    .fade-in {
        animation: fadeIn 0.5s ease-out;
    }
    
    /* Cards personnalis√©es */
    .model-card {
        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
        border-radius: 15px;
        padding: 20px;
        margin: 10px 0;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1);
        transition: all 0.3s ease;
    }
    
    .model-card:hover {
        transform: translateY(-5px);
        box-shadow: 0 8px 25px rgba(0,0,0,0.15);
    }
    
    /* Progress bars am√©lior√©es */
    .custom-progress {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        border-radius: 10px;
        height: 8px;
    }
    
    /* R√©sultats stylis√©s */
    .result-box {
        background: #f8f9fa;
        border-left: 4px solid #667eea;
        padding: 15px;
        border-radius: 8px;
        margin: 10px 0;
    }
    
    /* Badges de statut */
    .status-badge {
        display: inline-block;
        padding: 5px 15px;
        border-radius: 20px;
        font-size: 14px;
        font-weight: 600;
    }
    
    .status-success {
        background: #d4edda;
        color: #155724;
    }
    
    .status-warning {
        background: #fff3cd;
        color: #856404;
    }
    
    .status-error {
        background: #f8d7da;
        color: #721c24;
    }
    
    /* Tooltips */
    .tooltip {
        position: relative;
        display: inline-block;
        cursor: help;
    }
    
    .tooltip .tooltiptext {
        visibility: hidden;
        background-color: #555;
        color: #fff;
        text-align: center;
        border-radius: 6px;
        padding: 5px 10px;
        position: absolute;
        z-index: 1;
        bottom: 125%;
        left: 50%;
        margin-left: -60px;
        opacity: 0;
        transition: opacity 0.3s;
    }
    
    .tooltip:hover .tooltiptext {
        visibility: visible;
        opacity: 1;
    }
    
    /* Effet de chargement */
    .loading-wave {
        display: inline-block;
        animation: wave 1.4s linear infinite;
    }
    
    @keyframes wave {
        0% { transform: translateY(0px); }
        50% { transform: translateY(-10px); }
        100% { transform: translateY(0px); }
    }
    </style>
    """, unsafe_allow_html=True)
    
    # Titre avec animation
    st.markdown('<div class="fade-in">', unsafe_allow_html=True)
    st.title("üéØ Module IA Multi-Mod√®les Avanc√©")
    st.markdown("**Analysez et traitez vos documents juridiques avec plusieurs mod√®les d'IA en simultan√©**")
    st.markdown('</div>', unsafe_allow_html=True)
    
    # Initialisation avanc√©e des variables de session
    if 'module_state' not in st.session_state:
        st.session_state.module_state = {
            'initialized': True,
            'results': None,
            'config': {},
            'selected_models': [],
            'fusion_mode': 'weighted',
            'processing_history': [],
            'cache': {},
            'user_preferences': {
                'theme': 'light',
                'auto_save': True,
                'notifications': True
            }
        }
    
    # Barre de progression globale
    if st.session_state.module_state.get('processing'):
        progress_container = st.container()
        with progress_container:
            st.markdown(
                f"""
                <div class="custom-progress" style="width: {st.session_state.module_state.get('progress', 0)}%"></div>
                """,
                unsafe_allow_html=True
            )
    
    # Structure en onglets am√©lior√©e
    tab_icons = ["üì§", "ü§ñ", "‚öôÔ∏è", "üöÄ", "üìä", "üìà", "üíæ"]
    tab_names = ["Entr√©e", "Mod√®les IA", "Configuration", "Traitement", "R√©sultats", "Analytics", "Export"]
    tabs = st.tabs([f"{icon} {name}" for icon, name in zip(tab_icons, tab_names)])
    
    with tabs[0]:  # Onglet Entr√©e am√©lior√©
        st.markdown("### üì§ S√©lection intelligente des donn√©es")
        
        # Mode de s√©lection
        input_mode = st.radio(
            "Mode d'entr√©e",
            ["üîç Recherche intelligente", "üìÅ Container Azure", "üì§ Upload direct", "üîó Import URL"],
            horizontal=True
        )
        
        if input_mode == "üîç Recherche intelligente":
            col1, col2 = st.columns([3, 1])
            with col1:
                search_query = st.text_input(
                    "Recherche avanc√©e",
                    placeholder="Ex: contrat bail commercial 2024 Paris...",
                    help="Utilisez des mots-cl√©s, dates, types de documents"
                )
            with col2:
                search_filters = st.multiselect(
                    "Filtres",
                    ["üìÖ Date", "üìç Lieu", "üë§ Partie", "üìÑ Type"],
                    default=[]
                )
            
            if search_query:
                with st.spinner("üîç Recherche en cours..."):
                    time.sleep(0.5)  # Simulation
                    st.success(f"‚úÖ 12 documents trouv√©s pour '{search_query}'")
                    
                    # Aper√ßu des r√©sultats
                    preview_data = {
                        'Document': ['Contrat_001.pdf', 'Avenant_2024.docx', 'Courrier_mise_demeure.pdf'],
                        'Type': ['Contrat', 'Avenant', 'Courrier'],
                        'Date': ['2024-01-15', '2024-03-20', '2024-02-10'],
                        'Pertinence': ['95%', '87%', '76%']
                    }
                    st.dataframe(preview_data, use_container_width=True, hide_index=True)
        
        elif input_mode == "üìÅ Container Azure":
            col1, col2, col3 = st.columns([2, 2, 1])
            with col1:
                container = st.selectbox(
                    "Container",
                    ["juridique", "expertises", "procedures", "correspondances"],
                    help="S√©lectionnez le container Azure"
                )
            with col2:
                subfolder = st.text_input("Sous-dossier (optionnel)", placeholder="2024/contrats/")
            with col3:
                st.metric("Fichiers", "248", help="Nombre de fichiers dans le container")
        
        elif input_mode == "üì§ Upload direct":
            uploaded_files = st.file_uploader(
                "Glissez vos fichiers ici",
                type=['pdf', 'txt', 'docx', 'xlsx', 'msg', 'eml'],
                accept_multiple_files=True,
                help="Formats support√©s: PDF, TXT, DOCX, XLSX, MSG, EML"
            )
            
            if uploaded_files:
                st.success(f"‚úÖ {len(uploaded_files)} fichier(s) charg√©(s)")
                # Affichage d√©taill√© des fichiers
                for file in uploaded_files:
                    col1, col2, col3 = st.columns([3, 1, 1])
                    with col1:
                        st.text(f"üìÑ {file.name}")
                    with col2:
                        st.text(f"{file.size / 1024:.1f} KB")
                    with col3:
                        if st.button("‚ùå", key=f"del_{file.name}"):
                            uploaded_files.remove(file)
        
        else:  # Import URL
            url_input = st.text_area(
                "URLs des documents",
                placeholder="https://example.com/document1.pdf\nhttps://example.com/document2.pdf",
                height=100
            )
    
    with tabs[1]:  # Onglet Mod√®les IA
        st.markdown("### ü§ñ S√©lection et configuration des mod√®les IA")
        
        # S√©lection rapide
        quick_select = st.radio(
            "S√©lection rapide",
            ["üéØ Recommand√©", "‚ö° Performance", "üí∞ √âconomique", "üîß Personnalis√©"],
            horizontal=True
        )
        
        if quick_select == "üéØ Recommand√©":
            st.session_state.module_state['selected_models'] = ["gpt4", "claude"]
        elif quick_select == "‚ö° Performance":
            st.session_state.module_state['selected_models'] = ["gpt4", "claude", "gemini"]
        elif quick_select == "üí∞ √âconomique":
            st.session_state.module_state['selected_models'] = ["mistral", "llama"]
        
        # Affichage des mod√®les avec cards am√©lior√©es
        st.markdown("#### Mod√®les disponibles")
        
        cols = st.columns(3)
        for idx, (model_id, model) in enumerate(AI_MODELS.items()):
            with cols[idx % 3]:
                selected = st.checkbox(
                    f"{model['icon']} **{model['name']}**",
                    value=model_id in st.session_state.module_state.get('selected_models', []),
                    key=f"model_{model_id}"
                )
                
                if selected and model_id not in st.session_state.module_state['selected_models']:
                    st.session_state.module_state['selected_models'].append(model_id)
                elif not selected and model_id in st.session_state.module_state['selected_models']:
                    st.session_state.module_state['selected_models'].remove(model_id)
                
                # Card avec infos d√©taill√©es
                st.markdown(
                    f"""
                    <div class="model-card" style="border-top: 3px solid {model['color']}">
                        <p style="font-size: 14px; color: #666;">{model['description']}</p>
                        <div style="margin: 10px 0;">
                            <strong>Points forts:</strong><br>
                            {'<br>'.join([f'‚Ä¢ {s}' for s in model['strengths']])}
                        </div>
                        <div style="margin-top: 10px;">
                            <strong>Performance:</strong>
                            <div style="background: #e0e0e0; border-radius: 5px; height: 10px; margin-top: 5px;">
                                <div style="background: {model['color']}; width: {model['performance_score']*100}%; height: 100%; border-radius: 5px;"></div>
                            </div>
                            <small>{model['performance_score']*100:.0f}%</small>
                        </div>
                    </div>
                    """,
                    unsafe_allow_html=True
                )
        
        # Mode de fusion
        st.markdown("#### Mode de fusion des r√©sultats")
        fusion_col1, fusion_col2 = st.columns([2, 1])
        
        with fusion_col1:
            fusion_mode = st.selectbox(
                "Strat√©gie de fusion",
                [
                    ("weighted", "üéØ Pond√©r√©e - Combine selon la performance"),
                    ("consensus", "ü§ù Consensus - Points communs"),
                    ("complementary", "üîÑ Compl√©mentaire - Combine les forces"),
                    ("voting", "üó≥Ô∏è Vote majoritaire - D√©cision d√©mocratique"),
                    ("hierarchical", "üìä Hi√©rarchique - Par ordre de priorit√©")
                ],
                format_func=lambda x: x[1],
                help="Choisissez comment combiner les r√©sultats des diff√©rents mod√®les"
            )
            st.session_state.module_state['fusion_mode'] = fusion_mode[0]
        
        with fusion_col2:
            confidence_threshold = st.slider(
                "Seuil de confiance",
                0.0, 1.0, 0.7,
                help="Niveau minimum de confiance pour accepter un r√©sultat"
            )
    
    with tabs[2]:  # Onglet Configuration avanc√©e
        st.markdown("### ‚öôÔ∏è Configuration avanc√©e")
        
        # Organisation en accord√©on
        with st.expander("üé® Param√®tres d'interface", expanded=True):
            col1, col2, col3 = st.columns(3)
            
            with col1:
                theme = st.selectbox("Th√®me", ["üåû Clair", "üåô Sombre", "üé® Auto"])
                language = st.selectbox("Langue", ["üá´üá∑ Fran√ßais", "üá¨üáß English", "üá™üá∏ Espa√±ol"])
            
            with col2:
                auto_save = st.checkbox("üíæ Sauvegarde auto", value=True)
                notifications = st.checkbox("üîî Notifications", value=True)
            
            with col3:
                animation_speed = st.select_slider(
                    "Vitesse animations",
                    ["üêå Lente", "üö∂ Normale", "üèÉ Rapide", "‚ö° Instantan√©"]
                )
        
        with st.expander("üîß Param√®tres de traitement"):
            col1, col2 = st.columns(2)
            
            with col1:
                batch_size = st.number_input("Taille des lots", 1, 100, 10)
                parallel_processing = st.checkbox("‚ö° Traitement parall√®le", value=True)
                cache_results = st.checkbox("üíæ Mise en cache", value=True)
            
            with col2:
                timeout = st.slider("Timeout (secondes)", 30, 300, 120)
                retry_count = st.number_input("Tentatives en cas d'√©chec", 1, 5, 3)
                
        with st.expander("üîç Param√®tres d'analyse"):
            analysis_depth = st.select_slider(
                "Profondeur d'analyse",
                ["Superficielle", "Standard", "Approfondie", "Exhaustive"],
                value="Standard"
            )
            
            extract_options = st.multiselect(
                "Extractions sp√©cifiques",
                ["üìÖ Dates", "üí∞ Montants", "üë§ Parties", "üìç Lieux", "üìß Contacts", "üî¢ R√©f√©rences"],
                default=["üìÖ Dates", "üí∞ Montants", "üë§ Parties"]
            )
            
            analysis_focus = st.multiselect(
                "Focus d'analyse",
                ["‚öñÔ∏è Juridique", "üíº Commercial", "üí∞ Financier", "üö® Risques", "üìä Statistique"],
                default=["‚öñÔ∏è Juridique", "üö® Risques"]
            )
        
        with st.expander("üîê S√©curit√© et confidentialit√©"):
            col1, col2 = st.columns(2)
            
            with col1:
                anonymize = st.checkbox("üîí Anonymiser les donn√©es", value=False)
                encryption = st.checkbox("üîê Chiffrement des r√©sultats", value=True)
            
            with col2:
                data_retention = st.selectbox(
                    "R√©tention des donn√©es",
                    ["1 heure", "24 heures", "7 jours", "30 jours", "Permanent"]
                )
                audit_log = st.checkbox("üìù Journal d'audit", value=True)
    
    with tabs[3]:  # Onglet Traitement am√©lior√©
        st.markdown("### üöÄ Centre de traitement")
        
        # R√©sum√© de la configuration
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                "Documents", 
                len(st.session_state.module_state.get('documents', [])),
                help="Nombre de documents √† traiter"
            )
        
        with col2:
            st.metric(
                "Mod√®les IA",
                len(st.session_state.module_state.get('selected_models', [])),
                help="Mod√®les s√©lectionn√©s"
            )
        
        with col3:
            estimated_time = len(st.session_state.module_state.get('documents', [])) * 2.5
            st.metric(
                "Temps estim√©",
                f"{estimated_time:.0f}s",
                help="Estimation bas√©e sur l'historique"
            )
        
        with col4:
            cost_estimate = len(st.session_state.module_state.get('documents', [])) * 0.02
            st.metric(
                "Co√ªt estim√©",
                f"{cost_estimate:.2f}‚Ç¨",
                help="Estimation des co√ªts API"
            )
        
        # V√©rifications pr√©-traitement
        st.markdown("#### üîç V√©rifications pr√©-traitement")
        checks = {
            "Documents s√©lectionn√©s": len(st.session_state.module_state.get('documents', [])) > 0,
            "Mod√®les IA configur√©s": len(st.session_state.module_state.get('selected_models', [])) > 0,
            "Param√®tres valid√©s": True,
            "Quota API suffisant": True
        }
        
        all_checks_passed = all(checks.values())
        
        for check, status in checks.items():
            if status:
                st.success(f"‚úÖ {check}")
            else:
                st.error(f"‚ùå {check}")
        
        # Options de lancement
        col1, col2 = st.columns([3, 1])
        
        with col1:
            if st.button(
                "üöÄ Lancer le traitement",
                type="primary",
                use_container_width=True,
                disabled=not all_checks_passed
            ):
                run_processing()
        
        with col2:
            schedule_processing = st.checkbox("üìÖ Planifier", help="Planifier le traitement")
        
        if schedule_processing:
            schedule_date = st.date_input("Date", min_value=datetime.now().date())
            schedule_time = st.time_input("Heure")
        
        # File d'attente et historique
        with st.expander("üìã File d'attente et historique", expanded=False):
            queue_tab, history_tab = st.tabs(["File d'attente", "Historique"])
            
            with queue_tab:
                if st.session_state.module_state.get('processing_queue'):
                    queue_df = pd.DataFrame(st.session_state.module_state['processing_queue'])
                    st.dataframe(queue_df, use_container_width=True)
                else:
                    st.info("Aucun traitement en attente")
            
            with history_tab:
                if st.session_state.module_state.get('processing_history'):
                    history_df = pd.DataFrame(st.session_state.module_state['processing_history'])
                    st.dataframe(history_df, use_container_width=True)
                else:
                    st.info("Aucun historique disponible")
    
    with tabs[4]:  # Onglet R√©sultats enrichi
        if st.session_state.module_state.get('results'):
            st.markdown("### üìä Tableau de bord des r√©sultats")
            
            # Vue d'ensemble avec m√©triques am√©lior√©es
            metrics_container = st.container()
            with metrics_container:
                col1, col2, col3, col4, col5 = st.columns(5)
                
                with col1:
                    st.metric("Documents trait√©s", "42", "100%", help="Tous les documents ont √©t√© analys√©s")
                with col2:
                    st.metric("Temps total", "2m 34s", "-15%", help="Plus rapide que la moyenne")
                with col3:
                    st.metric("Pr√©cision moyenne", "94.2%", "+2.1%", help="Bas√© sur la validation crois√©e")
                with col4:
                    st.metric("Anomalies d√©tect√©es", "3", help="N√©cessitent une attention particuli√®re")
                with col5:
                    st.metric("Score global", "A+", help="Excellente qualit√© d'analyse")
            
            # R√©sultats par mod√®le avec visualisation
            st.markdown("#### ü§ñ Performance par mod√®le")
            
            model_results = {
                'Mod√®le': ['GPT-4', 'Claude 3', 'Mistral', 'Gemini'],
                'Documents': [42, 42, 42, 42],
                'Temps (s)': [45, 52, 28, 38],
                'Pr√©cision (%)': [96.5, 95.2, 91.8, 93.7],
                'Co√ªt (‚Ç¨)': [2.10, 1.95, 0.84, 1.68]
            }
            
            # Graphique interactif
            fig = go.Figure()
            
            for model in model_results['Mod√®le']:
                idx = model_results['Mod√®le'].index(model)
                fig.add_trace(go.Bar(
                    name=model,
                    x=['Temps', 'Pr√©cision', 'Co√ªt'],
                    y=[
                        model_results['Temps (s)'][idx] / 10,
                        model_results['Pr√©cision (%)'][idx] / 10,
                        model_results['Co√ªt (‚Ç¨)'][idx] * 10
                    ],
                    text=[
                        f"{model_results['Temps (s)'][idx]}s",
                        f"{model_results['Pr√©cision (%)'][idx]}%",
                        f"{model_results['Co√ªt (‚Ç¨)'][idx]}‚Ç¨"
                    ],
                    textposition='auto',
                ))
            
            fig.update_layout(
                title="Comparaison des performances",
                barmode='group',
                height=400,
                showlegend=True
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # R√©sultats fusionn√©s
            st.markdown("#### üîÑ R√©sultats fusionn√©s")
            
            fusion_tabs = st.tabs(["üìù Synth√®se", "üîç D√©tails", "‚öñÔ∏è Analyse juridique", "üö® Risques"])
            
            with fusion_tabs[0]:
                st.markdown(
                    """
                    <div class="result-box">
                        <h4>Synth√®se ex√©cutive</h4>
                        <p>L'analyse multi-mod√®les a identifi√© 3 points critiques n√©cessitant une attention imm√©diate:</p>
                        <ul>
                            <li><strong>Clause de non-concurrence:</strong> Potentiellement excessive (dur√©e: 5 ans, zone: mondiale)</li>
                            <li><strong>P√©nalit√©s de retard:</strong> Montant disproportionn√© (500‚Ç¨/jour)</li>
                            <li><strong>Juridiction:</strong> Clause attributive de comp√©tence √† l'√©tranger</li>
                        </ul>
                        <p><strong>Recommandation:</strong> R√©vision urgente des clauses identifi√©es avant signature.</p>
                    </div>
                    """,
                    unsafe_allow_html=True
                )
            
            with fusion_tabs[1]:
                # Tableau d√©taill√© des r√©sultats
                detailed_results = pd.DataFrame({
                    'Section': ['Pr√©ambule', 'Obligations', 'P√©nalit√©s', 'Juridiction'],
                    'Risque': ['Faible', 'Moyen', '√âlev√©', 'Critique'],
                    'Confiance': ['98%', '92%', '87%', '95%'],
                    'Consensus': ['‚úÖ Unanime', '‚úÖ Majoritaire', '‚ö†Ô∏è Divergent', '‚úÖ Unanime']
                })
                
                st.dataframe(
                    detailed_results,
                    use_container_width=True,
                    hide_index=True,
                    column_config={
                        "Risque": st.column_config.TextColumn(
                            "Niveau de risque",
                            help="√âvaluation du risque juridique"
                        ),
                        "Confiance": st.column_config.ProgressColumn(
                            "Confiance",
                            help="Niveau de confiance de l'analyse",
                            format="%s",
                            min_value="0%",
                            max_value="100%"
                        )
                    }
                )
            
            with fusion_tabs[2]:
                st.markdown("**Analyse juridique approfondie**")
                
                legal_analysis = {
                    "Qualification juridique": "Contrat de prestation de services avec clauses abusives potentielles",
                    "Articles pertinents": ["Art. 1171 Code civil", "Art. L442-1 Code commerce"],
                    "Jurisprudence": ["Cass. Com. 2019-123", "CA Paris 2022-456"],
                    "Recommandations": [
                        "Limiter la clause de non-concurrence √† 2 ans et au territoire national",
                        "Plafonner les p√©nalit√©s √† 0.5% du montant du contrat par jour",
                        "Pr√©voir une clause de juridiction fran√ßaise"
                    ]
                }
                
                for key, value in legal_analysis.items():
                    st.markdown(f"**{key}:**")
                    if isinstance(value, list):
                        for item in value:
                            st.markdown(f"- {item}")
                    else:
                        st.markdown(f"> {value}")
            
            with fusion_tabs[3]:
                # Matrice des risques interactive
                risk_matrix = pd.DataFrame({
                    'Risque': ['Juridique', 'Financier', 'Op√©rationnel', 'R√©putationnel'],
                    'Impact': [4, 3, 2, 3],
                    'Probabilit√©': [3, 4, 2, 2],
                    'Score': [12, 12, 4, 6]
                })
                
                fig_risk = px.scatter(
                    risk_matrix,
                    x='Probabilit√©',
                    y='Impact',
                    size='Score',
                    color='Risque',
                    hover_data=['Score'],
                    title="Matrice des risques",
                    labels={'Probabilit√©': 'Probabilit√© (1-5)', 'Impact': 'Impact (1-5)'}
                )
                
                fig_risk.update_layout(height=400)
                st.plotly_chart(fig_risk, use_container_width=True)
                
                # Actions recommand√©es
                st.markdown("**üéØ Plan d'action recommand√©:**")
                actions = [
                    ("üî¥ Urgent", "Ren√©gocier la clause de non-concurrence", "Sous 48h"),
                    ("üü† Important", "R√©viser les p√©nalit√©s de retard", "Sous 1 semaine"),
                    ("üü° Moyen", "Clarifier les modalit√©s de paiement", "Sous 2 semaines"),
                    ("üü¢ Faible", "Ajouter clause de force majeure", "Avant signature")
                ]
                
                for priority, action, deadline in actions:
                    col1, col2, col3 = st.columns([1, 3, 1])
                    with col1:
                        st.markdown(priority)
                    with col2:
                        st.markdown(action)
                    with col3:
                        st.markdown(f"*{deadline}*")
        else:
            st.info("üëÜ Lancez le traitement pour voir les r√©sultats")
            
            # D√©mo des r√©sultats
            if st.button("üëÅÔ∏è Voir une d√©mo des r√©sultats"):
                st.session_state.module_state['results'] = True
                st.rerun()
    
    with tabs[5]:  # Onglet Analytics
        st.markdown("### üìà Analytics et insights")
        
        # KPIs principaux
        kpi_col1, kpi_col2, kpi_col3, kpi_col4 = st.columns(4)
        
        with kpi_col1:
            st.metric("Utilisation ce mois", "1,247 analyses", "+23%")
        with kpi_col2:
            st.metric("Temps moyen", "1m 45s", "-12%")
        with kpi_col3:
            st.metric("Taux de succ√®s", "98.4%", "+0.8%")
        with kpi_col4:
            st.metric("ROI estim√©", "3.2x", "+0.4x")
        
        # Graphiques d'utilisation
        col1, col2 = st.columns(2)
        
        with col1:
            # Utilisation par mod√®le
            usage_data = pd.DataFrame({
                'Mod√®le': ['GPT-4', 'Claude', 'Mistral', 'Gemini', 'Llama'],
                'Utilisation': [450, 380, 220, 150, 47]
            })
            
            fig_usage = px.pie(
                usage_data,
                values='Utilisation',
                names='Mod√®le',
                title="R√©partition d'utilisation des mod√®les"
            )
            st.plotly_chart(fig_usage, use_container_width=True)
        
        with col2:
            # Tendance temporelle
            dates = pd.date_range(start='2024-01-01', periods=30, freq='D')
            trend_data = pd.DataFrame({
                'Date': dates,
                'Analyses': [50 + i*2 + (i%7)*5 for i in range(30)]
            })
            
            fig_trend = px.line(
                trend_data,
                x='Date',
                y='Analyses',
                title="√âvolution du nombre d'analyses"
            )
            st.plotly_chart(fig_trend, use_container_width=True)
        
        # Insights automatiques
        st.markdown("#### üí° Insights automatiques")
        
        insights = [
            ("üìà", "Les analyses juridiques ont augment√© de 34% ce mois", "success"),
            ("üéØ", "Le mod√®le GPT-4 offre le meilleur ratio pr√©cision/co√ªt", "info"),
            ("‚ö†Ô∏è", "3 documents ont n√©cessit√© une r√©vision manuelle", "warning"),
            ("üí∞", "√âconomie r√©alis√©e: 2,450‚Ç¨ vs traitement manuel", "success")
        ]
        
        for icon, insight, status in insights:
            st.markdown(
                f'<div class="status-badge status-{status}">{icon} {insight}</div>',
                unsafe_allow_html=True
            )
    
    with tabs[6]:  # Onglet Export am√©lior√©
        st.markdown("### üíæ Centre d'export et de sauvegarde")
        
        export_format = st.selectbox(
            "Format d'export",
            [
                ("pdf", "üìÑ PDF - Document professionnel"),
                ("word", "üìù Word - √âditable"),
                ("excel", "üìä Excel - Donn√©es structur√©es"),
                ("json", "üîß JSON - Int√©gration API"),
                ("bundle", "üì¶ Bundle complet - Tout inclus")
            ],
            format_func=lambda x: x[1]
        )
        
        # Options d'export
        with st.expander("‚öôÔ∏è Options d'export", expanded=True):
            col1, col2 = st.columns(2)
            
            with col1:
                include_metadata = st.checkbox("üìã Inclure les m√©tadonn√©es", value=True)
                include_graphics = st.checkbox("üìä Inclure les graphiques", value=True)
                include_raw_data = st.checkbox("üíæ Inclure les donn√©es brutes", value=False)
            
            with col2:
                compression = st.checkbox("üóúÔ∏è Compression", value=True)
                password_protect = st.checkbox("üîí Protection par mot de passe", value=False)
                digital_signature = st.checkbox("‚úçÔ∏è Signature num√©rique", value=False)
        
        # Templates pr√©d√©finis
        st.markdown("#### üìã Templates pr√©d√©finis")
        
        template = st.radio(
            "S√©lectionner un template",
            [
                "üìÑ Rapport standard",
                "‚öñÔ∏è Note juridique",
                "üìä Analyse ex√©cutive",
                "üîç Rapport d√©taill√©",
                "üéØ Personnalis√©"
            ],
            horizontal=True
        )
        
        # Aper√ßu et g√©n√©ration
        col1, col2 = st.columns([2, 1])
        
        with col1:
            if st.button("üëÅÔ∏è Aper√ßu avant export", use_container_width=True):
                with st.expander("Aper√ßu du document", expanded=True):
                    st.markdown(
                        """
                        ### Rapport d'analyse juridique
                        
                        **Date:** 14 juin 2025  
                        **R√©f√©rence:** REP-2025-0614-001  
                        **Confidentialit√©:** Confidentiel
                        
                        #### R√©sum√© ex√©cutif
                        L'analyse multi-mod√®les a permis d'identifier...
                        
                        #### Conclusions principales
                        1. Point critique n¬∞1
                        2. Point critique n¬∞2
                        3. Point critique n¬∞3
                        
                        #### Recommandations
                        - Action imm√©diate requise sur...
                        - R√©vision n√©cessaire de...
                        """
                    )
        
        with col2:
            if st.button(
                "üì• G√©n√©rer l'export",
                type="primary",
                use_container_width=True,
                disabled=not st.session_state.module_state.get('results')
            ):
                with st.spinner("G√©n√©ration en cours..."):
                    time.sleep(2)
                    
                    # Simulation de t√©l√©chargement
                    st.download_button(
                        label="üíæ T√©l√©charger",
                        data=b"Contenu du fichier...",
                        file_name=f"rapport_analyse_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf",
                        mime="application/pdf",
                        use_container_width=True
                    )
        
        # Historique des exports
        with st.expander("üìú Historique des exports"):
            export_history = pd.DataFrame({
                'Date': ['2025-06-14 10:30', '2025-06-13 15:45', '2025-06-12 09:20'],
                'Format': ['PDF', 'Excel', 'Bundle'],
                'Taille': ['2.4 MB', '1.8 MB', '15.3 MB'],
                'Statut': ['‚úÖ Compl√©t√©', '‚úÖ Compl√©t√©', '‚úÖ Compl√©t√©']
            })
            
            st.dataframe(export_history, use_container_width=True, hide_index=True)

def run_processing():
    """Lance le traitement avec animation et feedback en temps r√©el"""
    
    # Initialisation
    st.session_state.module_state['processing'] = True
    progress_placeholder = st.empty()
    status_placeholder = st.empty()
    log_placeholder = st.empty()
    
    # Phases de traitement avec d√©tails
    phases = [
        ("üîç Initialisation", 10, ["V√©rification des param√®tres", "Chargement des mod√®les", "Allocation des ressources"]),
        ("üìÑ Pr√©paration des documents", 20, ["Extraction du texte", "Normalisation", "Segmentation"]),
        ("ü§ñ Analyse IA - GPT-4", 35, ["Envoi des requ√™tes", "Traitement", "R√©ception des r√©sultats"]),
        ("ü§ñ Analyse IA - Claude", 50, ["Envoi des requ√™tes", "Traitement", "R√©ception des r√©sultats"]),
        ("ü§ñ Analyse IA - Mistral", 65, ["Envoi des requ√™tes", "Traitement", "R√©ception des r√©sultats"]),
        ("üîÑ Fusion des r√©sultats", 80, ["Alignement", "Pond√©ration", "Consensus"]),
        ("üìä G√©n√©ration des rapports", 95, ["Formatage", "Graphiques", "Export"]),
        ("‚úÖ Finalisation", 100, ["Sauvegarde", "Nettoyage", "Notification"])
    ]
    
    # Animation du traitement
    for phase, progress, subtasks in phases:
        # Mise √† jour du statut principal
        status_placeholder.markdown(
            f"""
            <div style="text-align: center; padding: 20px;">
                <h3>{phase}</h3>
                <div class="loading-wave" style="font-size: 30px;">‚è≥</div>
            </div>
            """,
            unsafe_allow_html=True
        )
        
        # Barre de progression
        progress_placeholder.progress(progress / 100)
        
        # Log des sous-t√¢ches
        log_text = "```\n"
        for subtask in subtasks:
            log_text += f"[{datetime.now().strftime('%H:%M:%S')}] {subtask}...\n"
            log_placeholder.text(log_text + "```")
            time.sleep(0.3)
            log_text = log_text[:-4] + " ‚úÖ\n"
            log_placeholder.text(log_text + "```")
        
        time.sleep(0.5)
    
    # Finalisation
    st.session_state.module_state['processing'] = False
    st.session_state.module_state['results'] = True
    
    # Ajout √† l'historique
    if 'processing_history' not in st.session_state.module_state:
        st.session_state.module_state['processing_history'] = []
    
    st.session_state.module_state['processing_history'].append({
        'Date': datetime.now().strftime('%Y-%m-%d %H:%M'),
        'Documents': 42,
        'Dur√©e': '2m 34s',
        'Statut': 'Succ√®s'
    })
    
    # Message de succ√®s
    st.success("‚úÖ Traitement termin√© avec succ√®s!")
    st.balloons()
    
    # Redirection vers les r√©sultats
    time.sleep(1)
    st.rerun()

# Fonctions utilitaires avanc√©es
async def process_with_model(model_id: str, documents: List[Dict], config: Dict) -> Dict:
    """Traite les documents avec un mod√®le sp√©cifique"""
    model = AI_MODELS[model_id]
    results = {
        'model_id': model_id,
        'model_name': model['name'],
        'documents_processed': len(documents),
        'confidence_scores': [],
        'extracted_data': [],
        'processing_time': 0
    }
    
    # Simulation du traitement (√† remplacer par l'appel API r√©el)
    start_time = time.time()
    
    for doc in documents:
        # Traitement du document
        await asyncio.sleep(0.1)  # Simulation async
        
        results['extracted_data'].append({
            'document': doc['name'],
            'entities': ['Partie A', 'Partie B'],
            'dates': ['2024-01-15', '2024-12-31'],
            'amounts': [10000, 5000],
            'risks': ['Clause abusive', 'D√©lai court']
        })
        
        results['confidence_scores'].append(0.85 + (model['performance_score'] - 0.85))
    
    results['processing_time'] = time.time() - start_time
    return results

def fusion_results(model_results: List[Dict], fusion_mode: str, threshold: float) -> Dict:
    """Fusionne les r√©sultats de plusieurs mod√®les selon la strat√©gie choisie"""
    
    if fusion_mode == 'weighted':
        # Fusion pond√©r√©e selon la performance
        weights = [AI_MODELS[r['model_id']]['performance_score'] for r in model_results]
        total_weight = sum(weights)
        weights = [w/total_weight for w in weights]
        
        # Calcul des r√©sultats fusionn√©s
        fused_results = {
            'fusion_mode': 'weighted',
            'confidence': sum(r['confidence_scores'][0] * w for r, w in zip(model_results, weights)),
            'consensus_level': 'high',
            'combined_insights': []
        }
        
    elif fusion_mode == 'consensus':
        # Recherche du consensus
        fused_results = {
            'fusion_mode': 'consensus',
            'confidence': 0.9,
            'consensus_level': 'medium',
            'combined_insights': []
        }
        
    elif fusion_mode == 'voting':
        # Vote majoritaire
        fused_results = {
            'fusion_mode': 'voting',
            'confidence': 0.85,
            'consensus_level': 'high',
            'combined_insights': []
        }
    
    else:
        # Mode par d√©faut
        fused_results = model_results[0]
    
    return fused_results

def generate_visualization(data: Dict, viz_type: str) -> go.Figure:
    """G√©n√®re des visualisations interactives selon le type demand√©"""
    
    if viz_type == 'risk_matrix':
        fig = go.Figure()
        
        # Ajout des donn√©es
        fig.add_trace(go.Scatter(
            x=[1, 2, 3, 4, 5],
            y=[1, 2, 3, 4, 5],
            mode='markers+text',
            marker=dict(size=20, color='red'),
            text=['R1', 'R2', 'R3', 'R4', 'R5']
        ))
        
        fig.update_layout(
            title="Matrice des risques",
            xaxis_title="Probabilit√©",
            yaxis_title="Impact",
            height=400
        )
        
        return fig
    
    elif viz_type == 'timeline':
        # Timeline des √©v√©nements
        fig = go.Figure()
        
        # Donn√©es exemple
        dates = ['2024-01', '2024-02', '2024-03', '2024-04']
        events = ['Signature', 'Livraison', 'Paiement', 'Cl√¥ture']
        
        fig.add_trace(go.Scatter(
            x=dates,
            y=[1, 1, 1, 1],
            mode='markers+text',
            marker=dict(size=15),
            text=events,
            textposition="top center"
        ))
        
        fig.update_layout(
            title="Timeline des √©v√©nements",
            showlegend=False,
            height=300
        )
        
        return fig

def calculate_metrics(results: Dict) -> Dict:
    """Calcule les m√©triques de performance"""
    return {
        'accuracy': 0.94,
        'processing_speed': 2.5,
        'cost_efficiency': 0.85,
        'quality_score': 'A+'
    }

# Cache pour am√©liorer les performances
@st.cache_data(ttl=3600)
def get_cached_results(doc_hash: str) -> Optional[Dict]:
    """R√©cup√®re les r√©sultats mis en cache"""
    # Impl√©mentation du cache
    return None

def generate_cache_key(documents: List[Dict], config: Dict) -> str:
    """G√©n√®re une cl√© de cache unique"""
    content = json.dumps({'docs': [d['name'] for d in documents], 'config': config}, sort_keys=True)
    return hashlib.md5(content.encode()).hexdigest()

# Point d'entr√©e
if __name__ == "__main__":
    run()