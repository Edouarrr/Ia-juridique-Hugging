# modules/mapping.py
"""Module de cartographie des relations et entit√©s juridiques avec multi-IA"""

import json
import os
import re
import sys
import time
from collections import Counter, defaultdict
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, Tuple

import streamlit as st

# Ajouter le chemin parent pour importer utils
sys.path.append(str(Path(__file__).parent.parent))
from utils.text_processing import extract_entities
from utils import clean_key, format_legal_date, truncate_text

import networkx as nx
import plotly.graph_objects as go
import pandas as pd

from managers.multi_llm_manager import MultiLLMManager
from modules.dataclasses import Document, Entity, Relationship


def run():
    """Fonction principale du module - Point d'entr√©e pour le lazy loading"""
    
    # Initialisation du style personnalis√©
    apply_custom_styling()
    
    # Header avec animation
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        st.markdown("""
        <div class="module-header">
            <h1>üó∫Ô∏è Cartographie des Relations</h1>
            <p class="module-subtitle">Analyse intelligente des r√©seaux d'entit√©s et relations juridiques</p>
        </div>
        """, unsafe_allow_html=True)
    
    # Initialisation des variables de session
    initialize_session_state()
    
    # V√©rification des d√©pendances
    check_dependencies()
    
    # Interface principale en onglets
    tab_icons = ["üì§", "ü§ñ", "‚öôÔ∏è", "üöÄ", "üìä", "üíæ"]
    tab_names = ["Sources", "IA & Mod√®les", "Configuration", "Analyse", "R√©sultats", "Export"]
    tabs = st.tabs([f"{icon} {name}" for icon, name in zip(tab_icons, tab_names)])
    
    with tabs[0]:  # Sources
        render_sources_tab()
    
    with tabs[1]:  # IA & Mod√®les
        render_ai_models_tab()
    
    with tabs[2]:  # Configuration
        render_configuration_tab()
    
    with tabs[3]:  # Analyse
        render_analysis_tab()
    
    with tabs[4]:  # R√©sultats
        render_results_tab()
    
    with tabs[5]:  # Export
        render_export_tab()

def apply_custom_styling():
    """Applique le style CSS personnalis√© pour le module"""
    st.markdown("""
    <style>
    .module-header {
        text-align: center;
        padding: 2rem 0;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        border-radius: 15px;
        margin-bottom: 2rem;
        box-shadow: 0 10px 20px rgba(0,0,0,0.1);
        animation: fadeIn 0.5s ease-in;
    }
    
    .module-header h1 {
        color: white;
        font-size: 2.5rem;
        margin: 0;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.2);
    }
    
    .module-subtitle {
        color: rgba(255,255,255,0.9);
        font-size: 1.1rem;
        margin-top: 0.5rem;
    }
    
    @keyframes fadeIn {
        from { opacity: 0; transform: translateY(-20px); }
        to { opacity: 1; transform: translateY(0); }
    }
    
    .config-card {
        background: #f8f9fa;
        border-radius: 10px;
        padding: 1.5rem;
        margin: 1rem 0;
        border: 1px solid #e9ecef;
        transition: all 0.3s ease;
    }
    
    .config-card:hover {
        box-shadow: 0 5px 15px rgba(0,0,0,0.1);
        transform: translateY(-2px);
    }
    
    .ai-model-card {
        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
        border-radius: 10px;
        padding: 1rem;
        margin: 0.5rem 0;
        cursor: pointer;
        transition: all 0.3s ease;
    }
    
    .ai-model-card:hover {
        transform: scale(1.02);
        box-shadow: 0 5px 15px rgba(0,0,0,0.2);
    }
    
    .result-card {
        background: white;
        border-radius: 10px;
        padding: 1.5rem;
        margin: 1rem 0;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
    }
    
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-radius: 10px;
        padding: 1rem;
        text-align: center;
        transition: transform 0.3s ease;
    }
    
    .metric-card:hover {
        transform: scale(1.05);
    }
    
    .progress-step {
        background: #e9ecef;
        border-radius: 5px;
        padding: 0.5rem 1rem;
        margin: 0.2rem 0;
        transition: all 0.3s ease;
    }
    
    .progress-step.active {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        transform: translateX(10px);
    }
    
    .network-container {
        background: white;
        border-radius: 15px;
        padding: 2rem;
        box-shadow: 0 5px 20px rgba(0,0,0,0.1);
    }
    
    .entity-badge {
        display: inline-block;
        padding: 0.3rem 0.8rem;
        border-radius: 20px;
        font-size: 0.85rem;
        margin: 0.2rem;
        transition: all 0.2s ease;
    }
    
    .entity-badge:hover {
        transform: scale(1.1);
    }
    
    .entity-badge.person {
        background: #FF6B6B;
        color: white;
    }
    
    .entity-badge.company {
        background: #4ECDC4;
        color: white;
    }
    
    .entity-badge.organization {
        background: #45B7D1;
        color: white;
    }
    
    .relation-line {
        stroke: #999;
        stroke-width: 2;
        fill: none;
        transition: all 0.3s ease;
    }
    
    .relation-line:hover {
        stroke: #667eea;
        stroke-width: 4;
    }
    </style>
    """, unsafe_allow_html=True)

def initialize_session_state():
    """Initialise les variables de session pour le module"""
    if 'mapping_state' not in st.session_state:
        st.session_state.mapping_state = {
            'initialized': True,
            'selected_documents': [],
            'selected_models': [],
            'fusion_mode': 'consensus',
            'config': {
                'mapping_type': 'complete',
                'depth': 2,
                'min_strength': 0.3,
                'layout': 'spring',
                'show_labels': True,
                'show_weights': False,
                'color_by': 'type',
                'entity_types': ['personne', 'soci√©t√©'],
                'exclude_entities': '',
                'focus_entities': ''
            },
            'analysis_status': 'idle',
            'results': None,
            'ai_results': {},
            'fusion_result': None
        }

def check_dependencies():
    """V√©rifie et affiche l'√©tat des d√©pendances"""
    with st.expander("üì¶ √âtat des d√©pendances", expanded=False):
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.success("‚úÖ NetworkX install√©")

        with col2:
            st.success("‚úÖ Plotly install√©")

        with col3:
            st.success("‚úÖ Pandas install√©")

def render_sources_tab():
    """Rendu de l'onglet Sources"""
    st.markdown("### üì§ S√©lection des sources de donn√©es")
    
    # M√©thode de s√©lection
    source_method = st.radio(
        "M√©thode de s√©lection",
        ["üìÅ Documents Azure", "üì§ Upload de fichiers", "üîç Recherche intelligente", "üìö S√©lection multiple"],
        horizontal=True
    )
    
    selected_docs = []
    
    if source_method == "üìÅ Documents Azure":
        # S√©lection depuis Azure
        if 'azure_documents' in st.session_state and st.session_state.azure_documents:
            st.markdown("#### Documents disponibles")
            
            # Filtres
            col1, col2, col3 = st.columns(3)
            with col1:
                doc_type_filter = st.multiselect(
                    "Type de document",
                    ["Contrat", "Proc√©dure", "Correspondance", "Expertise"],
                    default=[]
                )
            with col2:
                date_filter = st.date_input(
                    "Date apr√®s le",
                    value=None
                )
            with col3:
                search_filter = st.text_input(
                    "Rechercher dans les titres",
                    placeholder="Mots-cl√©s..."
                )
            
            # Liste des documents avec s√©lection am√©lior√©e
            st.markdown("#### S√©lectionner les documents")
            
            # Boutons de s√©lection rapide
            col1, col2, col3 = st.columns(3)
            with col1:
                if st.button("‚úÖ Tout s√©lectionner", use_container_width=True):
                    st.session_state.mapping_state['selected_documents'] = list(st.session_state.azure_documents.keys())
            with col2:
                if st.button("‚ùå Tout d√©s√©lectionner", use_container_width=True):
                    st.session_state.mapping_state['selected_documents'] = []
            with col3:
                if st.button("üîÑ Inverser s√©lection", use_container_width=True):
                    current = st.session_state.mapping_state['selected_documents']
                    all_docs = list(st.session_state.azure_documents.keys())
                    st.session_state.mapping_state['selected_documents'] = [d for d in all_docs if d not in current]
            
            # Affichage des documents
            for doc_id, doc in st.session_state.azure_documents.items():
                # Appliquer les filtres
                if doc_type_filter and doc.metadata.get('type') not in doc_type_filter:
                    continue
                if search_filter and search_filter.lower() not in doc.title.lower():
                    continue
                
                # Carte de document
                with st.container():
                    col1, col2 = st.columns([1, 4])
                    
                    with col1:
                        is_selected = st.checkbox(
                            "S√©lectionner",
                            key=f"select_doc_{doc_id}",
                            value=doc_id in st.session_state.mapping_state.get('selected_documents', [])
                        )
                        
                        if is_selected and doc_id not in st.session_state.mapping_state['selected_documents']:
                            st.session_state.mapping_state['selected_documents'].append(doc_id)
                        elif not is_selected and doc_id in st.session_state.mapping_state['selected_documents']:
                            st.session_state.mapping_state['selected_documents'].remove(doc_id)
                    
                    with col2:
                        st.markdown(f"""
                        <div class="config-card">
                            <h4>üìÑ {doc.title}</h4>
                            <p><small>Source: {doc.source} | Taille: {len(doc.content)} caract√®res</small></p>
                            <p>{truncate_text(doc.content, 150)}</p>
                        </div>
                        """, unsafe_allow_html=True)
            
            # R√©sum√© de la s√©lection
            if st.session_state.mapping_state['selected_documents']:
                st.success(f"‚úÖ {len(st.session_state.mapping_state['selected_documents'])} documents s√©lectionn√©s")
            else:
                st.warning("‚ö†Ô∏è Aucun document s√©lectionn√©")
        else:
            st.info("‚ÑπÔ∏è Aucun document Azure disponible. Veuillez d'abord charger des documents.")
    
    elif source_method == "üì§ Upload de fichiers":
        uploaded_files = st.file_uploader(
            "Chargez vos fichiers",
            type=['pdf', 'txt', 'docx', 'rtf'],
            accept_multiple_files=True,
            help="Formats support√©s : PDF, TXT, DOCX, RTF"
        )
        
        if uploaded_files:
            st.success(f"‚úÖ {len(uploaded_files)} fichiers charg√©s")
            # Traiter les fichiers upload√©s
            for file in uploaded_files:
                with st.expander(f"üìÑ {file.name}"):
                    st.write(f"Type: {file.type}")
                    st.write(f"Taille: {file.size} octets")
    
    elif source_method == "üîç Recherche intelligente":
        st.markdown("#### Recherche avanc√©e dans la base documentaire")
        
        # Interface de recherche avanc√©e
        search_query = st.text_area(
            "Requ√™te de recherche",
            placeholder="Ex: Tous les contrats mentionnant 'soci√©t√© XYZ' ET 'acquisition' sign√©s apr√®s 2023",
            height=100
        )
        
        col1, col2 = st.columns(2)
        with col1:
            search_scope = st.multiselect(
                "Chercher dans",
                ["Titre", "Contenu", "M√©tadonn√©es", "Parties prenantes"],
                default=["Titre", "Contenu"]
            )
        
        with col2:
            search_operator = st.radio(
                "Op√©rateur",
                ["ET (tous les termes)", "OU (au moins un terme)", "Expression exacte"],
                horizontal=True
            )
        
        if st.button("üîç Lancer la recherche", type="primary", use_container_width=True):
            with st.spinner("Recherche en cours..."):
                time.sleep(1)  # Simulation
                st.info("üîç Recherche simul√©e - Fonctionnalit√© √† impl√©menter")

def render_ai_models_tab():
    """Rendu de l'onglet IA & Mod√®les"""
    st.markdown("### ü§ñ Configuration des mod√®les d'IA")
    
    # Gestion multi-LLM
    llm_manager = MultiLLMManager()
    available_providers = list(llm_manager.clients.keys()) if llm_manager.clients else []
    
    if not available_providers:
        st.error("‚ùå Aucun mod√®le d'IA configur√©. Veuillez configurer au moins un fournisseur.")
        return
    
    # Mode de traitement
    col1, col2 = st.columns([2, 1])
    
    with col1:
        analysis_mode = st.radio(
            "Mode d'analyse",
            ["üéØ Mod√®le unique", "üîÄ Multi-mod√®les parall√®le", "üß¨ Fusion intelligente"],
            horizontal=True,
            help="""
            - **Mod√®le unique** : Utilise un seul mod√®le pour l'analyse
            - **Multi-mod√®les parall√®le** : Interroge plusieurs mod√®les en parall√®le
            - **Fusion intelligente** : Combine les r√©sultats de plusieurs mod√®les
            """
        )
    
    with col2:
        if analysis_mode == "üß¨ Fusion intelligente":
            fusion_strategy = st.selectbox(
                "Strat√©gie de fusion",
                ["consensus", "weighted", "best_confidence", "union", "intersection"],
                format_func=lambda x: {
                    "consensus": "ü§ù Consensus majoritaire",
                    "weighted": "‚öñÔ∏è Moyenne pond√©r√©e",
                    "best_confidence": "üéØ Meilleure confiance",
                    "union": "‚ûï Union (tous)",
                    "intersection": "üîó Intersection (commun)"
                }.get(x, x)
            )
            st.session_state.mapping_state['fusion_mode'] = fusion_strategy
    
    # S√©lection des mod√®les
    st.markdown("#### S√©lection des mod√®les")
    
    if analysis_mode == "üéØ Mod√®le unique":
        selected_model = st.selectbox(
            "Choisir le mod√®le",
            available_providers,
            format_func=lambda x: f"ü§ñ {x.upper()}"
        )
        st.session_state.mapping_state['selected_models'] = [selected_model]
    else:
        # Multi-s√©lection avec interface am√©lior√©e
        st.markdown("S√©lectionnez les mod√®les √† utiliser :")
        
        # Grille de mod√®les
        cols = st.columns(min(3, len(available_providers)))
        selected_models = []
        
        for idx, provider in enumerate(available_providers):
            col_idx = idx % len(cols)
            with cols[col_idx]:
                # Carte de mod√®le stylis√©e
                is_selected = st.checkbox(
                    f"ü§ñ {provider.upper()}",
                    key=f"model_{provider}",
                    value=provider in st.session_state.mapping_state.get('selected_models', [])
                )
                
                if is_selected:
                    selected_models.append(provider)
                
                # Informations sur le mod√®le
                with st.expander(f"‚ÑπÔ∏è Info {provider}", expanded=False):
                    model_info = llm_manager.get_model_info(provider)
                    if model_info:
                        st.write(f"**Mod√®le :** {model_info.get('model', 'N/A')}")
                        st.write(f"**Temp√©rature :** {model_info.get('temperature', 0.3)}")
                        st.write(f"**Tokens max :** {model_info.get('max_tokens', 'N/A')}")
        
        st.session_state.mapping_state['selected_models'] = selected_models
        
        if selected_models:
            st.success(f"‚úÖ {len(selected_models)} mod√®les s√©lectionn√©s : {', '.join(selected_models)}")
        else:
            st.warning("‚ö†Ô∏è Veuillez s√©lectionner au moins un mod√®le")
    
    # Configuration avanc√©e des mod√®les
    with st.expander("‚öôÔ∏è Configuration avanc√©e des mod√®les", expanded=False):
        col1, col2, col3 = st.columns(3)
        
        with col1:
            temperature = st.slider(
                "Temp√©rature",
                0.0, 1.0, 0.3,
                help="Contr√¥le la cr√©ativit√© des r√©ponses"
            )
        
        with col2:
            max_tokens = st.number_input(
                "Tokens max",
                min_value=100,
                max_value=4000,
                value=1500,
                step=100
            )
        
        with col3:
            retry_attempts = st.number_input(
                "Tentatives en cas d'√©chec",
                min_value=1,
                max_value=5,
                value=3
            )
    
    # Prompt personnalis√©
    st.markdown("#### Personnalisation du prompt")
    
    use_custom_prompt = st.checkbox("Utiliser un prompt personnalis√©", value=False)
    
    if use_custom_prompt:
        custom_prompt = st.text_area(
            "Prompt personnalis√©",
            value="""Analyse ces documents pour identifier TOUTES les entit√©s et relations.
Focus sur : {mapping_type}
Profondeur d'analyse : {depth}

Instructions sp√©cifiques :
- Identifier toutes les personnes, soci√©t√©s et organisations
- Extraire toutes les relations avec leur type et force
- Fournir des preuves textuelles pour chaque relation
""",
            height=200,
            help="Utilisez {mapping_type} et {depth} comme variables"
        )

def render_configuration_tab():
    """Rendu de l'onglet Configuration"""
    st.markdown("### ‚öôÔ∏è Configuration de l'analyse")
    
    # Configuration principale dans des cartes
    st.markdown("#### üéØ Param√®tres principaux")
    
    col1, col2 = st.columns(2)
    
    with col1:
        with st.container():
            st.markdown('<div class="config-card">', unsafe_allow_html=True)
            
            # Type de cartographie avec descriptions
            mapping_type = st.selectbox(
                "üó∫Ô∏è Type de cartographie",
                ["complete", "personnes", "societes", "flux_financiers", "hierarchique"],
                format_func=lambda x: {
                    "complete": "üåê Cartographie compl√®te - Toutes les relations",
                    "personnes": "üë• Relations entre personnes - Liens familiaux et professionnels",
                    "societes": "üè¢ Structure soci√©taire - Participations et filiales",
                    "flux_financiers": "üí∞ Flux financiers - Virements et transactions",
                    "hierarchique": "üìä Relations hi√©rarchiques - Organigrammes"
                }.get(x, x.title()),
                key="mapping_type_config"
            )
            st.session_state.mapping_state['config']['mapping_type'] = mapping_type
            
            # Profondeur d'analyse avec visualisation
            depth = st.select_slider(
                "üîç Profondeur d'analyse",
                options=[1, 2, 3],
                value=st.session_state.mapping_state['config']['depth'],
                format_func=lambda x: {
                    1: "üî∏ Niveau 1 - Relations directes uniquement",
                    2: "üî∏üî∏ Niveau 2 - Relations directes + indirectes",
                    3: "üî∏üî∏üî∏ Niveau 3 - R√©seau complet"
                }.get(x),
                key="depth_config"
            )
            st.session_state.mapping_state['config']['depth'] = depth
            
            # Indicateur visuel de profondeur
            st.progress(depth / 3)
            
            st.markdown('</div>', unsafe_allow_html=True)
    
    with col2:
        with st.container():
            st.markdown('<div class="config-card">', unsafe_allow_html=True)
            
            # Force minimale des relations
            min_strength = st.slider(
                "üí™ Force minimale des relations",
                0.0, 1.0,
                st.session_state.mapping_state['config']['min_strength'],
                0.05,
                help="Filtrer les relations faibles",
                key="min_strength_config"
            )
            st.session_state.mapping_state['config']['min_strength'] = min_strength
            
            # Visualisation du seuil
            strength_levels = ["Tr√®s faible", "Faible", "Moyenne", "Forte", "Tr√®s forte"]
            strength_index = int(min_strength * 4)
            st.info(f"Seuil actuel : {strength_levels[strength_index]} ({min_strength:.0%})")
            
            # Layout du graphe
            layout = st.selectbox(
                "üìê Disposition du r√©seau",
                ["spring", "circular", "hierarchical", "kamada_kawai"],
                format_func=lambda x: {
                    "spring": "üå∏ Spring - Disposition organique naturelle",
                    "circular": "‚≠ï Circulaire - N≈ìuds en cercle",
                    "hierarchical": "üìä Hi√©rarchique - Niveaux verticaux",
                    "kamada_kawai": "üéØ Kamada-Kawai - Optimis√©"
                }.get(x, x.title()),
                key="layout_config"
            )
            st.session_state.mapping_state['config']['layout'] = layout
            
            st.markdown('</div>', unsafe_allow_html=True)
    
    # Options d'affichage
    st.markdown("#### üé® Options d'affichage")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        show_labels = st.checkbox(
            "üè∑Ô∏è Afficher les labels",
            value=st.session_state.mapping_state['config']['show_labels'],
            key="show_labels_config"
        )
        st.session_state.mapping_state['config']['show_labels'] = show_labels
        
        show_weights = st.checkbox(
            "üìä Afficher les poids",
            value=st.session_state.mapping_state['config']['show_weights'],
            key="show_weights_config"
        )
        st.session_state.mapping_state['config']['show_weights'] = show_weights
    
    with col2:
        color_by = st.radio(
            "üé® Coloration des n≈ìuds",
            ["type", "centrality", "community"],
            format_func=lambda x: {
                "type": "üìå Par type d'entit√©",
                "centrality": "üéØ Par centralit√©",
                "community": "üë• Par communaut√©"
            }.get(x, x.title()),
            key="color_by_config"
        )
        st.session_state.mapping_state['config']['color_by'] = color_by
    
    with col3:
        # Taille des n≈ìuds
        node_size_factor = st.slider(
            "üìè Taille des n≈ìuds",
            0.5, 2.0, 1.0, 0.1,
            help="Facteur de taille des n≈ìuds"
        )
    
    # Filtres avanc√©s
    with st.expander("üîç Filtres avanc√©s", expanded=False):
        col1, col2 = st.columns(2)
        
        with col1:
            # Types d'entit√©s
            entity_types = st.multiselect(
                "Types d'entit√©s √† inclure",
                ["personne", "soci√©t√©", "organisation", "lieu", "compte", "autre"],
                default=st.session_state.mapping_state['config']['entity_types'],
                key="entity_types_config"
            )
            st.session_state.mapping_state['config']['entity_types'] = entity_types
            
            # Focus sur certaines entit√©s
            focus_entities = st.text_input(
                "üéØ Focus sur ces entit√©s (s√©par√©es par des virgules)",
                value=st.session_state.mapping_state['config']['focus_entities'],
                placeholder="Ex: Jean Dupont, Soci√©t√© XYZ",
                key="focus_entities_config"
            )
            st.session_state.mapping_state['config']['focus_entities'] = focus_entities
        
        with col2:
            # Entit√©s √† exclure
            exclude_entities = st.text_area(
                "‚ùå Entit√©s √† exclure (une par ligne)",
                value=st.session_state.mapping_state['config']['exclude_entities'],
                placeholder="Ex:\nFrance\nParis\nEurope",
                height=100,
                key="exclude_entities_config"
            )
            st.session_state.mapping_state['config']['exclude_entities'] = exclude_entities
            
            # Relations √† filtrer
            relation_types = st.multiselect(
                "Types de relations",
                ["hierarchical", "contractual", "financial", "familial", "business", "ownership"],
                help="Laisser vide pour toutes les relations"
            )
    
    # Aper√ßu de la configuration
    st.markdown("#### üëÅÔ∏è Aper√ßu de la configuration")
    
    config_summary = f"""
    <div class="result-card">
        <h4>Configuration actuelle :</h4>
        <ul>
            <li><strong>Type :</strong> {mapping_type.replace('_', ' ').title()}</li>
            <li><strong>Profondeur :</strong> Niveau {depth}</li>
            <li><strong>Seuil de force :</strong> {min_strength:.0%}</li>
            <li><strong>Layout :</strong> {layout.title()}</li>
            <li><strong>Types d'entit√©s :</strong> {', '.join(entity_types)}</li>
            <li><strong>Mod√®les IA :</strong> {len(st.session_state.mapping_state['selected_models'])} s√©lectionn√©s</li>
        </ul>
    </div>
    """
    st.markdown(config_summary, unsafe_allow_html=True)

def render_analysis_tab():
    """Rendu de l'onglet Analyse"""
    st.markdown("### üöÄ Lancement de l'analyse")
    
    # V√©rifications pr√©-analyse
    ready_to_analyze = True
    checks = []
    
    # V√©rifier les documents
    if not st.session_state.mapping_state['selected_documents']:
        checks.append("‚ùå Aucun document s√©lectionn√©")
        ready_to_analyze = False
    else:
        checks.append(f"‚úÖ {len(st.session_state.mapping_state['selected_documents'])} documents s√©lectionn√©s")
    
    # V√©rifier les mod√®les
    if not st.session_state.mapping_state['selected_models']:
        checks.append("‚ùå Aucun mod√®le IA s√©lectionn√©")
        ready_to_analyze = False
    else:
        checks.append(f"‚úÖ {len(st.session_state.mapping_state['selected_models'])} mod√®les s√©lectionn√©s")
    
    # V√©rifier la configuration
    if st.session_state.mapping_state['config']:
        checks.append("‚úÖ Configuration d√©finie")
    else:
        checks.append("‚ùå Configuration manquante")
        ready_to_analyze = False
    
    # Afficher les v√©rifications
    for check in checks:
        st.write(check)
    
    # Estimation du temps
    if ready_to_analyze:
        doc_count = len(st.session_state.mapping_state['selected_documents'])
        model_count = len(st.session_state.mapping_state['selected_models'])
        depth = st.session_state.mapping_state['config']['depth']
        
        # Estimation basique
        base_time = 5  # secondes par document
        model_factor = 1 if model_count == 1 else 0.7 * model_count  # Parall√©lisation
        depth_factor = depth * 0.5
        
        estimated_time = int(doc_count * base_time * model_factor * depth_factor)
        
        st.info(f"‚è±Ô∏è Temps estim√© : {estimated_time // 60} min {estimated_time % 60} sec")
    
    # Bouton de lancement
    col1, col2, col3 = st.columns([1, 2, 1])
    
    with col2:
        if st.button(
            "üöÄ Lancer l'analyse",
            type="primary",
            use_container_width=True,
            disabled=not ready_to_analyze
        ):
            st.session_state.mapping_state['analysis_status'] = 'running'
            run_mapping_analysis()
    
    # Affichage du statut d'analyse
    if st.session_state.mapping_state['analysis_status'] == 'running':
        display_analysis_progress()
    elif st.session_state.mapping_state['analysis_status'] == 'completed':
        st.success("‚úÖ Analyse termin√©e avec succ√®s !")
        st.balloons()
    elif st.session_state.mapping_state['analysis_status'] == 'failed':
        st.error("‚ùå L'analyse a √©chou√©. Veuillez r√©essayer.")

def run_mapping_analysis():
    """Lance l'analyse de cartographie"""
    progress_container = st.container()
    
    with progress_container:
        progress_bar = st.progress(0)
        status_text = st.empty()
        details_text = st.empty()
        
        # Phases d'analyse
        phases = [
            ("Initialisation", 5),
            ("Chargement des documents", 10),
            ("Extraction des entit√©s", 25),
            ("Analyse des relations", 40),
            ("Enrichissement IA", 70),
            ("Fusion des r√©sultats", 85),
            ("G√©n√©ration de la visualisation", 95),
            ("Finalisation", 100)
        ]
        
        try:
            # Collecter les documents
            documents = []
            for doc_id in st.session_state.mapping_state['selected_documents']:
                if doc_id in st.session_state.azure_documents:
                    doc = st.session_state.azure_documents[doc_id]
                    documents.append({
                        'id': doc_id,
                        'title': doc.title,
                        'content': doc.content,
                        'source': doc.source,
                        'metadata': doc.metadata
                    })
            
            # Simulation de l'analyse avec progression
            for phase, progress_value in phases:
                status_text.text(f"‚è≥ {phase}...")
                details_text.text(f"Traitement en cours... {progress_value}%")
                progress_bar.progress(progress_value / 100)
                
                if phase == "Extraction des entit√©s":
                    # Extraction r√©elle des entit√©s
                    entities, relationships = extract_entities_and_relationships(
                        documents, 
                        st.session_state.mapping_state['config']
                    )
                    details_text.text(f"‚úÖ {len(entities)} entit√©s trouv√©es")
                
                elif phase == "Analyse des relations":
                    # Analyse des relations
                    details_text.text(f"‚úÖ {len(relationships)} relations identifi√©es")
                
                elif phase == "Enrichissement IA":
                    # Enrichissement avec les mod√®les s√©lectionn√©s
                    if len(st.session_state.mapping_state['selected_models']) > 0:
                        ai_results = process_with_multiple_models(
                            documents, entities, relationships,
                            st.session_state.mapping_state['selected_models'],
                            st.session_state.mapping_state['config']
                        )
                        st.session_state.mapping_state['ai_results'] = ai_results
                
                elif phase == "Fusion des r√©sultats":
                    # Fusion si multi-mod√®les
                    if len(st.session_state.mapping_state['selected_models']) > 1:
                        fusion_result = fuse_ai_results(
                            st.session_state.mapping_state['ai_results'],
                            st.session_state.mapping_state['fusion_mode']
                        )
                        st.session_state.mapping_state['fusion_result'] = fusion_result
                
                time.sleep(0.5)  # Simulation du temps de traitement
            
            # G√©n√©rer le r√©sultat final
            mapping_result = generate_final_mapping_result(
                documents, entities, relationships,
                st.session_state.mapping_state['config'],
                st.session_state.mapping_state.get('fusion_result')
            )
            
            st.session_state.mapping_state['results'] = mapping_result
            st.session_state.mapping_state['analysis_status'] = 'completed'
            
            status_text.text("‚úÖ Analyse termin√©e !")
            details_text.text("")
            
        except Exception as e:
            st.session_state.mapping_state['analysis_status'] = 'failed'
            status_text.text("‚ùå Erreur lors de l'analyse")
            details_text.text(str(e))
            st.error(f"Erreur : {str(e)}")

def display_analysis_progress():
    """Affiche la progression de l'analyse en temps r√©el"""
    # Cette fonction serait appel√©e pendant l'analyse pour afficher la progression
    st.info("üîÑ Analyse en cours...")

def process_with_multiple_models(documents, entities, relationships, selected_models, config):
    """Traite l'analyse avec plusieurs mod√®les IA"""
    llm_manager = MultiLLMManager()
    results = {}
    
    for model in selected_models:
        if model in llm_manager.clients:
            # Enrichir avec ce mod√®le sp√©cifique
            model_entities, model_relationships = enrich_with_specific_model(
                documents, entities, relationships, config, model, llm_manager
            )
            
            results[model] = {
                'entities': model_entities,
                'relationships': model_relationships,
                'confidence': 0.8  # Simul√©
            }
    
    return results

def enrich_with_specific_model(documents, entities, relationships, config, model, llm_manager):
    """Enrichit l'analyse avec un mod√®le sp√©cifique"""
    # Construction du prompt
    prompt = f"""Analyse ces documents pour identifier TOUTES les entit√©s et relations de type {config['mapping_type']}.

DOCUMENTS:
"""
    
    for doc in documents[:3]:  # Limiter pour la d√©mo
        prompt += f"\n--- {doc['title']} ---\n{doc['content'][:1000]}...\n"
    
    prompt += f"""
Identifie:
1. ENTIT√âS (personnes, soci√©t√©s, organisations)
   - Nom complet
   - Type
   - R√¥le/fonction
   - Attributs importants

2. RELATIONS
   - Entit√© source -> Entit√© cible
   - Type de relation
   - Description
   - Force (0-1)

Focus sur les relations de type : {config['mapping_type']}
Profondeur : {config['depth']}
"""
    
    # Interroger le mod√®le
    response = llm_manager.query_single_llm(
        model,
        prompt,
        "Tu es un expert en analyse de r√©seaux et relations dans les documents juridiques.",
        temperature=0.3
    )
    
    if response['success']:
        # Parser la r√©ponse
        new_entities, new_relationships = parse_ai_mapping_response(response['response'])
        
        # Fusionner avec l'existant
        all_entities = merge_entities(entities, new_entities)
        all_relationships = relationships + new_relationships
        
        return all_entities, consolidate_relationships(all_relationships)
    
    return entities, relationships

def fuse_ai_results(ai_results, fusion_mode):
    """Fusionne les r√©sultats de plusieurs mod√®les IA"""
    if not ai_results:
        return None
    
    if fusion_mode == "consensus":
        # Fusion par consensus majoritaire
        return fuse_by_consensus(ai_results)
    elif fusion_mode == "weighted":
        # Fusion pond√©r√©e par confiance
        return fuse_by_weighted_average(ai_results)
    elif fusion_mode == "best_confidence":
        # Prendre le mod√®le avec la meilleure confiance
        return fuse_by_best_confidence(ai_results)
    elif fusion_mode == "union":
        # Union de tous les r√©sultats
        return fuse_by_union(ai_results)
    elif fusion_mode == "intersection":
        # Intersection des r√©sultats
        return fuse_by_intersection(ai_results)
    
    return None

def fuse_by_consensus(ai_results):
    """Fusion par consensus majoritaire"""
    # Compter les occurrences de chaque entit√© et relation
    entity_votes = defaultdict(int)
    relation_votes = defaultdict(int)
    
    for model, result in ai_results.items():
        for entity in result['entities']:
            entity_votes[entity.name] += 1
        
        for rel in result['relationships']:
            rel_key = (rel.source, rel.target, rel.type)
            relation_votes[rel_key] += 1
    
    # Seuil de consensus (majorit√©)
    threshold = len(ai_results) / 2
    
    # Entit√©s consensuelles
    consensus_entities = []
    for entity_name, votes in entity_votes.items():
        if votes >= threshold:
            # R√©cup√©rer l'entit√© depuis n'importe quel mod√®le
            for result in ai_results.values():
                for entity in result['entities']:
                    if entity.name == entity_name:
                        consensus_entities.append(entity)
                        break
                else:
                    continue
                break
    
    # Relations consensuelles
    consensus_relationships = []
    for rel_key, votes in relation_votes.items():
        if votes >= threshold:
            source, target, rel_type = rel_key
            # Cr√©er la relation
            consensus_relationships.append(Relationship(
                source=source,
                target=target,
                type=rel_type,
                strength=votes / len(ai_results)
            ))
    
    return {
        'entities': consensus_entities,
        'relationships': consensus_relationships,
        'fusion_method': 'consensus',
        'model_count': len(ai_results)
    }

def fuse_by_weighted_average(ai_results):
    """Fusion pond√©r√©e par la confiance des mod√®les"""
    # Impl√©menter la fusion pond√©r√©e
    # Pour la d√©mo, on retourne le premier r√©sultat
    return list(ai_results.values())[0] if ai_results else None

def fuse_by_best_confidence(ai_results):
    """S√©lectionne le r√©sultat du mod√®le avec la meilleure confiance"""
    best_model = max(ai_results.items(), key=lambda x: x[1].get('confidence', 0))
    return best_model[1]

def fuse_by_union(ai_results):
    """Union de tous les r√©sultats"""
    all_entities = []
    all_relationships = []
    
    for result in ai_results.values():
        all_entities.extend(result['entities'])
        all_relationships.extend(result['relationships'])
    
    # D√©dupliquer
    unique_entities = list({e.name: e for e in all_entities}.values())
    unique_relationships = consolidate_relationships(all_relationships)
    
    return {
        'entities': unique_entities,
        'relationships': unique_relationships,
        'fusion_method': 'union'
    }

def fuse_by_intersection(ai_results):
    """Intersection des r√©sultats"""
    # Pour l'intersection, on ne garde que ce qui est pr√©sent dans tous les mod√®les
    if not ai_results:
        return None
    
    # Initialiser avec le premier r√©sultat
    first_result = list(ai_results.values())[0]
    common_entities = set(e.name for e in first_result['entities'])
    common_relations = set((r.source, r.target, r.type) for r in first_result['relationships'])
    
    # Intersection avec les autres
    for result in list(ai_results.values())[1:]:
        entity_names = set(e.name for e in result['entities'])
        relation_keys = set((r.source, r.target, r.type) for r in result['relationships'])
        
        common_entities &= entity_names
        common_relations &= relation_keys
    
    # Reconstruire les objets
    final_entities = []
    final_relationships = []
    
    for result in ai_results.values():
        for entity in result['entities']:
            if entity.name in common_entities and entity.name not in [e.name for e in final_entities]:
                final_entities.append(entity)
        
        for rel in result['relationships']:
            rel_key = (rel.source, rel.target, rel.type)
            if rel_key in common_relations and rel_key not in [(r.source, r.target, r.type) for r in final_relationships]:
                final_relationships.append(rel)
    
    return {
        'entities': final_entities,
        'relationships': final_relationships,
        'fusion_method': 'intersection'
    }

def generate_final_mapping_result(documents, entities, relationships, config, fusion_result=None):
    """G√©n√®re le r√©sultat final de la cartographie"""
    # Utiliser le r√©sultat de fusion si disponible
    if fusion_result:
        entities = fusion_result.get('entities', entities)
        relationships = fusion_result.get('relationships', relationships)
    
    # Filtrer selon la configuration
    filtered_entities, filtered_relationships = filter_mapping_data(entities, relationships, config)
    
    # Analyser le r√©seau
    network_analysis = analyze_network(filtered_entities, filtered_relationships)
    
    # Cr√©er la visualisation
    visualization = create_network_visualization(filtered_entities, filtered_relationships, config, network_analysis)
    
    return {
        'type': config['mapping_type'],
        'entities': filtered_entities,
        'relationships': filtered_relationships,
        'analysis': network_analysis,
        'visualization': visualization,
        'document_count': len(documents),
        'config': config,
        'timestamp': datetime.now(),
        'fusion_info': fusion_result if fusion_result else None
    }

def render_results_tab():
    """Rendu de l'onglet R√©sultats"""
    if not st.session_state.mapping_state.get('results'):
        st.info("üëÜ Lancez d'abord l'analyse pour voir les r√©sultats")
        return
    
    results = st.session_state.mapping_state['results']
    
    st.markdown("### üìä R√©sultats de la cartographie")
    
    # M√©triques principales avec style
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown(f"""
        <div class="metric-card">
            <h2>{results['analysis']['node_count']}</h2>
            <p>Entit√©s</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
        <div class="metric-card">
            <h2>{results['analysis']['edge_count']}</h2>
            <p>Relations</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        density_pct = results['analysis']['density'] * 100
        st.markdown(f"""
        <div class="metric-card">
            <h2>{density_pct:.1f}%</h2>
            <p>Densit√©</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        components = len(results['analysis'].get('components', []))
        st.markdown(f"""
        <div class="metric-card">
            <h2>{components}</h2>
            <p>Composantes</p>
        </div>
        """, unsafe_allow_html=True)
    
    # Information sur la fusion si applicable
    if results.get('fusion_info'):
        fusion_info = results['fusion_info']
        st.info(f"üß¨ R√©sultats fusionn√©s de {fusion_info.get('model_count', 0)} mod√®les - M√©thode : {fusion_info.get('fusion_method', 'N/A')}")
    
    # Visualisation principale
    st.markdown("#### üó∫Ô∏è Visualisation du r√©seau")
    
    if results.get('visualization'):
        with st.container():
            st.markdown('<div class="network-container">', unsafe_allow_html=True)
            st.plotly_chart(results['visualization'], use_container_width=True)
            st.markdown('</div>', unsafe_allow_html=True)
    else:
        st.warning("‚ö†Ô∏è Visualisation non disponible - Installez plotly pour les graphiques")
    
    # Onglets d√©taill√©s
    detail_tabs = st.tabs(["üéØ Acteurs cl√©s", "üë• Entit√©s", "üîó Relations", "üìä Analyse", "üåê Communaut√©s"])
    
    with detail_tabs[0]:  # Acteurs cl√©s
        display_key_players(results['analysis'])
    
    with detail_tabs[1]:  # Entit√©s
        display_entities_detailed(results['entities'], results['analysis'])
    
    with detail_tabs[2]:  # Relations
        display_relationships_detailed(results['relationships'])
    
    with detail_tabs[3]:  # Analyse
        display_network_metrics(results['analysis'])
    
    with detail_tabs[4]:  # Communaut√©s
        display_communities(results['analysis'])

def display_key_players(analysis):
    """Affiche les acteurs cl√©s du r√©seau"""
    st.markdown("#### üéØ Acteurs principaux du r√©seau")
    
    if 'key_players' in analysis and analysis['key_players']:
        for i, player in enumerate(analysis['key_players'][:10], 1):
            centrality = analysis.get('degree_centrality', {}).get(player, 0)
            betweenness = analysis.get('betweenness_centrality', {}).get(player, 0)
            
            col1, col2, col3, col4 = st.columns([3, 2, 2, 1])
            
            with col1:
                st.markdown(f"**{i}. {player}**")
            
            with col2:
                st.progress(centrality)
                st.caption(f"Centralit√©: {centrality:.3f}")
            
            with col3:
                st.progress(betweenness)
                st.caption(f"Interm√©diarit√©: {betweenness:.3f}")
            
            with col4:
                if centrality > 0.5:
                    st.markdown("üî¥ **Crucial**")
                elif centrality > 0.3:
                    st.markdown("üü° **Important**")
                else:
                    st.markdown("üü¢ **Normal**")
    else:
        st.info("Aucun acteur cl√© identifi√©")

def display_entities_detailed(entities, analysis):
    """Affiche le d√©tail des entit√©s"""
    st.markdown("#### üë• Liste d√©taill√©e des entit√©s")
    
    # Filtres
    col1, col2, col3 = st.columns(3)
    
    with col1:
        entity_type_filter = st.multiselect(
            "Filtrer par type",
            list(set(e.type for e in entities)),
            default=[]
        )
    
    with col2:
        sort_by = st.selectbox(
            "Trier par",
            ["Nom", "Type", "Mentions", "Centralit√©"]
        )
    
    with col3:
        search_entity = st.text_input(
            "Rechercher",
            placeholder="Nom de l'entit√©..."
        )
    
    # Filtrer et trier
    filtered_entities = entities
    
    if entity_type_filter:
        filtered_entities = [e for e in filtered_entities if e.type in entity_type_filter]
    
    if search_entity:
        filtered_entities = [e for e in filtered_entities if search_entity.lower() in e.name.lower()]
    
    # Trier
    if sort_by == "Nom":
        filtered_entities = sorted(filtered_entities, key=lambda e: e.name)
    elif sort_by == "Type":
        filtered_entities = sorted(filtered_entities, key=lambda e: (e.type, e.name))
    elif sort_by == "Mentions":
        filtered_entities = sorted(filtered_entities, key=lambda e: e.mentions_count, reverse=True)
    else:  # Centralit√©
        centrality = analysis.get('degree_centrality', {})
        filtered_entities = sorted(filtered_entities, key=lambda e: centrality.get(e.name, 0), reverse=True)
    
    # Affichage en grille
    for i in range(0, len(filtered_entities), 3):
        cols = st.columns(3)
        for j, col in enumerate(cols):
            if i + j < len(filtered_entities):
                entity = filtered_entities[i + j]
                with col:
                    # Badge de type
                    type_class = entity.type.lower().replace(' ', '-')
                    st.markdown(f'<span class="entity-badge {type_class}">{entity.type.upper()}</span>', unsafe_allow_html=True)
                    
                    st.markdown(f"**{entity.name}**")
                    
                    if 'degree_centrality' in analysis:
                        centrality = analysis['degree_centrality'].get(entity.name, 0)
                        st.progress(centrality)
                        st.caption(f"Centralit√©: {centrality:.3f}")
                    
                    st.caption(f"Mentions: {entity.mentions_count}")
                    
                    if entity.attributes:
                        with st.expander("Plus d'infos"):
                            for key, value in entity.attributes.items():
                                st.write(f"**{key}:** {value}")

def display_relationships_detailed(relationships):
    """Affiche le d√©tail des relations"""
    st.markdown("#### üîó Analyse des relations")
    
    # Statistiques par type
    rel_types = Counter(r.type for r in relationships)

    # Graphique des types de relations
    if rel_types:
        fig = go.Figure(data=[
            go.Bar(
                x=list(rel_types.keys()),
                y=list(rel_types.values()),
                marker_color='rgb(102, 126, 234)'
            )
        ])
        fig.update_layout(
            title="Distribution des types de relations",
            xaxis_title="Type de relation",
            yaxis_title="Nombre",
            showlegend=False
        )
        st.plotly_chart(fig, use_container_width=True)
    
    # Top relations par force
    st.markdown("##### üí™ Relations les plus fortes")
    
    top_relations = sorted(relationships, key=lambda r: r.strength, reverse=True)[:10]
    
    for rel in top_relations:
        strength_bar = "üü©" * int(rel.strength * 5) + "‚¨ú" * (5 - int(rel.strength * 5))
        
        col1, col2, col3 = st.columns([3, 2, 1])
        
        with col1:
            st.write(f"**{rel.source}** ‚Üí **{rel.target}**")
        
        with col2:
            st.write(f"{strength_bar} ({rel.strength:.2f})")
        
        with col3:
            st.caption(rel.type.replace('_', ' ').title())

def display_network_metrics(analysis):
    """Affiche les m√©triques d√©taill√©es du r√©seau"""
    st.markdown("#### üìä M√©triques du r√©seau")
    
    # M√©triques en colonnes
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("##### üåê M√©triques globales")
        
        metrics = {
            "N≈ìuds": analysis.get('node_count', 0),
            "Ar√™tes": analysis.get('edge_count', 0),
            "Densit√©": f"{analysis.get('density', 0):.3f}",
            "Connect√©": "‚úÖ Oui" if analysis.get('is_connected') else "‚ùå Non"
        }
        
        if 'average_shortest_path' in analysis:
            metrics["Chemin moyen"] = f"{analysis['average_shortest_path']:.2f}"
        
        if 'diameter' in analysis:
            metrics["Diam√®tre"] = analysis['diameter']
        
        for metric, value in metrics.items():
            st.metric(metric, value)
    
    with col2:
        st.markdown("##### üìà Distribution des degr√©s")
        
        if 'degree_centrality' in analysis:
            degrees = list(analysis['degree_centrality'].values())
            
            fig = go.Figure(data=[go.Histogram(
                x=degrees,
                nbinsx=20,
                marker_color='rgb(102, 126, 234)'
            )])
            fig.update_layout(
                xaxis_title="Centralit√© de degr√©",
                yaxis_title="Nombre de n≈ìuds",
                showlegend=False
            )
            st.plotly_chart(fig, use_container_width=True)

def display_communities(analysis):
    """Affiche les communaut√©s d√©tect√©es"""
    st.markdown("#### üåê Communaut√©s d√©tect√©es")
    
    if 'communities' in analysis and analysis['communities']:
        st.write(f"**Nombre de communaut√©s :** {len(analysis['communities'])}")
        
        if 'modularity' in analysis:
            st.metric("Modularit√©", f"{analysis['modularity']:.3f}")
        
        # Afficher chaque communaut√©
        for i, community in enumerate(analysis['communities'], 1):
            with st.expander(f"Communaut√© {i} - {len(community)} membres"):
                # Afficher les membres en badges
                for member in sorted(community):
                    st.markdown(f'<span class="entity-badge">{member}</span>', unsafe_allow_html=True)
    else:
        st.info("Aucune communaut√© d√©tect√©e. Activez NetworkX pour cette fonctionnalit√©.")

def render_export_tab():
    """Rendu de l'onglet Export"""
    if not st.session_state.mapping_state.get('results'):
        st.info("üëÜ Lancez d'abord l'analyse pour exporter les r√©sultats")
        return
    
    st.markdown("### üíæ Export des r√©sultats")
    
    results = st.session_state.mapping_state['results']
    
    # Options d'export
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### üìÑ Formats de document")
        
        # Rapport textuel
        if st.button("üìù G√©n√©rer rapport texte", use_container_width=True):
            report = generate_mapping_report(results)
            st.download_button(
                "üíæ T√©l√©charger rapport TXT",
                report.encode('utf-8'),
                f"rapport_cartographie_{results['type']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                "text/plain",
                use_container_width=True
            )
        
        # Rapport PDF (simul√©)
        if st.button("üìë G√©n√©rer rapport PDF", use_container_width=True):
            st.info("üöß Export PDF en cours de d√©veloppement")
        
        # Rapport Word (simul√©)
        if st.button("üìò G√©n√©rer rapport Word", use_container_width=True):
            st.info("üöß Export Word en cours de d√©veloppement")
    
    with col2:
        st.markdown("#### üìä Formats de donn√©es")
        
        # Export Excel
        if st.button("üìä G√©n√©rer fichier Excel", use_container_width=True):
            excel_data = export_mapping_to_excel(results)
            st.download_button(
                "üíæ T√©l√©charger Excel",
                excel_data,
                f"cartographie_{results['type']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True,
            )
        
        # Export JSON
        if st.button("üóÇÔ∏è Exporter en JSON", use_container_width=True):
            json_data = export_to_json(results)
            st.download_button(
                "üíæ T√©l√©charger JSON",
                json_data,
                f"cartographie_{results['type']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                "application/json",
                use_container_width=True
            )
        
        # Export GraphML (pour NetworkX)
        if st.button("üîó Exporter GraphML", use_container_width=True):
            graphml_data = export_to_graphml(results)
            if graphml_data:
                st.download_button(
                    "üíæ T√©l√©charger GraphML",
                    graphml_data,
                    f"reseau_{results['type']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.graphml",
                    "application/xml",
                    use_container_width=True,
                )
    
    # Export de la visualisation
    st.markdown("#### üñºÔ∏è Export de la visualisation")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if results.get('visualization'):
            if st.button("üñºÔ∏è Exporter en PNG", use_container_width=True):
                # Exporter la figure Plotly en PNG
                img_bytes = results['visualization'].to_image(format="png", width=1200, height=800)
                st.download_button(
                    "üíæ T√©l√©charger PNG",
                    img_bytes,
                    f"cartographie_{results['type']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png",
                    "image/png",
                    use_container_width=True
                )
    
    with col2:
        if results.get('visualization'):
            if st.button("üé® Exporter en SVG", use_container_width=True):
                # Exporter en SVG
                svg_str = results['visualization'].to_image(format="svg").decode()
                st.download_button(
                    "üíæ T√©l√©charger SVG",
                    svg_str,
                    f"cartographie_{results['type']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.svg",
                    "image/svg+xml",
                    use_container_width=True
                )
    
    with col3:
        if results.get('visualization'):
            if st.button("üìÑ Exporter HTML interactif", use_container_width=True):
                # Exporter en HTML interactif
                html_str = results['visualization'].to_html(include_plotlyjs='cdn')
                st.download_button(
                    "üíæ T√©l√©charger HTML",
                    html_str,
                    f"cartographie_{results['type']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html",
                    "text/html",
                    use_container_width=True
                )

def export_to_json(results):
    """Exporte les r√©sultats en JSON"""
    export_data = {
        'metadata': {
            'type': results['type'],
            'timestamp': results['timestamp'].isoformat(),
            'document_count': results['document_count'],
            'config': results['config']
        },
        'entities': [
            {
                'name': e.name,
                'type': e.type,
                'mentions_count': e.mentions_count,
                'attributes': e.attributes
            } for e in results['entities']
        ],
        'relationships': [
            {
                'source': r.source,
                'target': r.target,
                'type': r.type,
                'strength': r.strength,
                'direction': r.direction,
                'evidence': r.evidence
            } for r in results['relationships']
        ],
        'analysis': {
            k: v for k, v in results['analysis'].items()
            if isinstance(v, (int, float, str, list))
        }
    }
    
    return json.dumps(export_data, indent=2, ensure_ascii=False)

def export_to_graphml(results):
    """Exporte le r√©seau au format GraphML"""
    
    # Recr√©er le graphe
    G = nx.DiGraph()
    
    # Ajouter les n≈ìuds
    for entity in results['entities']:
        G.add_node(
            entity.name,
            type=entity.type,
            mentions=entity.mentions_count
        )
    
    # Ajouter les ar√™tes
    for rel in results['relationships']:
        G.add_edge(
            rel.source,
            rel.target,
            type=rel.type,
            weight=rel.strength
        )
    
    # Exporter en GraphML
    import io
    buffer = io.StringIO()
    nx.write_graphml(G, buffer)
    return buffer.getvalue()

# ===== FONCTIONS UTILITAIRES DU MODULE ORIGINAL =====

def extract_entities_and_relationships(documents: List[Dict[str, Any]], config: dict) -> Tuple[List[Entity], List[Relationship]]:
    """Extrait les entit√©s et relations des documents"""
    
    all_entities = {}  # nom -> Entity
    all_relationships = []
    
    for doc in documents:
        # Extraire les entit√©s du document
        doc_entities = extract_document_entities(doc, config)
        
        # Fusionner avec les entit√©s existantes
        for entity in doc_entities:
            if entity.name in all_entities:
                # Fusionner les informations
                existing = all_entities[entity.name]
                existing.mentions_count += entity.mentions_count
                existing.aliases.extend(entity.aliases)
                existing.aliases = list(set(existing.aliases))
            else:
                all_entities[entity.name] = entity
        
        # Extraire les relations
        doc_relationships = extract_document_relationships(doc, doc_entities, config)
        all_relationships.extend(doc_relationships)
    
    # Consolider les relations
    consolidated_relationships = consolidate_relationships(all_relationships)
    
    return list(all_entities.values()), consolidated_relationships

def extract_document_entities(doc: Dict[str, Any], config: dict) -> List[Entity]:
    """Extrait les entit√©s d'un document"""
    
    content = doc['content']
    entities = []
    
    # Utiliser la fonction helper pour extraire les entit√©s de base
    basic_entities = extract_entities(content)
    
    # Convertir en objets Entity selon le type de mapping
    if config['mapping_type'] in ['personnes', 'complete']:
        for person in basic_entities.get('persons', []):
            entity = Entity(
                name=person,
                type='person',
                mentions_count=content.count(person),
                first_mention=doc.get('title', 'Document')
            )
            entities.append(entity)
    
    if config['mapping_type'] in ['societes', 'complete', 'flux_financiers']:
        for org in basic_entities.get('organizations', []):
            entity = Entity(
                name=org,
                type='company',
                mentions_count=content.count(org),
                first_mention=doc.get('title', 'Document')
            )
            entities.append(entity)
    
    # Extraction sp√©cifique selon le type
    if config['mapping_type'] == 'flux_financiers':
        # Extraire les comptes bancaires
        account_pattern = r'\b(?:compte|IBAN|RIB)\s*:?\s*([A-Z0-9]+)'
        accounts = re.findall(account_pattern, content)
        for account in accounts:
            entity = Entity(
                name=f"Compte {account[:8]}...",
                type='account',
                mentions_count=1,
                first_mention=doc.get('title', 'Document')
            )
            entities.append(entity)
    
    return entities

def extract_document_relationships(doc: Dict[str, Any], entities: List[Entity], config: dict) -> List[Relationship]:
    """Extrait les relations d'un document"""
    
    content = doc['content']
    relationships = []
    
    # Cr√©er un mapping nom -> entit√©
    entity_map = {e.name.lower(): e for e in entities}
    
    # Patterns de relations selon le type
    relation_patterns = get_relation_patterns(config['mapping_type'])
    
    for pattern_info in relation_patterns:
        pattern = pattern_info['pattern']
        rel_type = pattern_info['type']
        
        matches = re.finditer(pattern, content, re.IGNORECASE)
        
        for match in matches:
            # Extraire les entit√©s de la relation
            source_entity, target_entity = extract_entities_from_match(match, entity_map, entities)
            
            if source_entity and target_entity:
                relationship = Relationship(
                    source=source_entity.name,
                    target=target_entity.name,
                    type=rel_type,
                    strength=calculate_relationship_strength(match.group(0), doc),
                    evidence=[doc.get('title', 'Document')]
                )
                relationships.append(relationship)
    
    # Relations de proximit√©
    proximity_relationships = extract_proximity_relationships(content, entities, config)
    relationships.extend(proximity_relationships)
    
    return relationships

def get_relation_patterns(mapping_type: str) -> List[Dict[str, Any]]:
    """Retourne les patterns de relations selon le type de mapping"""
    
    patterns = {
        'complete': [
            {
                'pattern': r'(\w+(?:\s+\w+)*)\s+(?:est|√©tait)\s+(?:le|la|l\')\s+(\w+)\s+de\s+(\w+(?:\s+\w+)*)',
                'type': 'hierarchical'
            },
            {
                'pattern': r'(\w+(?:\s+\w+)*)\s+et\s+(\w+(?:\s+\w+)*)\s+ont\s+(?:sign√©|conclu)',
                'type': 'contractual'
            },
            {
                'pattern': r'(\w+(?:\s+\w+)*)\s+(?:verse|transf√®re|paie)\s+.*\s+√†\s+(\w+(?:\s+\w+)*)',
                'type': 'financial'
            }
        ],
        'personnes': [
            {
                'pattern': r'(\w+\s+\w+)\s+(?:√©poux|√©pouse|conjoint|mari√©)',
                'type': 'familial'
            },
            {
                'pattern': r'(\w+\s+\w+)\s+(?:fils|fille|enfant|parent)\s+de\s+(\w+\s+\w+)',
                'type': 'familial'
            },
            {
                'pattern': r'(\w+\s+\w+)\s+(?:associ√©|partenaire)\s+(?:de|avec)\s+(\w+\s+\w+)',
                'type': 'business'
            }
        ],
        'societes': [
            {
                'pattern': r'(\w+(?:\s+\w+)*)\s+(?:filiale|succursale)\s+de\s+(\w+(?:\s+\w+)*)',
                'type': 'subsidiary'
            },
            {
                'pattern': r'(\w+(?:\s+\w+)*)\s+(?:d√©tient|poss√®de|contr√¥le)\s+.*\s+de\s+(\w+(?:\s+\w+)*)',
                'type': 'ownership'
            },
            {
                'pattern': r'fusion\s+(?:entre|de)\s+(\w+(?:\s+\w+)*)\s+et\s+(\w+(?:\s+\w+)*)',
                'type': 'merger'
            }
        ],
        'flux_financiers': [
            {
                'pattern': r'virement\s+de\s+([0-9,.\s]+)\s*‚Ç¨?\s+(?:de|depuis)\s+(\w+(?:\s+\w+)*)\s+(?:√†|vers)\s+(\w+(?:\s+\w+)*)',
                'type': 'transfer'
            },
            {
                'pattern': r'(\w+(?:\s+\w+)*)\s+(?:doit|verse|paie)\s+([0-9,.\s]+)\s*‚Ç¨?\s+√†\s+(\w+(?:\s+\w+)*)',
                'type': 'payment'
            }
        ],
        'hierarchique': [
            {
                'pattern': r'(\w+\s+\w+)\s+(?:directeur|pr√©sident|g√©rant)\s+de\s+(\w+(?:\s+\w+)*)',
                'type': 'manages'
            },
            {
                'pattern': r'(\w+\s+\w+)\s+(?:employ√©|salari√©|travaille)\s+(?:chez|pour)\s+(\w+(?:\s+\w+)*)',
                'type': 'employed_by'
            }
        ]
    }
    
    return patterns.get(mapping_type, patterns['complete'])

def extract_entities_from_match(match, entity_map: Dict[str, Entity], all_entities: List[Entity]) -> Tuple[Optional[Entity], Optional[Entity]]:
    """Extrait les entit√©s source et cible d'un match de pattern"""
    
    groups = match.groups()
    if len(groups) < 2:
        return None, None
    
    # Chercher les entit√©s dans les groupes
    source_text = groups[0].lower() if groups[0] else ""
    target_text = groups[-1].lower() if groups[-1] else ""
    
    source_entity = None
    target_entity = None
    
    # Recherche exacte d'abord
    source_entity = entity_map.get(source_text)
    target_entity = entity_map.get(target_text)
    
    # Si pas trouv√©, recherche partielle
    if not source_entity:
        for entity in all_entities:
            if source_text in entity.name.lower() or entity.name.lower() in source_text:
                source_entity = entity
                break
    
    if not target_entity:
        for entity in all_entities:
            if target_text in entity.name.lower() or entity.name.lower() in target_text:
                target_entity = entity
                break
    
    return source_entity, target_entity

def extract_proximity_relationships(content: str, entities: List[Entity], config: dict) -> List[Relationship]:
    """Extrait les relations bas√©es sur la proximit√© dans le texte"""
    
    relationships = []
    
    # Param√®tres de proximit√©
    window_size = 100  # caract√®res
    min_occurrences = 2  # minimum d'occurrences proches
    
    # Trouver les positions de chaque entit√©
    entity_positions = {}
    for entity in entities:
        positions = []
        for match in re.finditer(re.escape(entity.name), content, re.IGNORECASE):
            positions.append(match.start())
        entity_positions[entity.name] = positions
    
    # Analyser les proximit√©s
    for i, entity1 in enumerate(entities):
        for entity2 in entities[i+1:]:
            if entity1.name == entity2.name:
                continue
            
            # Compter les occurrences proches
            close_occurrences = 0
            
            for pos1 in entity_positions[entity1.name]:
                for pos2 in entity_positions[entity2.name]:
                    if abs(pos1 - pos2) <= window_size:
                        close_occurrences += 1
            
            if close_occurrences >= min_occurrences:
                relationship = Relationship(
                    source=entity1.name,
                    target=entity2.name,
                    type='proximity',
                    strength=min(close_occurrences / 10, 1.0),
                    evidence=[f"Proximit√© textuelle ({close_occurrences} occurrences)"]
                )
                relationships.append(relationship)
    
    return relationships

def calculate_relationship_strength(context: str, doc: Dict[str, Any]) -> float:
    """Calcule la force d'une relation"""
    
    strength = 0.5  # Base
    
    # Mots renfor√ßant la relation
    strong_words = ['principal', 'majoritaire', 'exclusif', 'unique', 'total', 'complet']
    weak_words = ['possible', '√©ventuel', 'partiel', 'minoritaire', 'accessoire']
    
    context_lower = context.lower()
    
    for word in strong_words:
        if word in context_lower:
            strength += 0.1
    
    for word in weak_words:
        if word in context_lower:
            strength -= 0.1
    
    # Montants √©lev√©s renforcent les relations financi√®res
    amounts = re.findall(r'(\d+(?:\.\d{3})*(?:,\d{2})?)\s*‚Ç¨', context)
    if amounts:
        for amount_str in amounts:
            try:
                amount = float(amount_str.replace('.', '').replace(',', '.'))
                if amount > 100000:
                    strength += 0.2
            except:
                pass
    
    return max(0.1, min(1.0, strength))

def consolidate_relationships(relationships: List[Relationship]) -> List[Relationship]:
    """Consolide les relations dupliqu√©es"""
    
    # Grouper les relations identiques
    rel_groups = defaultdict(list)
    
    for rel in relationships:
        # Cl√© normalis√©e (ignorer la direction pour certains types)
        if rel.type in ['contractual', 'business', 'proximity']:
            key = tuple(sorted([rel.source, rel.target])) + (rel.type,)
        else:
            key = (rel.source, rel.target, rel.type)
        
        rel_groups[key].append(rel)
    
    # Consolider
    consolidated = []
    
    for key, group in rel_groups.items():
        if len(group) == 1:
            consolidated.append(group[0])
        else:
            # Fusionner les relations
            merged = Relationship(
                source=group[0].source,
                target=group[0].target,
                type=group[0].type,
                strength=sum(r.strength for r in group) / len(group),
                direction=group[0].direction,
                evidence=list(set(sum([r.evidence for r in group], [])))
            )
            consolidated.append(merged)
    
    return consolidated

def parse_ai_mapping_response(response: str) -> Tuple[List[Entity], List[Relationship]]:
    """Parse la r√©ponse de l'IA pour extraire entit√©s et relations"""
    
    entities = []
    relationships = []
    
    lines = response.split('\n')
    current_section = None
    
    for line in lines:
        line = line.strip()
        
        if 'ENTIT√â' in line.upper():
            current_section = 'entities'
        elif 'RELATION' in line.upper():
            current_section = 'relationships'
        elif current_section == 'entities' and line.startswith('-'):
            # Parser une entit√©
            entity_match = re.match(r'-\s*([^:]+):\s*(.+)', line)
            if entity_match:
                name = entity_match.group(1).strip()
                details = entity_match.group(2).strip()
                
                # D√©terminer le type
                entity_type = 'person' if any(word in details.lower() for word in ['directeur', 'pr√©sident', 'g√©rant']) else 'company'
                
                entities.append(Entity(
                    name=name,
                    type=entity_type,
                    attributes={'details': details}
                ))
        
        elif current_section == 'relationships' and '->' in line:
            # Parser une relation
            rel_match = re.match(r'([^->]+)\s*->\s*([^:]+):\s*(.+)', line)
            if rel_match:
                source = rel_match.group(1).strip()
                target = rel_match.group(2).strip()
                rel_type = rel_match.group(3).strip()
                
                relationships.append(Relationship(
                    source=source,
                    target=target,
                    type=rel_type,
                    strength=0.7
                ))
    
    return entities, relationships

def merge_entities(existing: List[Entity], new: List[Entity]) -> List[Entity]:
    """Fusionne les listes d'entit√©s"""
    
    entity_map = {e.name.lower(): e for e in existing}
    
    for new_entity in new:
        key = new_entity.name.lower()
        if key in entity_map:
            # Fusionner les attributs
            entity_map[key].attributes.update(new_entity.attributes)
        else:
            entity_map[key] = new_entity
    
    return list(entity_map.values())

def filter_mapping_data(entities: List[Entity], relationships: List[Relationship], 
                       config: dict) -> Tuple[List[Entity], List[Relationship]]:
    """Filtre les donn√©es selon la configuration"""
    
    # Filtrer les entit√©s
    filtered_entities = entities
    
    # Par type
    if config.get('entity_types'):
        filtered_entities = [e for e in filtered_entities if e.type in config['entity_types']]
    
    # Exclure certaines entit√©s
    if config.get('exclude_entities'):
        exclude_list = [e.strip().lower() for e in config['exclude_entities'].split('\n') if e.strip()]
        filtered_entities = [e for e in filtered_entities if e.name.lower() not in exclude_list]
    
    # Focus sur certaines entit√©s
    if config.get('focus_entities'):
        focus_list = [e.strip().lower() for e in config['focus_entities'].split(',') if e.strip()]
        if focus_list:
            # Garder les entit√©s focus et leurs voisins directs
            focus_entities = {e.name for e in filtered_entities if e.name.lower() in focus_list}
            
            # Ajouter les voisins
            for rel in relationships:
                if rel.source in focus_entities:
                    focus_entities.add(rel.target)
                if rel.target in focus_entities:
                    focus_entities.add(rel.source)
            
            filtered_entities = [e for e in filtered_entities if e.name in focus_entities]
    
    # Filtrer les relations
    entity_names = {e.name for e in filtered_entities}
    filtered_relationships = [
        r for r in relationships 
        if r.source in entity_names and r.target in entity_names
        and r.strength >= config.get('min_strength', 0)
    ]
    
    return filtered_entities, filtered_relationships

def analyze_network(entities: List[Entity], relationships: List[Relationship]) -> Dict[str, Any]:
    """Analyse le r√©seau avec NetworkX"""
    
    # Cr√©er le graphe
    G = nx.Graph() if any(r.direction == 'bidirectional' for r in relationships) else nx.DiGraph()
    
    # Ajouter les n≈ìuds
    for entity in entities:
        G.add_node(entity.name, **entity.attributes, type=entity.type)
    
    # Ajouter les ar√™tes
    for rel in relationships:
        if rel.direction == 'bidirectional' or isinstance(G, nx.Graph):
            G.add_edge(rel.source, rel.target, weight=rel.strength, type=rel.type)
        else:
            G.add_edge(rel.source, rel.target, weight=rel.strength, type=rel.type)
    
    # Analyses
    analysis = {
        'node_count': G.number_of_nodes(),
        'edge_count': G.number_of_edges(),
        'density': nx.density(G),
        'components': list(nx.connected_components(G.to_undirected())) if isinstance(G, nx.DiGraph) else list(nx.connected_components(G)),
        'is_connected': nx.is_connected(G.to_undirected()) if isinstance(G, nx.DiGraph) else nx.is_connected(G)
    }
    
    # Centralit√©s
    try:
        analysis['degree_centrality'] = nx.degree_centrality(G)
        analysis['betweenness_centrality'] = nx.betweenness_centrality(G)
        
        if isinstance(G, nx.DiGraph):
            analysis['in_degree_centrality'] = nx.in_degree_centrality(G)
            analysis['out_degree_centrality'] = nx.out_degree_centrality(G)
    except:
        pass
    
    # Acteurs cl√©s (top 5 par centralit√©)
    if 'degree_centrality' in analysis:
        sorted_centrality = sorted(analysis['degree_centrality'].items(), key=lambda x: x[1], reverse=True)
        analysis['key_players'] = [node for node, _ in sorted_centrality[:5]]
    
    # Communaut√©s
    try:
        if isinstance(G, nx.Graph):
            communities = nx.community.greedy_modularity_communities(G)
            analysis['communities'] = [list(c) for c in communities]
            analysis['modularity'] = nx.community.modularity(G, communities)
    except:
        pass
    
    # Chemins
    if G.number_of_nodes() > 1:
        try:
            if nx.is_connected(G.to_undirected() if isinstance(G, nx.DiGraph) else G):
                analysis['average_shortest_path'] = nx.average_shortest_path_length(G)
                analysis['diameter'] = nx.diameter(G.to_undirected() if isinstance(G, nx.DiGraph) else G)
        except:
            pass
    
    return analysis

def basic_network_analysis(entities: List[Entity], relationships: List[Relationship]) -> Dict[str, Any]:
    """Analyse basique du r√©seau sans NetworkX"""
    
    # Compter les connexions par entit√©
    connections = defaultdict(int)
    for rel in relationships:
        connections[rel.source] += 1
        connections[rel.target] += 1
    
    # Acteurs cl√©s (plus de connexions)
    sorted_connections = sorted(connections.items(), key=lambda x: x[1], reverse=True)
    
    return {
        'node_count': len(entities),
        'edge_count': len(relationships),
        'density': len(relationships) / (len(entities) * (len(entities) - 1) / 2) if len(entities) > 1 else 0,
        'key_players': [node for node, _ in sorted_connections[:5]],
        'components': [],  # Non calcul√© sans NetworkX
        'is_connected': None
    }

def create_network_visualization(entities: List[Entity], relationships: List[Relationship], 
                                config: dict, analysis: Dict[str, Any]) -> go.Figure:
    """Cr√©e la visualisation du r√©seau avec Plotly"""
    
    # Calculer les positions des n≈ìuds
    pos = calculate_node_positions(entities, relationships, config['layout'])
    
    # Pr√©parer les donn√©es pour Plotly
    edge_trace = create_edge_trace(relationships, pos)
    node_trace = create_node_trace(entities, pos, config, analysis)
    
    # Cr√©er la figure
    fig = go.Figure(data=[edge_trace, node_trace])
    
    # Mise en forme
    fig.update_layout(
        title=f"Cartographie {config['mapping_type'].replace('_', ' ').title()}",
        showlegend=False,
        hovermode='closest',
        margin=dict(b=20, l=5, r=5, t=40),
        annotations=[],
        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
        plot_bgcolor='white'
    )
    
    # Ajouter les labels si demand√©
    if config.get('show_labels'):
        for entity, (x, y) in pos.items():
            fig.add_annotation(
                x=x, y=y,
                text=entity,
                showarrow=False,
                font=dict(size=10)
            )
    
    return fig

def calculate_node_positions(entities: List[Entity], relationships: List[Relationship], layout: str) -> Dict[str, Tuple[float, float]]:
    """Calcule les positions des n≈ìuds selon le layout"""

    # Cr√©er un graphe NetworkX temporaire
    G = nx.Graph()
    G.add_nodes_from([e.name for e in entities])
    G.add_edges_from([(r.source, r.target) for r in relationships])

    # Calculer les positions selon le layout
    if layout == 'spring':
        pos = nx.spring_layout(G, k=1, iterations=50)
    elif layout == 'circular':
        pos = nx.circular_layout(G)
    elif layout == 'hierarchical':
        try:
            pos = nx.nx_agraph.graphviz_layout(G, prog='dot')
        except Exception:
            pos = nx.spring_layout(G)
    elif layout == 'kamada_kawai':
        pos = nx.kamada_kawai_layout(G)
    else:
        pos = nx.spring_layout(G)
    
    return pos

def create_edge_trace(relationships: List[Relationship], pos: Dict[str, Tuple[float, float]]) -> go.Scatter:
    """Cr√©e le trace des ar√™tes pour Plotly"""
    
    edge_x = []
    edge_y = []
    
    for rel in relationships:
        if rel.source in pos and rel.target in pos:
            x0, y0 = pos[rel.source]
            x1, y1 = pos[rel.target]
            
            edge_x.extend([x0, x1, None])
            edge_y.extend([y0, y1, None])
    
    edge_trace = go.Scatter(
        x=edge_x, y=edge_y,
        line=dict(width=0.5, color='#888'),
        hoverinfo='none',
        mode='lines'
    )
    
    return edge_trace

def create_node_trace(entities: List[Entity], pos: Dict[str, Tuple[float, float]], 
                     config: dict, analysis: Dict[str, Any]) -> go.Scatter:
    """Cr√©e le trace des n≈ìuds pour Plotly"""
    
    node_x = []
    node_y = []
    node_text = []
    node_color = []
    node_size = []
    
    # Couleurs par d√©faut
    type_colors = {
        'person': '#FF6B6B',
        'company': '#4ECDC4',
        'organization': '#45B7D1',
        'account': '#96CEB4',
        'other': '#DDA0DD'
    }
    
    for entity in entities:
        if entity.name in pos:
            x, y = pos[entity.name]
            node_x.append(x)
            node_y.append(y)
            
            # Texte du hover
            text = f"<b>{entity.name}</b><br>"
            text += f"Type: {entity.type}<br>"
            text += f"Mentions: {entity.mentions_count}"
            node_text.append(text)
            
            # Couleur selon la configuration
            if config['color_by'] == 'type':
                color = type_colors.get(entity.type, '#DDA0DD')
            elif config['color_by'] == 'centrality' and 'degree_centrality' in analysis:
                # Gradient selon la centralit√©
                centrality = analysis['degree_centrality'].get(entity.name, 0)
                color = centrality * 100  # Pour la colorscale
            else:
                color = '#1f77b4'
            
            node_color.append(color)
            
            # Taille selon les mentions ou la centralit√©
            if 'degree_centrality' in analysis:
                size = 10 + analysis['degree_centrality'].get(entity.name, 0) * 50
            else:
                size = 10 + min(entity.mentions_count, 20) * 2
            
            node_size.append(size)
    
    node_trace = go.Scatter(
        x=node_x, y=node_y,
        mode='markers',
        hoverinfo='text',
        text=node_text,
        marker=dict(
            showscale=config['color_by'] == 'centrality',
            colorscale='Viridis',
            size=node_size,
            color=node_color,
            line_width=2,
            colorbar=dict(
                thickness=15,
                title='Centralit√©',
                xanchor='left',
                titleside='right'
            ) if config['color_by'] == 'centrality' else None
        )
    )
    
    return node_trace

def generate_mapping_report(mapping_result: Dict[str, Any]) -> str:
    """G√©n√®re un rapport textuel de la cartographie"""
    
    report = f"RAPPORT DE CARTOGRAPHIE - {mapping_result['type'].upper()}\n"
    report += "=" * 60 + "\n\n"
    
    report += f"G√©n√©r√© le : {mapping_result['timestamp'].strftime('%d/%m/%Y √† %H:%M')}\n"
    report += f"Documents analys√©s : {mapping_result['document_count']}\n\n"
    
    # R√©sum√©
    analysis = mapping_result['analysis']
    report += "R√âSUM√â DU R√âSEAU\n"
    report += "-" * 30 + "\n"
    report += f"Nombre d'entit√©s : {analysis['node_count']}\n"
    report += f"Nombre de relations : {analysis['edge_count']}\n"
    report += f"Densit√© du r√©seau : {analysis['density']:.2%}\n"
    report += f"R√©seau connect√© : {'Oui' if analysis.get('is_connected') else 'Non (fragment√©)'}\n\n"
    
    # Acteurs cl√©s
    if 'key_players' in analysis:
        report += "ACTEURS PRINCIPAUX\n"
        report += "-" * 30 + "\n"
        for i, player in enumerate(analysis['key_players'], 1):
            report += f"{i}. {player}\n"
        report += "\n"
    
    # Entit√©s par type
    type_counts = Counter(e.type for e in mapping_result['entities'])
    report += "R√âPARTITION DES ENTIT√âS\n"
    report += "-" * 30 + "\n"
    for entity_type, count in type_counts.items():
        report += f"{entity_type.title()} : {count}\n"
    report += "\n"
    
    # Relations par type
    rel_type_counts = Counter(r.type for r in mapping_result['relationships'])
    report += "TYPES DE RELATIONS\n"
    report += "-" * 30 + "\n"
    for rel_type, count in rel_type_counts.items():
        report += f"{rel_type.replace('_', ' ').title()} : {count}\n"
    report += "\n"
    
    # Communaut√©s d√©tect√©es
    if 'communities' in analysis and analysis['communities']:
        report += "COMMUNAUT√âS D√âTECT√âES\n"
        report += "-" * 30 + "\n"
        for i, community in enumerate(analysis['communities'], 1):
            report += f"Communaut√© {i} : {len(community)} membres\n"
            report += f"Membres : {', '.join(list(community)[:5])}"
            if len(community) > 5:
                report += "..."
            report += "\n\n"
    
    return report

def export_mapping_to_excel(mapping_result: Dict[str, Any]) -> bytes:
    """Exporte la cartographie vers Excel"""
    
    import io
    
    buffer = io.BytesIO()
    
    with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
        # Feuille des entit√©s
        entities_data = []
        for entity in mapping_result['entities']:
            entities_data.append({
                'Nom': entity.name,
                'Type': entity.type,
                'Mentions': entity.mentions_count,
                'Premi√®re mention': entity.first_mention or '',
                'Centralit√©': mapping_result['analysis'].get('degree_centrality', {}).get(entity.name, 0)
            })
        
        df_entities = pd.DataFrame(entities_data)
        df_entities.to_excel(writer, sheet_name='Entit√©s', index=False)
        
        # Feuille des relations
        relations_data = []
        for rel in mapping_result['relationships']:
            relations_data.append({
                'Source': rel.source,
                'Cible': rel.target,
                'Type': rel.type,
                'Force': rel.strength,
                'Direction': rel.direction,
                'Sources': ', '.join(rel.evidence) if rel.evidence else ''
            })
        
        df_relations = pd.DataFrame(relations_data)
        df_relations.to_excel(writer, sheet_name='Relations', index=False)
        
        # Feuille d'analyse
        analysis_data = []
        for key, value in mapping_result['analysis'].items():
            if isinstance(value, (int, float, str)):
                analysis_data.append({'M√©trique': key, 'Valeur': value})
        
        if analysis_data:
            df_analysis = pd.DataFrame(analysis_data)
            df_analysis.to_excel(writer, sheet_name='Analyse', index=False)
    
    buffer.seek(0)
    return buffer.getvalue()

# Point d'entr√©e pour le lazy loading
if __name__ == "__main__":
    run()