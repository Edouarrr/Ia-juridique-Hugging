"""Syst√®me de cache pour optimiser les performances du module juridique"""

import os
import json
import hashlib
import pickle
from datetime import datetime, timedelta
from typing import Any, Dict, Optional, Union
from functools import wraps
import streamlit as st

# Configuration du cache
CACHE_DIR = "cache_juridique"
CACHE_DURATION = {
    'acte_genere': timedelta(hours=24),      # Actes g√©n√©r√©s : 24h
    'analyse_requete': timedelta(hours=1),    # Analyses : 1h
    'enrichissement': timedelta(days=7),      # Infos soci√©t√©s : 7 jours
    'jurisprudence': timedelta(days=30),      # Jurisprudences : 30 jours
    'template': timedelta(days=90)            # Templates : 90 jours
}

# ========================= GESTIONNAIRE DE CACHE =========================

class CacheJuridique:
    """Gestionnaire de cache pour les op√©rations juridiques"""
    
    def __init__(self):
        self.cache_dir = CACHE_DIR
        self._ensure_cache_dir()
        self.memory_cache = {}  # Cache en m√©moire pour la session
    
    def _ensure_cache_dir(self):
        """Cr√©e le r√©pertoire de cache s'il n'existe pas"""
        if not os.path.exists(self.cache_dir):
            os.makedirs(self.cache_dir)
    
    def _get_cache_key(self, key: str, cache_type: str) -> str:
        """G√©n√®re une cl√© de cache unique"""
        # Hasher la cl√© pour √©viter les probl√®mes de noms de fichiers
        key_hash = hashlib.md5(key.encode()).hexdigest()
        return f"{cache_type}_{key_hash}"
    
    def _get_cache_path(self, cache_key: str) -> str:
        """Retourne le chemin complet du fichier de cache"""
        return os.path.join(self.cache_dir, f"{cache_key}.cache")
    
    def get(self, key: str, cache_type: str = 'general') -> Optional[Any]:
        """R√©cup√®re une valeur du cache"""
        
        # V√©rifier d'abord le cache m√©moire
        memory_key = f"{cache_type}:{key}"
        if memory_key in self.memory_cache:
            entry = self.memory_cache[memory_key]
            if self._is_valid_entry(entry, cache_type):
                return entry['data']
        
        # Sinon, v√©rifier le cache disque
        cache_key = self._get_cache_key(key, cache_type)
        cache_path = self._get_cache_path(cache_key)
        
        if os.path.exists(cache_path):
            try:
                with open(cache_path, 'rb') as f:
                    entry = pickle.load(f)
                
                if self._is_valid_entry(entry, cache_type):
                    # Mettre aussi en cache m√©moire
                    self.memory_cache[memory_key] = entry
                    return entry['data']
                else:
                    # Supprimer l'entr√©e expir√©e
                    os.remove(cache_path)
                    
            except Exception as e:
                print(f"Erreur lecture cache: {e}")
        
        return None
    
    def set(self, key: str, data: Any, cache_type: str = 'general'):
        """Stocke une valeur dans le cache"""
        
        entry = {
            'data': data,
            'timestamp': datetime.now().isoformat(),
            'type': cache_type
        }
        
        # Stocker en cache m√©moire
        memory_key = f"{cache_type}:{key}"
        self.memory_cache[memory_key] = entry
        
        # Stocker sur disque
        cache_key = self._get_cache_key(key, cache_type)
        cache_path = self._get_cache_path(cache_key)
        
        try:
            with open(cache_path, 'wb') as f:
                pickle.dump(entry, f)
        except Exception as e:
            print(f"Erreur √©criture cache: {e}")
    
    def _is_valid_entry(self, entry: Dict, cache_type: str) -> bool:
        """V√©rifie si une entr√©e de cache est encore valide"""
        
        if 'timestamp' not in entry:
            return False
        
        timestamp = datetime.fromisoformat(entry['timestamp'])
        duration = CACHE_DURATION.get(cache_type, timedelta(hours=1))
        
        return datetime.now() - timestamp < duration
    
    def clear(self, cache_type: Optional[str] = None):
        """Efface le cache (tout ou un type sp√©cifique)"""
        
        # Effacer le cache m√©moire
        if cache_type:
            keys_to_remove = [k for k in self.memory_cache.keys() 
                            if k.startswith(f"{cache_type}:")]
            for k in keys_to_remove:
                del self.memory_cache[k]
        else:
            self.memory_cache.clear()
        
        # Effacer le cache disque
        if os.path.exists(self.cache_dir):
            for filename in os.listdir(self.cache_dir):
                if cache_type and not filename.startswith(f"{cache_type}_"):
                    continue
                
                file_path = os.path.join(self.cache_dir, filename)
                try:
                    os.remove(file_path)
                except:
                    pass
    
    def get_stats(self) -> Dict[str, Any]:
        """Retourne des statistiques sur le cache"""
        
        stats = {
            'memory_entries': len(self.memory_cache),
            'disk_entries': 0,
            'total_size': 0,
            'by_type': {}
        }
        
        if os.path.exists(self.cache_dir):
            for filename in os.listdir(self.cache_dir):
                file_path = os.path.join(self.cache_dir, filename)
                stats['disk_entries'] += 1
                stats['total_size'] += os.path.getsize(file_path)
                
                # Compter par type
                cache_type = filename.split('_')[0]
                if cache_type not in stats['by_type']:
                    stats['by_type'][cache_type] = 0
                stats['by_type'][cache_type] += 1
        
        # Convertir la taille en format lisible
        stats['total_size_readable'] = self._format_size(stats['total_size'])
        
        return stats
    
    def _format_size(self, size_bytes: int) -> str:
        """Formate une taille en bytes en format lisible"""
        for unit in ['B', 'KB', 'MB', 'GB']:
            if size_bytes < 1024.0:
                return f"{size_bytes:.2f} {unit}"
            size_bytes /= 1024.0
        return f"{size_bytes:.2f} TB"

# Instance globale du cache
_cache_instance = None

def get_cache() -> CacheJuridique:
    """Retourne l'instance globale du cache"""
    global _cache_instance
    if _cache_instance is None:
        _cache_instance = CacheJuridique()
    return _cache_instance

# ========================= D√âCORATEURS DE CACHE =========================

def cache_result(cache_type: str = 'general', key_generator=None):
    """
    D√©corateur pour mettre en cache le r√©sultat d'une fonction
    
    Args:
        cache_type: Type de cache √† utiliser
        key_generator: Fonction pour g√©n√©rer la cl√© de cache √† partir des arguments
    """
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            # G√©n√©rer la cl√© de cache
            if key_generator:
                cache_key = key_generator(*args, **kwargs)
            else:
                # Cl√© par d√©faut bas√©e sur les arguments
                key_parts = [func.__name__]
                key_parts.extend(str(arg) for arg in args)
                key_parts.extend(f"{k}={v}" for k, v in sorted(kwargs.items()))
                cache_key = "|".join(key_parts)
            
            # V√©rifier le cache
            cache = get_cache()
            cached_result = cache.get(cache_key, cache_type)
            
            if cached_result is not None:
                return cached_result
            
            # Sinon, ex√©cuter la fonction
            result = func(*args, **kwargs)
            
            # Mettre en cache le r√©sultat
            cache.set(cache_key, result, cache_type)
            
            return result
        
        return wrapper
    return decorator

def cache_streamlit(cache_type: str = 'general', show_spinner: bool = True):
    """
    D√©corateur sp√©cifique pour Streamlit avec gestion du spinner
    """
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            # G√©n√©rer la cl√©
            key_parts = [func.__name__]
            key_parts.extend(str(arg) for arg in args if not callable(arg))
            cache_key = "|".join(key_parts)
            
            # V√©rifier le cache
            cache = get_cache()
            cached_result = cache.get(cache_key, cache_type)
            
            if cached_result is not None:
                st.info("üì¶ R√©sultat charg√© depuis le cache")
                return cached_result
            
            # Ex√©cuter avec spinner si demand√©
            if show_spinner:
                with st.spinner(f"‚è≥ G√©n√©ration en cours..."):
                    result = func(*args, **kwargs)
            else:
                result = func(*args, **kwargs)
            
            # Mettre en cache
            cache.set(cache_key, result, cache_type)
            
            return result
        
        return wrapper
    return decorator

# ========================= CACHE POUR LES ACTES =========================

class CacheActesJuridiques:
    """Cache sp√©cialis√© pour les actes juridiques g√©n√©r√©s"""
    
    def __init__(self):
        self.cache = get_cache()
    
    def get_acte(self, type_acte: str, parties: Dict, infractions: List[str]) -> Optional[Any]:
        """R√©cup√®re un acte en cache"""
        
        # Cr√©er une cl√© unique bas√©e sur les param√®tres
        key_data = {
            'type': type_acte,
            'demandeurs': sorted(parties.get('demandeurs', [])),
            'defendeurs': sorted(parties.get('defendeurs', [])),
            'infractions': sorted(infractions)
        }
        
        key = json.dumps(key_data, sort_keys=True)
        return self.cache.get(key, 'acte_genere')
    
    def save_acte(self, acte: Any, type_acte: str, parties: Dict, infractions: List[str]):
        """Sauvegarde un acte en cache"""
        
        key_data = {
            'type': type_acte,
            'demandeurs': sorted(parties.get('demandeurs', [])),
            'defendeurs': sorted(parties.get('defendeurs', [])),
            'infractions': sorted(infractions)
        }
        
        key = json.dumps(key_data, sort_keys=True)
        self.cache.set(key, acte, 'acte_genere')
    
    def get_recent_actes(self, limit: int = 10) -> List[Dict]:
        """R√©cup√®re les actes r√©cents depuis le cache"""
        
        recent = []
        
        if os.path.exists(self.cache.cache_dir):
            files = []
            
            # Lister tous les fichiers d'actes
            for filename in os.listdir(self.cache.cache_dir):
                if filename.startswith('acte_genere_'):
                    file_path = os.path.join(self.cache.cache_dir, filename)
                    files.append((file_path, os.path.getmtime(file_path)))
            
            # Trier par date de modification
            files.sort(key=lambda x: x[1], reverse=True)
            
            # Charger les plus r√©cents
            for file_path, mtime in files[:limit]:
                try:
                    with open(file_path, 'rb') as f:
                        entry = pickle.load(f)
                    
                    if self.cache._is_valid_entry(entry, 'acte_genere'):
                        acte = entry['data']
                        recent.append({
                            'acte': acte,
                            'date': datetime.fromtimestamp(mtime),
                            'type': acte.type_acte if hasattr(acte, 'type_acte') else 'inconnu'
                        })
                except:
                    pass
        
        return recent

# ========================= OPTIMISATION DES PERFORMANCES =========================

class OptimiseurPerformances:
    """Classe pour optimiser les performances du module juridique"""
    
    @staticmethod
    def preload_common_data():
        """Pr√©charge les donn√©es communes en cache"""
        
        cache = get_cache()
        
        # Pr√©charger les infractions communes
        from config.cahier_des_charges import INFRACTIONS_PENALES
        
        for code, details in INFRACTIONS_PENALES.items():
            cache.set(f"infraction_{code}", details, 'template')
        
        # Pr√©charger les templates de base
        from config.cahier_des_charges import TEMPLATES_SECTIONS
        
        for nom, template in TEMPLATES_SECTIONS.items():
            cache.set(f"template_{nom}", template, 'template')
    
    @staticmethod
    @cache_result(cache_type='analyse_requete')
    def analyze_query_cached(query: str) -> Dict:
        """Version cach√©e de l'analyse de requ√™te"""
        
        from modules.integration_juridique import AnalyseurRequeteJuridique
        
        analyseur = AnalyseurRequeteJuridique()
        return analyseur.analyser_requete(query)
    
    @staticmethod
    def get_performance_report() -> Dict[str, Any]:
        """G√©n√®re un rapport de performance"""
        
        cache = get_cache()
        stats = cache.get_stats()
        
        # Ajouter des m√©triques sp√©cifiques
        report = {
            'cache_stats': stats,
            'optimizations': {
                'memory_cache_enabled': True,
                'disk_cache_enabled': True,
                'lazy_loading_enabled': True
            },
            'recommendations': []
        }
        
        # Recommandations
        if stats['total_size'] > 100 * 1024 * 1024:  # 100 MB
            report['recommendations'].append(
                "Le cache d√©passe 100 MB. Pensez √† le nettoyer r√©guli√®rement."
            )
        
        if stats['memory_entries'] > 1000:
            report['recommendations'].append(
                "Plus de 1000 entr√©es en m√©moire. Red√©marrez l'application pour lib√©rer la m√©moire."
            )
        
        return report

# ========================= INTERFACE STREAMLIT =========================

def show_cache_management():
    """Interface de gestion du cache dans Streamlit"""
    
    st.header("üóÑÔ∏è Gestion du cache")
    
    cache = get_cache()
    stats = cache.get_stats()
    
    # Afficher les statistiques
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Entr√©es m√©moire", stats['memory_entries'])
    
    with col2:
        st.metric("Entr√©es disque", stats['disk_entries'])
    
    with col3:
        st.metric("Taille totale", stats['total_size_readable'])
    
    # D√©tails par type
    if stats['by_type']:
        st.subheader("üìä R√©partition par type")
        
        for cache_type, count in stats['by_type'].items():
            st.write(f"‚Ä¢ **{cache_type}:** {count} entr√©es")
    
    # Actions
    st.subheader("üéØ Actions")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("üîÑ Pr√©charger donn√©es", key="preload_cache"):
            with st.spinner("Pr√©chargement..."):
                OptimiseurPerformances.preload_common_data()
            st.success("‚úÖ Donn√©es pr√©charg√©es")
    
    with col2:
        cache_type_to_clear = st.selectbox(
            "Type √† effacer",
            ["Tout"] + list(CACHE_DURATION.keys()),
            key="cache_type_clear"
        )
    
    with col3:
        if st.button("üóëÔ∏è Effacer le cache", key="clear_cache"):
            if cache_type_to_clear == "Tout":
                cache.clear()
            else:
                cache.clear(cache_type_to_clear)
            st.success("‚úÖ Cache effac√©")
            st.rerun()
    
    # Actes r√©cents
    st.subheader("üìã Actes r√©cents en cache")
    
    cache_actes = CacheActesJuridiques()
    recent = cache_actes.get_recent_actes(5)
    
    if recent:
        for item in recent:
            with st.expander(f"{item['type']} - {item['date'].strftime('%d/%m/%Y %H:%M')}"):
                acte = item['acte']
                st.write(f"**Parties:** {len(acte.parties.get('defendeurs', []))} d√©fendeurs")
                st.write(f"**Longueur:** {acte.metadata.get('longueur_mots', 0)} mots")
                
                if st.button(f"R√©utiliser", key=f"reuse_{item['date'].timestamp()}"):
                    st.session_state.acte_genere = acte
                    st.success("‚úÖ Acte charg√©")
    else:
        st.info("Aucun acte r√©cent en cache")

# ========================= UTILISATION =========================

# Exemple d'utilisation avec le d√©corateur
@cache_result(cache_type='enrichissement')
def get_enriched_company_info(company_name: str) -> Dict:
    """R√©cup√®re les infos enrichies d'une soci√©t√© (avec cache)"""
    
    from services.pappers_service import PappersService
    
    service = PappersService()
    results = service.search_entreprise(company_name)
    
    if results:
        return results[0].to_dict()
    return {}

# Fonction pour nettoyer automatiquement le cache ancien
def cleanup_old_cache():
    """Nettoie les entr√©es de cache expir√©es"""
    
    cache = get_cache()
    
    if os.path.exists(cache.cache_dir):
        for filename in os.listdir(cache.cache_dir):
            file_path = os.path.join(cache.cache_dir, filename)
            
            try:
                # Charger pour v√©rifier l'expiration
                with open(file_path, 'rb') as f:
                    entry = pickle.load(f)
                
                # D√©terminer le type de cache
                cache_type = filename.split('_')[0]
                
                if not cache._is_valid_entry(entry, cache_type):
                    os.remove(file_path)
                    
            except:
                # Supprimer les fichiers corrompus
                try:
                    os.remove(file_path)
                except:
                    pass

if __name__ == "__main__":
    # Test du cache
    cache = get_cache()
    
    # Test set/get
    cache.set("test_key", {"data": "test"}, "general")
    result = cache.get("test_key", "general")
    print("Test cache:", result)
    
    # Stats
    stats = cache.get_stats()
    print("\nStatistiques du cache:")
    print(f"- Entr√©es m√©moire: {stats['memory_entries']}")
    print(f"- Entr√©es disque: {stats['disk_entries']}")
    print(f"- Taille totale: {stats['total_size_readable']}")